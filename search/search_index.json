{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Undine \ud83d\udd17 1 pip install undine Source Code : https://github.com/MrThearMan/undine/ Undine is a GraphQL library for Django. It's designed to be easy to use and extend while providing out-of-the-box solutions for many common issues GraphQL developers face. Feature highlights: Automatic generation of GraphQL types from Django models Automatic query optimization Logically composable filtering Ordering based on enums Single and bulk mutations, including relations Hidden and input-only mutation inputs Built-in permission and validation hooks Support for Relay Global object IDs and Connection pagination File uploads based on GraphQL multipart request specification Support for asynchronous execution Subscriptions with websockets Optional persisted documents support Lifecycle hooks for customizing the GraphQL request cycle Hiding fields and types from schema (experimental) Built-in testing tools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 from typing import Any from undine import Entrypoint , FilterSet , GQLInfo , MutationType , OrderSet , QueryType , RootType , create_schema from undine.exceptions import GraphQLPermissionError from undine.relay import Connection from .models import Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( Connection ( TaskType )) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation )","title":"Home"},{"location":"#undine","text":"1 pip install undine Source Code : https://github.com/MrThearMan/undine/ Undine is a GraphQL library for Django. It's designed to be easy to use and extend while providing out-of-the-box solutions for many common issues GraphQL developers face. Feature highlights: Automatic generation of GraphQL types from Django models Automatic query optimization Logically composable filtering Ordering based on enums Single and bulk mutations, including relations Hidden and input-only mutation inputs Built-in permission and validation hooks Support for Relay Global object IDs and Connection pagination File uploads based on GraphQL multipart request specification Support for asynchronous execution Subscriptions with websockets Optional persisted documents support Lifecycle hooks for customizing the GraphQL request cycle Hiding fields and types from schema (experimental) Built-in testing tools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 from typing import Any from undine import Entrypoint , FilterSet , GQLInfo , MutationType , OrderSet , QueryType , RootType , create_schema from undine.exceptions import GraphQLPermissionError from undine.relay import Connection from .models import Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( Connection ( TaskType )) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation )","title":"Undine"},{"location":"async/","text":"Async support \ud83d\udd17 In this section, we'll cover how you can make you schema support async operations. Note that asynchronous execution will require an ASGI capable web server . Setup \ud83d\udd17 To enable async support, you need to set the ASYNC setting to True . 1 2 3 UNDINE = { \"ASYNC\" : True , } Now your GraphQL endpoint will change from a sync view to an async view. This allows you to write your Entrypoint resolvers as coroutines. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint async def example ( self , info : GQLInfo ) -> str : return \"foo\" @example . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : # Some permission check logic here return Various parts of the QueryTypes , MutationTypes , and their Fields and Inputs can also be made async. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve async def resolve_name ( self , info : GQLInfo ) -> str : return self . name @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class CustomTaskMutation ( MutationType [ Task ]): name = Input () @name . validate async def validate ( self , info : GQLInfo , value : str ) -> None : return @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return @classmethod async def __mutate__ ( cls , root : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Any : return @classmethod async def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> Any : return @classmethod async def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return Notes \ud83d\udd17 Using async resolvers without ASYNC enabled will raise an error when an operation resolves using that resolver. Existing resolvers e.g. for QueryTypes and MutationTypes will automatically adapt to work in an async context based on the ASYNC setting. Another small detail that is worth noting when ASYNC is enabled is that info.context.user is always fetched eagerly, even if it's not used in the operation. This allows using the request user in synchronous parts of the code without causing an error due to using the Django ORM directly in an async context. Asynchronous execution is also slightly slower than synchronous execution due to inherent overhead of the asyncio event loop. See Django's async documentation for changes that need to be made for Django to work in async context.","title":"Async Support"},{"location":"async/#async-support","text":"In this section, we'll cover how you can make you schema support async operations. Note that asynchronous execution will require an ASGI capable web server .","title":"Async support"},{"location":"async/#setup","text":"To enable async support, you need to set the ASYNC setting to True . 1 2 3 UNDINE = { \"ASYNC\" : True , } Now your GraphQL endpoint will change from a sync view to an async view. This allows you to write your Entrypoint resolvers as coroutines. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint async def example ( self , info : GQLInfo ) -> str : return \"foo\" @example . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : # Some permission check logic here return Various parts of the QueryTypes , MutationTypes , and their Fields and Inputs can also be made async. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve async def resolve_name ( self , info : GQLInfo ) -> str : return self . name @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class CustomTaskMutation ( MutationType [ Task ]): name = Input () @name . validate async def validate ( self , info : GQLInfo , value : str ) -> None : return @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return @classmethod async def __mutate__ ( cls , root : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Any : return @classmethod async def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> Any : return @classmethod async def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return","title":"Setup"},{"location":"async/#notes","text":"Using async resolvers without ASYNC enabled will raise an error when an operation resolves using that resolver. Existing resolvers e.g. for QueryTypes and MutationTypes will automatically adapt to work in an async context based on the ASYNC setting. Another small detail that is worth noting when ASYNC is enabled is that info.context.user is always fetched eagerly, even if it's not used in the operation. This allows using the request user in synchronous parts of the code without causing an error due to using the Django ORM directly in an async context. Asynchronous execution is also slightly slower than synchronous execution due to inherent overhead of the asyncio event loop. See Django's async documentation for changes that need to be made for Django to work in async context.","title":"Notes"},{"location":"contributing/","text":"Contributing \ud83d\udd17 Thank you for your interest in contributing! To start, please read the library docs thoroughly. If you don't find what you are looking for, proceed with the steps below. I found a bug! \ud83d\udd17 Please file a bug report . If you are not using the latest version of the library, please upgrade and see if that fixes the issue. If not, please create a minimal example that demonstrates the bug and instructions on how to create that setup from a new virtual environment. Also include any error tracebacks (unabridged when possible). This will help a lot when diagnosing the bug. Do not use pictures to include the traceback. I have a feature request! \ud83d\udd17 You can suggest new features to be implemented via a feature request . You can ask me to implement it or work on it yourself but all features should be discussed and agreed upon first before any coding is done. I have a question! \ud83d\udd17 Please ask it in the discussions section instead of creating an issue. If your question warrants an issue, I'll ask you to create it. Questions about clarifying documentation are appreciated! Creating a pull request \ud83d\udd17 Once you have created a feature request , we have agreed on an implementation, and you wish to work on it, follow these steps to create a pull request. Fork the repository . Clone your fork and create a new branch from the main branch. Set up the environment . Make changes and write tests following these guidelines . Add documentation when applicable following these guidelines . Push the changes to your fork. Create a pull request targeting the main branch. Sit back while your pull request is reviewed . Note that a pull request should always be aimed at solving a single issue. If you want multiple issues solved, make separate pull requests for each. Corrections for spelling mistakes are the exception, since I make so many of those... Pull requests should be kept as small as possible while following the guidelines mentioned above. Smaller pull request are easier to review and test which helps them get merged. Code review process \ud83d\udd17 Pull requests will be reviewed automatically and manually. In the automated phase, GitHub Actions will run testing pipelines for all supported operating systems and python versions, and pre-commit CI will check linting rules. If you encounter any errors, try to fix them based on what the pipelines tell you. If coverage is lowered, add tests, noting the guidelines here . Don't be afraid to ask for advice if you're unsure what is wrong. Note for first-time contributors: Checks are not allowed to run automatically for first-time contributors, so you'll need me to approve them each time you push new code. In the manual phase, I will review the pull request by adding comments with suggestions for changes. If you agree with the suggestions, implement them and push the changes to you fork \u2014 the pull request will be updated automatically. You can either amend your previous commits or add more commits, either is fine. If you disagree with the suggestions, provide your reasons for disagreeing and we can discuss what to do. Once all automated checks have passed and I have accepted the pull request, your code will be merged to the main branch. Any related issues should be closed as completed. I'll usually make a new release after each new feature, but if not, you can also ask for one. Creating a new release \ud83d\udd17 Increment the version in pyproject.toml , loosely following semantic versioning rules. Push the change to the main branch with the commit message Bump version . Draft a new release on GitHub. Use v{version} (e.g. v1.2.3) for the tag name and Release {version} for the release title, using the same version that's in pyproject.toml . Note that the release will be made with the pyproject.toml version and not the tag name! Fill in the release description. Add any attachments when applicable. Publish the release. This will start the release pipeline in GitHub Actions . Check that the release pipeline was successful. If not, delete the tag from origin with git push --delete origin {tag_name} and fix the issue before trying again. Setting up the environment \ud83d\udd17 Install Poetry . Install Just . Run just install to create a virtual environment and install project dependencies. Run just hook to install the pre-commit hooks. Run just help to list all existing development commands and their descriptions. Testing \ud83d\udd17 Tests can be run with just test and individual tests with just test <test_name> . This will run tests in you local environment . You can also test your code in multiple environments with nox . To do this, you must install python interpreters for all python version the library supports and then run just nox . Linting can be run on-demand with just lint or automatically before commits when installed with just hook . Guidelines for writing code \ud83d\udd17 All code should be tested with 100% coverage \ud83d\udd17 Do not write tests simply to archive 100% coverage. Instead, try to write tests for all the ways the feature could be used (use cases), including ways that should not work, and then test for coverage. If you find uncovered code, see if you can remove it, or maybe you simply missed a use case. You should always need more tests to cover all use cases than to achieve 100% coverage. Adding # pragma: no cover to a line of code will ignore it from coverage results, but this should be used very sparingly, as this can lead to undocumented behavior if you are not careful. An example of a line that might be ignored like this is an exception that is raised at the end of a match statement, where its cases cover all possible inputs (basically a statement that should never be reached). All code should be typed when possible \ud83d\udd17 Tests are an exception to this. Make sure the typing construct used is supported in all python versions the library supports. If not, you should reconsider if there is an older alternative, or if there is a backport that can be installed conditionally for the older versions. In these cases, the type should be added to the undine/typing.py file, so that the import logic between the backport and the standard library is contained in one place. Create all custom types in undine/typing.py and import them from there. This helps avoids circular imports and prevents creating duplicate types. Use of TypedDict is encouraged where dicts would be used. All \"public\" functions, methods, and classes should include a docstring \ud83d\udd17 \"Public\" here means that the piece of code is intended to be used by the library users directly, and not inside the library itself. Docstrings should be written in reStructuredText format . Code that is short and clearly self-documenting does not necessarily need a docstring. As an example, def sum(i: int, j: int) -> int: return i + j does not need a docstring. This applies more broadly to arguments, e.g., when a function might need a docstring, the arguments might not need explicit documentation. Keep the docstring to the point. Each line of documentation has a maintenance cost. Documentation is not an excuse to write code that is hard to understand. Docstrings can include code examples, but longer one should be written to docs . All code should be linted using the projects lint rules \ud83d\udd17 Easiest way to do this is to install the pre-commit hooks with just hook . This will make sure the pre-commit hooks will run automatically when you make a commit. You can also run hooks manually with just lint . Comments that ignore linting rules ( # type: ignore[...] , # fmt: off , # noqa: ... ) should be used very sparingly. They are often not necessary and can lead to undocumented behavior if you are not careful. Guidelines for writing documentation \ud83d\udd17 All documentation is written in docs/ using markdown, and built with mkdocs Write in idiomatic english, using simple language Keep examples simple and self-contained Give the reader time to understand the basics before going over edge cases and configurations Use markdown features, like fenced code blocks , blockquotes , horizontal rules , or links , to emphasize and format text If diagrams are needed, use mermaid.js inside fenced code blocks Break up lines around the 100 character mark Do not use emojis Double-check for spelling mistakes and grammar License \ud83d\udd17 By contributing, you agree that your contributions will be licensed under the MIT Licence .","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for your interest in contributing! To start, please read the library docs thoroughly. If you don't find what you are looking for, proceed with the steps below.","title":"Contributing"},{"location":"contributing/#i-found-a-bug","text":"Please file a bug report . If you are not using the latest version of the library, please upgrade and see if that fixes the issue. If not, please create a minimal example that demonstrates the bug and instructions on how to create that setup from a new virtual environment. Also include any error tracebacks (unabridged when possible). This will help a lot when diagnosing the bug. Do not use pictures to include the traceback.","title":"I found a bug!"},{"location":"contributing/#i-have-a-feature-request","text":"You can suggest new features to be implemented via a feature request . You can ask me to implement it or work on it yourself but all features should be discussed and agreed upon first before any coding is done.","title":"I have a feature request!"},{"location":"contributing/#i-have-a-question","text":"Please ask it in the discussions section instead of creating an issue. If your question warrants an issue, I'll ask you to create it. Questions about clarifying documentation are appreciated!","title":"I have a question!"},{"location":"contributing/#creating-a-pull-request","text":"Once you have created a feature request , we have agreed on an implementation, and you wish to work on it, follow these steps to create a pull request. Fork the repository . Clone your fork and create a new branch from the main branch. Set up the environment . Make changes and write tests following these guidelines . Add documentation when applicable following these guidelines . Push the changes to your fork. Create a pull request targeting the main branch. Sit back while your pull request is reviewed . Note that a pull request should always be aimed at solving a single issue. If you want multiple issues solved, make separate pull requests for each. Corrections for spelling mistakes are the exception, since I make so many of those... Pull requests should be kept as small as possible while following the guidelines mentioned above. Smaller pull request are easier to review and test which helps them get merged.","title":"Creating a pull request"},{"location":"contributing/#code-review-process","text":"Pull requests will be reviewed automatically and manually. In the automated phase, GitHub Actions will run testing pipelines for all supported operating systems and python versions, and pre-commit CI will check linting rules. If you encounter any errors, try to fix them based on what the pipelines tell you. If coverage is lowered, add tests, noting the guidelines here . Don't be afraid to ask for advice if you're unsure what is wrong. Note for first-time contributors: Checks are not allowed to run automatically for first-time contributors, so you'll need me to approve them each time you push new code. In the manual phase, I will review the pull request by adding comments with suggestions for changes. If you agree with the suggestions, implement them and push the changes to you fork \u2014 the pull request will be updated automatically. You can either amend your previous commits or add more commits, either is fine. If you disagree with the suggestions, provide your reasons for disagreeing and we can discuss what to do. Once all automated checks have passed and I have accepted the pull request, your code will be merged to the main branch. Any related issues should be closed as completed. I'll usually make a new release after each new feature, but if not, you can also ask for one.","title":"Code review process"},{"location":"contributing/#creating-a-new-release","text":"Increment the version in pyproject.toml , loosely following semantic versioning rules. Push the change to the main branch with the commit message Bump version . Draft a new release on GitHub. Use v{version} (e.g. v1.2.3) for the tag name and Release {version} for the release title, using the same version that's in pyproject.toml . Note that the release will be made with the pyproject.toml version and not the tag name! Fill in the release description. Add any attachments when applicable. Publish the release. This will start the release pipeline in GitHub Actions . Check that the release pipeline was successful. If not, delete the tag from origin with git push --delete origin {tag_name} and fix the issue before trying again.","title":"Creating a new release"},{"location":"contributing/#setting-up-the-environment","text":"Install Poetry . Install Just . Run just install to create a virtual environment and install project dependencies. Run just hook to install the pre-commit hooks. Run just help to list all existing development commands and their descriptions.","title":"Setting up the environment"},{"location":"contributing/#testing","text":"Tests can be run with just test and individual tests with just test <test_name> . This will run tests in you local environment . You can also test your code in multiple environments with nox . To do this, you must install python interpreters for all python version the library supports and then run just nox . Linting can be run on-demand with just lint or automatically before commits when installed with just hook .","title":"Testing"},{"location":"contributing/#guidelines-for-writing-code","text":"","title":"Guidelines for writing code"},{"location":"contributing/#all-code-should-be-tested-with-100-coverage","text":"Do not write tests simply to archive 100% coverage. Instead, try to write tests for all the ways the feature could be used (use cases), including ways that should not work, and then test for coverage. If you find uncovered code, see if you can remove it, or maybe you simply missed a use case. You should always need more tests to cover all use cases than to achieve 100% coverage. Adding # pragma: no cover to a line of code will ignore it from coverage results, but this should be used very sparingly, as this can lead to undocumented behavior if you are not careful. An example of a line that might be ignored like this is an exception that is raised at the end of a match statement, where its cases cover all possible inputs (basically a statement that should never be reached).","title":"All code should be tested with 100% coverage"},{"location":"contributing/#all-code-should-be-typed-when-possible","text":"Tests are an exception to this. Make sure the typing construct used is supported in all python versions the library supports. If not, you should reconsider if there is an older alternative, or if there is a backport that can be installed conditionally for the older versions. In these cases, the type should be added to the undine/typing.py file, so that the import logic between the backport and the standard library is contained in one place. Create all custom types in undine/typing.py and import them from there. This helps avoids circular imports and prevents creating duplicate types. Use of TypedDict is encouraged where dicts would be used.","title":"All code should be typed when possible"},{"location":"contributing/#all-public-functions-methods-and-classes-should-include-a-docstring","text":"\"Public\" here means that the piece of code is intended to be used by the library users directly, and not inside the library itself. Docstrings should be written in reStructuredText format . Code that is short and clearly self-documenting does not necessarily need a docstring. As an example, def sum(i: int, j: int) -> int: return i + j does not need a docstring. This applies more broadly to arguments, e.g., when a function might need a docstring, the arguments might not need explicit documentation. Keep the docstring to the point. Each line of documentation has a maintenance cost. Documentation is not an excuse to write code that is hard to understand. Docstrings can include code examples, but longer one should be written to docs .","title":"All \"public\" functions, methods, and classes should include a docstring"},{"location":"contributing/#all-code-should-be-linted-using-the-projects-lint-rules","text":"Easiest way to do this is to install the pre-commit hooks with just hook . This will make sure the pre-commit hooks will run automatically when you make a commit. You can also run hooks manually with just lint . Comments that ignore linting rules ( # type: ignore[...] , # fmt: off , # noqa: ... ) should be used very sparingly. They are often not necessary and can lead to undocumented behavior if you are not careful.","title":"All code should be linted using the projects lint rules"},{"location":"contributing/#guidelines-for-writing-documentation","text":"All documentation is written in docs/ using markdown, and built with mkdocs Write in idiomatic english, using simple language Keep examples simple and self-contained Give the reader time to understand the basics before going over edge cases and configurations Use markdown features, like fenced code blocks , blockquotes , horizontal rules , or links , to emphasize and format text If diagrams are needed, use mermaid.js inside fenced code blocks Break up lines around the 100 character mark Do not use emojis Double-check for spelling mistakes and grammar","title":"Guidelines for writing documentation"},{"location":"contributing/#license","text":"By contributing, you agree that your contributions will be licensed under the MIT Licence .","title":"License"},{"location":"dataloaders/","text":"DataLoaders \ud83d\udd17 In this section, we'll cover Undine's DataLoader , which is a utility for loading data in batches. DataLoaders can be used to optimize the performance of queries that require I/O operations, like fetching data from an external API. DataLoaders are implemented using python's asyncio library, so you'll need to turn on Undine's async support to use them. In most cases, using DataLoaders to optimize database queries is not necessary, as Undine's Optimizer already handles this for you. DataLoader \ud83d\udd17 A DataLoader always requires a \"load function\" ( load_fn ) which implements the actual logic for fetching data. This function receives a list of \"keys\" that identify the data that should be fetched. Let's look at an example which fetches a list of pokemon from an external API by their name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity return [ response . json () for response in responses ] pokemon_loader = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . load ( name ) Here, the DataLoader load function load_pokemon receives a list of keys (pokemon names in this case) and makes an equal number of concurrent HTTP requests to an external API to fetch these pokemon information. The keys which the load function receives for a given GraphQL operation are defined by calls to DataLoader.load , like in the pokemon_by_name Entrypoint resolver in the above example. Note that the resolver returns a Future object from the DataLoader , and that the function is not async \u2014 this is important for the DataLoader to work correctly. This is discussed more thoroughly in the Technical Details section. Given the above setup, if you query pokemon_by_name multiple times like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { slotOne : pokemonByName ( name : \"pikachu\" ) { id name height weight } slotTwo : pokemonByName ( name : \"eevee\" ) { id name height weight } } The DataLoader will run the load function load_pokemon once with keys [\"pikachu\", \"eevee\"] to fetch pokemon information for both slotOne and slotTwo . Note that the load function needs to return the loaded values in the same order that it received the keys in, so that the values can be matched up with the keys by the DataLoader . You also cannot return less or more values than the number of keys you received. Returning errors \ud83d\udd17 If the load for a particular key fails, you can return an exception from the load function for that key. This exception will be converted into a GraphQL error in the response to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon | ValueError ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity msg = \"Pokemon not found\" return [ response . json () if response . status_code == 200 else ValueError ( msg ) for response in responses ] pokemon_by_name = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon | None ]: return pokemon_by_name . load ( name ) Note that in this case the Entrypoint is made nullable so that only the requests for pokemon that fail to load will return null with an error, and the rest will return the loaded pokemon information. For example, given the query we defined above, if load for slotOne fails, the response will be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"slotOne\" : null , \"slotTwo\" : { \"id\" : 12 , \"name\" : \"eevee\" , \"height\" : 3 , \"weight\" : 65 } }, \"errors\" : [ { \"message\" : \"Pokemon not found\" , \"path\" : [ \"slotOne\" ] } ] } Max batch size \ud83d\udd17 By default, a DataLoader will load all keys requested in a GraphQL operation in a single batch. If you want to limit the number of keys that are loaded in a single batch, you can use the max_batch_size parameter. 1 2 3 4 5 6 7 8 9 10 11 12 from typing import TypedDict from undine import DataLoader class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon , max_batch_size = 10 ) In this case, limiting the maximum batch size will ensure that we don't send too many concurrent requests to the external API, which can help avoid timeouts and rate limits. Reusing loads \ud83d\udd17 By default, if a DataLoader receives a request to load the same key multiple times, it will reuse the previous load and share the result between them. For example, if you query the pokemon_by_name Entrypoint with the following query: 1 2 3 4 5 6 7 8 query { slotOne : pokemonByName ( name : \"pikachu\" ) { name } slotTwo : pokemonByName ( name : \"pikachu\" ) { name } } The DataLoader will run the load function load_pokemon once with keys [\"pikachu\"] and reuse the result for both slotOne and slotTwo . Reuse will happen even if the load happens in a different batches when a max_batch_size has been set. If you want to disable reuse, you can set the reuse_loads parameter to False . 1 2 3 4 5 6 7 8 9 10 11 12 from typing import TypedDict from undine import DataLoader class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon , reuse_loads = False ) This will result in the DataLoader running the load function load_pokemon with keys [\"pikachu\", \"pikachu\"] instead, where the first key matches load for slotOne and the second for slotTwo . Note that reused loads should not be treated as a cache, as they are not shared between requests or web service workers. Since load reuse stores Future objects (see Technical Details ), it's much easier to add caching in the load function or in application code using Django's cache API. Priming loads \ud83d\udd17 When DataLoader load reuse is enabled, you can prime the DataLoader with completed load results for specific keys without going through the load function. This way if a load would be requested for a primed key, that primed value would be returned immediately. If batch size is limited using max_batch_size , that load would also not contribute to the size of the batch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon ) pikachu = Pokemon ( id = 25 , name = \"pikachu\" , height = 4 , weight = 60 , ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . prime ( key = \"pikachu\" , value = pikachu ) . load ( name ) Priming can also be useful when loads for the same object can happen by different keys, for example, if loads for a pokemon can happen by the pokemon's name or its ID. In this case, you should also provide a common asyncio.Lock for the DataLoaders so that one load function can run before the other load functions. You might also want to set the can_prime_pending_loads parameter to True so that already pending loads from the other DataLoaders can be set. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon_by_id ( keys : list [ int ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_id} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_id = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity data : list [ Pokemon ] = [ response . json () for response in responses ] # Prime the name loader with the fetched data names = [ pokemon [ \"name\" ] for pokemon in data ] pokemon_name_loader . prime_many ( keys = names , values = data , can_prime_pending_loads = True ) return data async def load_pokemon_by_name ( keys : list [ str ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity data : list [ Pokemon ] = [ response . json () for response in responses ] # Prime the ID loader with the fetched data ids = [ pokemon [ \"id\" ] for pokemon in data ] pokemon_id_loader . prime_many ( keys = ids , values = data , can_prime_pending_loads = True ) return data lock = asyncio . Lock () pokemon_id_loader = DataLoader ( load_fn = load_pokemon_by_id , lock = lock ) pokemon_name_loader = DataLoader ( load_fn = load_pokemon_by_name , lock = lock ) class Query ( RootType ): @Entrypoint def pokemon_by_id ( self , info : GQLInfo , id : int ) -> Future [ Pokemon ]: return pokemon_id_loader . load ( id ) @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_name_loader . load ( name ) Clearing loads \ud83d\udd17 When DataLoader load reuse is enabled, you can also clear reused loads. A potential use case for this would be if a mutation on the loaded data would be performed during the GraphQL operation, and the load would therefore need to be re-fetched. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . clear ( key = name ) . load ( name ) Custom key hash function \ud83d\udd17 When DataLoader load reuse is enabled, loads are mapped internally by the DataLoader from the load key to a Future object where the load result will be stored once it's available. For the load key to be used as a key in a map, it needs to be hashable, but you can use non-hashable keys by providing a custom key hash function ( key_hash_fn ). A key hash function is also useful when two different objects should be considered equal when loading them using a DataLoader . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ dict [ str , str ]]) -> list [ Pokemon ]: ... def key_hash_fn ( key : dict [ str , str ]) -> str : return key [ \"name\" ] pokemon_loader = DataLoader ( load_fn = load_pokemon , key_hash_fn = key_hash_fn ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . load ({ \"name\" : name }) Technical Details \ud83d\udd17 In this section, we'll go over how Undine's DataLoader works during a GraphQL operation. Knowing these details can help you in debugging DataLoaders , but are not necessary for getting started with them. When a DataLoder is created, it adds a signal receiver for the request_finished signal. This receiver is responsible for clearing the DataLoader's reusable loads when a request finishes, freeing up memory. This ensures that you can reuse the same DataLoader for the next request. DataLoaders can be used in GraphQL resolvers by calling load on them. This creates a new Future that will be set when the data is loaded using the DataLoader load function ( load_fn ). If load reuse is enabled, calling load might also reuse an existing Future created by a previous call to load with the same key. The existing Future is likely pending, but it can be already completed if a maximum batch size has been set and the Future was set in a previous batch, or it can be primed manually. If a reusable load is found, its Future is returned immediately. Otherwise, the DataLoader will check if a new batch needs to be created. New batches are needed when the previous batch has already been dispatched, or when the maximum batch size has been reached. For the first load of a new request, a new batch will always be created. This batch is then scheduled in the event loop as a Task . Whether a call to DataLoder.load returns an existing Future or creates a new one, the resolver should then return that Future . During the execution of a GraphQL operation, when a resolver returns an awaitable value (like a coroutine or Future ), that awaitable is wrapped in a coroutine and saved until all other fields have been resolved. This allows all resolvers to run before any awaitables are awaited, which makes sure that DataLoaders are populated from all resolvers before the event loop next runs and any batches are dispatched. Next, all these resolver coroutines are executed concurrently using gather , which turns them into Tasks and schedules them to run in the event loop. Then, the Future returned by gather is awaited, which hands control back to the event loop. The event loop then decides which order it runs the batch and resolver Tasks . In a resolver Task , the resolver will begin awaiting its awaitable, which in case of DataLoader is the Future returned by the load . In a batch Task , the DataLoader load function is scheduled to run using yet another Task . Additionally, all Futures in the batch that are waiting for results from the load function Task will have a done callback added at this point. This callback will cancel the load function Task if any of the Futures waiting for its results are canceled and all other Futures are also done. This can happen, for example, when a TaskGroup is canceled due to an exception in one of its Tasks . Cancelling the load function Task in this case ensures that it won't use resources that are no longer available (e.g. a database connection). The batch Task then begins awaiting for the load function Task to complete. If multiple DataLoaders are used in the operation, their batch Tasks might also schedule their load function Tasks in the event loop as well. Then each DataLoader's load function Tasks are executed, until they have all finished running. Then execution resumes in the one of the batch Tasks , which sets its Futures with the results from the load function. After a batch Task returns, the resolver Tasks that were waiting for the Futures to be set from this batch can resume and return the Future results. The other batch Tasks will follow suit until each batch and resolver Task has finished running. Finally, the gather Future resolves and fills the response data with the results from each awaitable field resolver.","title":"DataLoaders"},{"location":"dataloaders/#dataloaders","text":"In this section, we'll cover Undine's DataLoader , which is a utility for loading data in batches. DataLoaders can be used to optimize the performance of queries that require I/O operations, like fetching data from an external API. DataLoaders are implemented using python's asyncio library, so you'll need to turn on Undine's async support to use them. In most cases, using DataLoaders to optimize database queries is not necessary, as Undine's Optimizer already handles this for you.","title":"DataLoaders"},{"location":"dataloaders/#dataloader","text":"A DataLoader always requires a \"load function\" ( load_fn ) which implements the actual logic for fetching data. This function receives a list of \"keys\" that identify the data that should be fetched. Let's look at an example which fetches a list of pokemon from an external API by their name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity return [ response . json () for response in responses ] pokemon_loader = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . load ( name ) Here, the DataLoader load function load_pokemon receives a list of keys (pokemon names in this case) and makes an equal number of concurrent HTTP requests to an external API to fetch these pokemon information. The keys which the load function receives for a given GraphQL operation are defined by calls to DataLoader.load , like in the pokemon_by_name Entrypoint resolver in the above example. Note that the resolver returns a Future object from the DataLoader , and that the function is not async \u2014 this is important for the DataLoader to work correctly. This is discussed more thoroughly in the Technical Details section. Given the above setup, if you query pokemon_by_name multiple times like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { slotOne : pokemonByName ( name : \"pikachu\" ) { id name height weight } slotTwo : pokemonByName ( name : \"eevee\" ) { id name height weight } } The DataLoader will run the load function load_pokemon once with keys [\"pikachu\", \"eevee\"] to fetch pokemon information for both slotOne and slotTwo . Note that the load function needs to return the loaded values in the same order that it received the keys in, so that the values can be matched up with the keys by the DataLoader . You also cannot return less or more values than the number of keys you received.","title":"DataLoader"},{"location":"dataloaders/#returning-errors","text":"If the load for a particular key fails, you can return an exception from the load function for that key. This exception will be converted into a GraphQL error in the response to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon | ValueError ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity msg = \"Pokemon not found\" return [ response . json () if response . status_code == 200 else ValueError ( msg ) for response in responses ] pokemon_by_name = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon | None ]: return pokemon_by_name . load ( name ) Note that in this case the Entrypoint is made nullable so that only the requests for pokemon that fail to load will return null with an error, and the rest will return the loaded pokemon information. For example, given the query we defined above, if load for slotOne fails, the response will be: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"slotOne\" : null , \"slotTwo\" : { \"id\" : 12 , \"name\" : \"eevee\" , \"height\" : 3 , \"weight\" : 65 } }, \"errors\" : [ { \"message\" : \"Pokemon not found\" , \"path\" : [ \"slotOne\" ] } ] }","title":"Returning errors"},{"location":"dataloaders/#max-batch-size","text":"By default, a DataLoader will load all keys requested in a GraphQL operation in a single batch. If you want to limit the number of keys that are loaded in a single batch, you can use the max_batch_size parameter. 1 2 3 4 5 6 7 8 9 10 11 12 from typing import TypedDict from undine import DataLoader class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon , max_batch_size = 10 ) In this case, limiting the maximum batch size will ensure that we don't send too many concurrent requests to the external API, which can help avoid timeouts and rate limits.","title":"Max batch size"},{"location":"dataloaders/#reusing-loads","text":"By default, if a DataLoader receives a request to load the same key multiple times, it will reuse the previous load and share the result between them. For example, if you query the pokemon_by_name Entrypoint with the following query: 1 2 3 4 5 6 7 8 query { slotOne : pokemonByName ( name : \"pikachu\" ) { name } slotTwo : pokemonByName ( name : \"pikachu\" ) { name } } The DataLoader will run the load function load_pokemon once with keys [\"pikachu\"] and reuse the result for both slotOne and slotTwo . Reuse will happen even if the load happens in a different batches when a max_batch_size has been set. If you want to disable reuse, you can set the reuse_loads parameter to False . 1 2 3 4 5 6 7 8 9 10 11 12 from typing import TypedDict from undine import DataLoader class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon , reuse_loads = False ) This will result in the DataLoader running the load function load_pokemon with keys [\"pikachu\", \"pikachu\"] instead, where the first key matches load for slotOne and the second for slotTwo . Note that reused loads should not be treated as a cache, as they are not shared between requests or web service workers. Since load reuse stores Future objects (see Technical Details ), it's much easier to add caching in the load function or in application code using Django's cache API.","title":"Reusing loads"},{"location":"dataloaders/#priming-loads","text":"When DataLoader load reuse is enabled, you can prime the DataLoader with completed load results for specific keys without going through the load function. This way if a load would be requested for a primed key, that primed value would be returned immediately. If batch size is limited using max_batch_size , that load would also not contribute to the size of the batch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon ) pikachu = Pokemon ( id = 25 , name = \"pikachu\" , height = 4 , weight = 60 , ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . prime ( key = \"pikachu\" , value = pikachu ) . load ( name ) Priming can also be useful when loads for the same object can happen by different keys, for example, if loads for a pokemon can happen by the pokemon's name or its ID. In this case, you should also provide a common asyncio.Lock for the DataLoaders so that one load function can run before the other load functions. You might also want to set the can_prime_pending_loads parameter to True so that already pending loads from the other DataLoaders can be set. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 import asyncio from asyncio import Future from typing import TypedDict import httpx from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): id : int name : str height : int weight : int async def load_pokemon_by_id ( keys : list [ int ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_id} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_id = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity data : list [ Pokemon ] = [ response . json () for response in responses ] # Prime the name loader with the fetched data names = [ pokemon [ \"name\" ] for pokemon in data ] pokemon_name_loader . prime_many ( keys = names , values = data , can_prime_pending_loads = True ) return data async def load_pokemon_by_name ( keys : list [ str ]) -> list [ Pokemon ]: base_url = \"https://pokeapi.co/api/v2/pokemon/ {pokemon_name} \" async with httpx . AsyncClient () as client : requests = ( client . get ( base_url . format ( pokemon_name = key )) for key in keys ) responses = await asyncio . gather ( * requests ) # Validation skipped for brevity data : list [ Pokemon ] = [ response . json () for response in responses ] # Prime the ID loader with the fetched data ids = [ pokemon [ \"id\" ] for pokemon in data ] pokemon_id_loader . prime_many ( keys = ids , values = data , can_prime_pending_loads = True ) return data lock = asyncio . Lock () pokemon_id_loader = DataLoader ( load_fn = load_pokemon_by_id , lock = lock ) pokemon_name_loader = DataLoader ( load_fn = load_pokemon_by_name , lock = lock ) class Query ( RootType ): @Entrypoint def pokemon_by_id ( self , info : GQLInfo , id : int ) -> Future [ Pokemon ]: return pokemon_id_loader . load ( id ) @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_name_loader . load ( name )","title":"Priming loads"},{"location":"dataloaders/#clearing-loads","text":"When DataLoader load reuse is enabled, you can also clear reused loads. A potential use case for this would be if a mutation on the loaded data would be performed during the GraphQL operation, and the load would therefore need to be re-fetched. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ str ]) -> list [ Pokemon ]: ... pokemon_loader = DataLoader ( load_fn = load_pokemon ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . clear ( key = name ) . load ( name )","title":"Clearing loads"},{"location":"dataloaders/#custom-key-hash-function","text":"When DataLoader load reuse is enabled, loads are mapped internally by the DataLoader from the load key to a Future object where the load result will be stored once it's available. For the load key to be used as a key in a map, it needs to be hashable, but you can use non-hashable keys by providing a custom key hash function ( key_hash_fn ). A key hash function is also useful when two different objects should be considered equal when loading them using a DataLoader . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from asyncio import Future from typing import TypedDict from undine import DataLoader , Entrypoint , GQLInfo , RootType class Pokemon ( TypedDict ): ... async def load_pokemon ( keys : list [ dict [ str , str ]]) -> list [ Pokemon ]: ... def key_hash_fn ( key : dict [ str , str ]) -> str : return key [ \"name\" ] pokemon_loader = DataLoader ( load_fn = load_pokemon , key_hash_fn = key_hash_fn ) class Query ( RootType ): @Entrypoint def pokemon_by_name ( self , info : GQLInfo , name : str ) -> Future [ Pokemon ]: return pokemon_loader . load ({ \"name\" : name })","title":"Custom key hash function"},{"location":"dataloaders/#technical-details","text":"In this section, we'll go over how Undine's DataLoader works during a GraphQL operation. Knowing these details can help you in debugging DataLoaders , but are not necessary for getting started with them. When a DataLoder is created, it adds a signal receiver for the request_finished signal. This receiver is responsible for clearing the DataLoader's reusable loads when a request finishes, freeing up memory. This ensures that you can reuse the same DataLoader for the next request. DataLoaders can be used in GraphQL resolvers by calling load on them. This creates a new Future that will be set when the data is loaded using the DataLoader load function ( load_fn ). If load reuse is enabled, calling load might also reuse an existing Future created by a previous call to load with the same key. The existing Future is likely pending, but it can be already completed if a maximum batch size has been set and the Future was set in a previous batch, or it can be primed manually. If a reusable load is found, its Future is returned immediately. Otherwise, the DataLoader will check if a new batch needs to be created. New batches are needed when the previous batch has already been dispatched, or when the maximum batch size has been reached. For the first load of a new request, a new batch will always be created. This batch is then scheduled in the event loop as a Task . Whether a call to DataLoder.load returns an existing Future or creates a new one, the resolver should then return that Future . During the execution of a GraphQL operation, when a resolver returns an awaitable value (like a coroutine or Future ), that awaitable is wrapped in a coroutine and saved until all other fields have been resolved. This allows all resolvers to run before any awaitables are awaited, which makes sure that DataLoaders are populated from all resolvers before the event loop next runs and any batches are dispatched. Next, all these resolver coroutines are executed concurrently using gather , which turns them into Tasks and schedules them to run in the event loop. Then, the Future returned by gather is awaited, which hands control back to the event loop. The event loop then decides which order it runs the batch and resolver Tasks . In a resolver Task , the resolver will begin awaiting its awaitable, which in case of DataLoader is the Future returned by the load . In a batch Task , the DataLoader load function is scheduled to run using yet another Task . Additionally, all Futures in the batch that are waiting for results from the load function Task will have a done callback added at this point. This callback will cancel the load function Task if any of the Futures waiting for its results are canceled and all other Futures are also done. This can happen, for example, when a TaskGroup is canceled due to an exception in one of its Tasks . Cancelling the load function Task in this case ensures that it won't use resources that are no longer available (e.g. a database connection). The batch Task then begins awaiting for the load function Task to complete. If multiple DataLoaders are used in the operation, their batch Tasks might also schedule their load function Tasks in the event loop as well. Then each DataLoader's load function Tasks are executed, until they have all finished running. Then execution resumes in the one of the batch Tasks , which sets its Futures with the results from the load function. After a batch Task returns, the resolver Tasks that were waiting for the Futures to be set from this batch can resume and return the Future results. The other batch Tasks will follow suit until each batch and resolver Task has finished running. Finally, the gather Future resolves and fills the response data with the results from each awaitable field resolver.","title":"Technical Details"},{"location":"directives/","text":"Directives \ud83d\udd17 In this section, we'll cover how you can use GraphQL directives in Undine. Directives are a way to add metadata to a GraphQL document or schema, which can be accessed during document execution or by clients consuming your schema. Directive \ud83d\udd17 In Undine, a GraphQL directive is implemented by subclassing the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... Note that a Directive by itself doesn't do anything. It is only used as a way to define additional metadata, which the GraphQL server or client can use at runtime. If the directive implies some behavior, you'll need to add it, e.g., using a ValidationRule . Note that declared Directives are automatically added to the schema, even if they are not used. A Directive always requires the locations it can be used in to be set using the locations argument. The locations can be divided into two categories: executable locations and type system locations . Executable locations \ud83d\udd17 Executable locations identify places in a GraphQL document (i.e. \"request\") where a directive can be used. See the example below on what these locations are. QUERY \ud83d\udd17 The QUERY location corresponds to query operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . QUERY ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query ( $pk : Int !) @ new { task ( pk : $pk ) { pk name done } } MUTATION \ud83d\udd17 The MUTATION location corresponds to mutation operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . MUTATION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 mutation ( $input : CreateTaskMutation !) @ new { createTask ( input : $input ) { pk } } SUBSCRIPTION \ud83d\udd17 The SUBSCRIPTION location corresponds to subscription operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . SUBSCRIPTION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 subscription @ new { comments { username message } } FIELD \ud83d\udd17 The FIELD location corresponds to a field selection on an operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query { task ( pk : 1 ) { pk @new name done } } FRAGMENT_DEFINITION \ud83d\udd17 The FRAGMENT_DEFINITION location corresponds to a fragment definition. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FRAGMENT_DEFINITION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment } } fragment taskFragment on TaskType @new { pk name done } FRAGMENT_SPREAD \ud83d\udd17 The FRAGMENT_SPREAD location corresponds to a fragment spread. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FRAGMENT_SPREAD ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment @new } } fragment taskFragment on TaskType { pk name done } INLINE_FRAGMENT \ud83d\udd17 The INLINE_FRAGMENT location corresponds to an inline fragment. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . INLINE_FRAGMENT ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType @new { name } } } VARIABLE_DEFINITION \ud83d\udd17 The VARIABLE_DEFINITION location corresponds to a variable definition. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . VARIABLE_DEFINITION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query ( $pk : Int ! @new ) { task ( pk : $pk ) { pk name done } } Type system locations \ud83d\udd17 Type system locations identify places in a GraphQL schema (i.e. \"API\") where a directive can be used. Since Undine is used to define the schema, each type system location corresponds to an Undine object that accepts that \"type\" of directive. SCHEMA \ud83d\udd17 The SCHEMA location corresponds to the schema definition itself. Directives can be added here by using the schema_definition_directives argument in the create_schema function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , RootType , create_schema from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . SCHEMA ], schema_name = \"new\" ): ... class Query ( RootType ): @Entrypoint def example ( self , value : str ) -> str : return value schema = create_schema ( query = Query , schema_definition_directives = [ NewDirective ()]) In schema definition: 1 2 3 4 5 directive @new on SCHEMA schema @new { query : Query } SCALAR \ud83d\udd17 The SCALAR location corresponds to the scalars defined in the schema. In Undine, ScalarType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine.directives import Directive from undine.scalars import ScalarType class NewDirective ( Directive , locations = [ DirectiveLocation . SCALAR ], schema_name = \"new\" ): ... vector3_scalar = ScalarType ( name = \"Vector3\" , directives = [ NewDirective ()]) # Alternatively... vector3_scalar_alt = ScalarType ( name = \"Vector3\" ) @ NewDirective () In schema definition: 1 2 3 directive @new on SCALAR scalar Vector3 @new OBJECT \ud83d\udd17 The OBJECT location corresponds to the ObjectTypes defined in the schema. In Undine, QueryTypes and RootTypes accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . OBJECT ], schema_name = \"new\" ): ... class TaskType ( QueryType [ Task ], directives = [ NewDirective ()]): ... class Query ( RootType , directives = [ NewDirective ()]): tasks = Entrypoint ( TaskType , many = True ) # Alternatively... @NewDirective () class TaskTypeAlt ( QueryType [ Task ]): ... @NewDirective () class QueryAlt ( RootType ): tasks = Entrypoint ( TaskType , many = True ) In schema definition: 1 2 3 4 5 6 7 8 9 10 directive @new on OBJECT type TaskType @new { name : String ! createdAt : DateTime ! } type Query @new { tasks : [ TaskType !]! } FIELD_DEFINITION \ud83d\udd17 The FIELD_DEFINITION location corresponds to the fields defined in the schema. In Undine, Fields , InterfaceFields and Entrypoints accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , Field , InterfaceField , InterfaceType , QueryType , RootType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) # Alternatively... name_alt = InterfaceField ( GraphQLNonNull ( GraphQLString )) @ NewDirective () @Named class TaskType ( QueryType [ Task ]): created_at = Field ( directives = [ NewDirective ()]) # Alternatively... created_at_alt = Field () @ NewDirective () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , directives = [ NewDirective ()]) # Alternatively... tasks_alt = Entrypoint ( TaskType , many = True ) @ NewDirective () In schema definition: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 directive @new on FIELD_DEFINITION interface Named { name : String ! @new } type TaskType implements Named { name: String! createdAt: DateTime! @new } type Query { tasks: [TaskType!]! @new } ARGUMENT_DEFINITION \ud83d\udd17 The ARGUMENT_DEFINITION location corresponds to the field arguments defined in the schema. In Undine, CalculationArguments and DirectiveArguments accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from django.db.models import Value from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Calculation , CalculationArgument , DjangoExpression , GQLInfo from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . ARGUMENT_DEFINITION ], schema_name = \"new\" ): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) # Alternatively... value_alt = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @ NewDirective () class Calc ( Calculation [ int ]): value = CalculationArgument ( int , directives = [ NewDirective ()]) # Alternatively... value_alt = CalculationArgument ( int ) @ NewDirective () def __call__ ( self , info : GQLInfo ) -> DjangoExpression : return Value ( self . value ) In schema definition: 1 2 3 4 5 6 7 8 9 10 11 directive @new on ARGUMENT_DEFINITION directive @version ( value: String! @new ) on FIELD_DEFINITION type TaskType { calc ( value : Int ! @ new ) : Int ! } INTERFACE \ud83d\udd17 The INTERFACE location corresponds to the interfaces defined in the schema. In Undine, InterfaceType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ], schema_name = \"new\" ): ... class Named ( InterfaceType , directives = [ NewDirective ()]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) # Alternatively... @NewDirective () class NamedAlt ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) In schema definition: 1 2 3 4 5 directive @new on INTERFACE interface Named @new { name : String ! } UNION \ud83d\udd17 The UNION location corresponds to the unions defined in the schema. In Undine, UnionType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class NewDirective ( Directive , locations = [ DirectiveLocation . UNION ], schema_name = \"new\" ): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObject ( UnionType [ TaskType , ProjectType ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class SearchObjectAlt ( UnionType [ TaskType , ProjectType ]): ... In schema definition: 1 2 3 directive @new on UNION union SearchObject @new = TaskType | ProjectType ENUM \ud83d\udd17 The ENUM location corresponds to the enums defined in the schema. In Undine, OrderSet accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation from undine import OrderSet from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . ENUM ], schema_name = \"new\" ): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class TaskOrderSetAlt ( OrderSet [ Task ]): ... In schema definition: 1 2 3 4 5 6 directive @new on ENUM enum TaskOrderSet @new { nameAsc nameDesc } ENUM_VALUE \ud83d\udd17 The ENUM_VALUE location corresponds to the enum values defined in the schema. In Undine, Order accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ], schema_name = \"new\" ): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" , directives = [ NewDirective ()]) # Alternatively... name_alt = Order ( \"name\" ) @ NewDirective () In schema definition: 1 2 3 4 5 6 directive @new on ENUM_VALUE enum TaskOrderSet { nameAsc @new nameDesc @new } INPUT_OBJECT \ud83d\udd17 The INPUT_OBJECT location corresponds to the input objects defined in the schema. In Undine, MutationType and FilterSet accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from graphql import DirectiveLocation from undine import FilterSet , MutationType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ], schema_name = \"new\" ): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ NewDirective ()]): ... class CreateTaskMutation ( MutationType [ Task ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class TaskFilterSetAlt ( FilterSet [ Task ]): ... @NewDirective () class CreateTaskMutationAlt ( MutationType [ Task ]): ... In schema definition: 1 2 3 4 5 6 7 8 9 directive @new on INPUT_OBJECT input TaskFilterSet @new { name : String } input TaskCreateMutation @new { name : String } INPUT_FIELD_DEFINITION \ud83d\udd17 The INPUT_FIELD_DEFINITION location corresponds to the input field definitions defined in the schema. In Undine, Input and Filter accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from graphql import DirectiveLocation from undine import Filter , FilterSet , Input , MutationType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ], schema_name = \"new\" ): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ NewDirective ()]) # Alternatively... name_alt = Filter () @ NewDirective () class CreateTaskMutation ( MutationType [ Task ]): name = Input ( directives = [ NewDirective ()]) # Alternatively... name_alt = Input () @ NewDirective () In schema definition: 1 2 3 4 5 6 7 8 9 directive @new on INPUT_FIELD_DEFINITION input TaskFilterSet { name : String @new } input TaskCreateMutation { name: String @new } Is repeatable \ud83d\udd17 A directive can be declared as repeatable using the is_repeatable argument. This means that the directive can be used multiple times in the same location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" , is_repeatable = True , ): ... class Query ( RootType ): @Entrypoint ( directives = [ NewDirective (), NewDirective ()]) def example ( self ) -> str : return \"Example\" # Alternatively... @NewDirective () @NewDirective () @Entrypoint () def example_alt ( self ) -> str : return \"Example\" In schema definition: 1 2 3 4 5 directive @new repeatable on FIELD_DEFINITION type Query { example : String ! @new @new } Schema name \ud83d\udd17 By default, the name of the generated GraphQL directive for a Directive class is the name of the Directive class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): ... Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Directive from certain users by using the __is_visible__ method. Hiding the Directive means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Directive didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation from undine.directives import Directive from undine.typing import DjangoRequestProtocol class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): @classmethod def __visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. Extensions \ud83d\udd17 You can provide custom extensions for the Directive by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Directive . 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ... Directive extensions are made available in the GraphQL directive extensions after the schema is created. The Directive itself is found in the GraphQL directive extensions under a key defined by the DIRECTIVE_EXTENSIONS_KEY setting. DirectiveArgument \ud83d\udd17 A Directive can optionally have a number of DirectiveArguments defined in the class body. These define the arguments that can or must be used with the directive. A DirectiveArgument always requires input type of the argument, which needs to be a GraphQL input type. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) Schema name \ud83d\udd17 By default, the name of the GraphQL directive argument generated from a DirectiveArgument is the same as the name of the DirectiveArgument on the Directive class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the GraphQL directive argument separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), schema_name = \"value\" ) This can be useful when the desired name of the GraphQL directive argument is a Python keyword and cannot be used as the DirectiveArgument attribute name. Description \ud83d\udd17 A description for a DirectiveArgument can be provided in on of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), description = \"Version value.\" ) 2) As class attribute docstring, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) \"\"\"Version value.\"\"\" Default value \ud83d\udd17 A default_value can be provided to set the default value for the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), default_value = \"1.0.0\" ) Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the DirectiveArgument as deprecated. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the DirectiveArgument by providing them using the directives argument. The directive must be usable in the ARGUMENT_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @ NewDirective () Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a DirectiveArgument from certain users by decorating a method with the <arg_name>.visible decorator. Hiding a DirectiveArgument means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the DirectiveArgument didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument from undine.typing import DjangoRequestProtocol class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @value . visible def value_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the DirectiveArgument . The self argument is not an instance of the Directive , but the instance of the DirectiveArgument that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. Extensions \ud83d\udd17 You can provide custom extensions for the DirectiveArgument by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) DirectiveArgument extensions are made available in the GraphQL argument extensions after the schema is created. The DirectiveArgument itself is found in the GraphQL argument extensions under a key defined by the DIRECTIVE_ARGUMENT_EXTENSIONS_KEY setting.","title":"Directives"},{"location":"directives/#directives","text":"In this section, we'll cover how you can use GraphQL directives in Undine. Directives are a way to add metadata to a GraphQL document or schema, which can be accessed during document execution or by clients consuming your schema.","title":"Directives"},{"location":"directives/#directive","text":"In Undine, a GraphQL directive is implemented by subclassing the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... Note that a Directive by itself doesn't do anything. It is only used as a way to define additional metadata, which the GraphQL server or client can use at runtime. If the directive implies some behavior, you'll need to add it, e.g., using a ValidationRule . Note that declared Directives are automatically added to the schema, even if they are not used. A Directive always requires the locations it can be used in to be set using the locations argument. The locations can be divided into two categories: executable locations and type system locations .","title":"Directive"},{"location":"directives/#executable-locations","text":"Executable locations identify places in a GraphQL document (i.e. \"request\") where a directive can be used. See the example below on what these locations are.","title":"Executable locations"},{"location":"directives/#query","text":"The QUERY location corresponds to query operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . QUERY ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query ( $pk : Int !) @ new { task ( pk : $pk ) { pk name done } }","title":"QUERY"},{"location":"directives/#mutation","text":"The MUTATION location corresponds to mutation operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . MUTATION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 mutation ( $input : CreateTaskMutation !) @ new { createTask ( input : $input ) { pk } }","title":"MUTATION"},{"location":"directives/#subscription","text":"The SUBSCRIPTION location corresponds to subscription operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . SUBSCRIPTION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 subscription @ new { comments { username message } }","title":"SUBSCRIPTION"},{"location":"directives/#field","text":"The FIELD location corresponds to a field selection on an operation. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query { task ( pk : 1 ) { pk @new name done } }","title":"FIELD"},{"location":"directives/#fragment_definition","text":"The FRAGMENT_DEFINITION location corresponds to a fragment definition. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FRAGMENT_DEFINITION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment } } fragment taskFragment on TaskType @new { pk name done }","title":"FRAGMENT_DEFINITION"},{"location":"directives/#fragment_spread","text":"The FRAGMENT_SPREAD location corresponds to a fragment spread. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FRAGMENT_SPREAD ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment @new } } fragment taskFragment on TaskType { pk name done }","title":"FRAGMENT_SPREAD"},{"location":"directives/#inline_fragment","text":"The INLINE_FRAGMENT location corresponds to an inline fragment. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . INLINE_FRAGMENT ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType @new { name } } }","title":"INLINE_FRAGMENT"},{"location":"directives/#variable_definition","text":"The VARIABLE_DEFINITION location corresponds to a variable definition. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . VARIABLE_DEFINITION ], schema_name = \"new\" ): ... In schema definition: 1 2 3 4 5 6 7 query ( $pk : Int ! @new ) { task ( pk : $pk ) { pk name done } }","title":"VARIABLE_DEFINITION"},{"location":"directives/#type-system-locations","text":"Type system locations identify places in a GraphQL schema (i.e. \"API\") where a directive can be used. Since Undine is used to define the schema, each type system location corresponds to an Undine object that accepts that \"type\" of directive.","title":"Type system locations"},{"location":"directives/#schema","text":"The SCHEMA location corresponds to the schema definition itself. Directives can be added here by using the schema_definition_directives argument in the create_schema function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , RootType , create_schema from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . SCHEMA ], schema_name = \"new\" ): ... class Query ( RootType ): @Entrypoint def example ( self , value : str ) -> str : return value schema = create_schema ( query = Query , schema_definition_directives = [ NewDirective ()]) In schema definition: 1 2 3 4 5 directive @new on SCHEMA schema @new { query : Query }","title":"SCHEMA"},{"location":"directives/#scalar","text":"The SCALAR location corresponds to the scalars defined in the schema. In Undine, ScalarType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine.directives import Directive from undine.scalars import ScalarType class NewDirective ( Directive , locations = [ DirectiveLocation . SCALAR ], schema_name = \"new\" ): ... vector3_scalar = ScalarType ( name = \"Vector3\" , directives = [ NewDirective ()]) # Alternatively... vector3_scalar_alt = ScalarType ( name = \"Vector3\" ) @ NewDirective () In schema definition: 1 2 3 directive @new on SCALAR scalar Vector3 @new","title":"SCALAR"},{"location":"directives/#object","text":"The OBJECT location corresponds to the ObjectTypes defined in the schema. In Undine, QueryTypes and RootTypes accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . OBJECT ], schema_name = \"new\" ): ... class TaskType ( QueryType [ Task ], directives = [ NewDirective ()]): ... class Query ( RootType , directives = [ NewDirective ()]): tasks = Entrypoint ( TaskType , many = True ) # Alternatively... @NewDirective () class TaskTypeAlt ( QueryType [ Task ]): ... @NewDirective () class QueryAlt ( RootType ): tasks = Entrypoint ( TaskType , many = True ) In schema definition: 1 2 3 4 5 6 7 8 9 10 directive @new on OBJECT type TaskType @new { name : String ! createdAt : DateTime ! } type Query @new { tasks : [ TaskType !]! }","title":"OBJECT"},{"location":"directives/#field_definition","text":"The FIELD_DEFINITION location corresponds to the fields defined in the schema. In Undine, Fields , InterfaceFields and Entrypoints accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , Field , InterfaceField , InterfaceType , QueryType , RootType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) # Alternatively... name_alt = InterfaceField ( GraphQLNonNull ( GraphQLString )) @ NewDirective () @Named class TaskType ( QueryType [ Task ]): created_at = Field ( directives = [ NewDirective ()]) # Alternatively... created_at_alt = Field () @ NewDirective () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , directives = [ NewDirective ()]) # Alternatively... tasks_alt = Entrypoint ( TaskType , many = True ) @ NewDirective () In schema definition: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 directive @new on FIELD_DEFINITION interface Named { name : String ! @new } type TaskType implements Named { name: String! createdAt: DateTime! @new } type Query { tasks: [TaskType!]! @new }","title":"FIELD_DEFINITION"},{"location":"directives/#argument_definition","text":"The ARGUMENT_DEFINITION location corresponds to the field arguments defined in the schema. In Undine, CalculationArguments and DirectiveArguments accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from django.db.models import Value from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Calculation , CalculationArgument , DjangoExpression , GQLInfo from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . ARGUMENT_DEFINITION ], schema_name = \"new\" ): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) # Alternatively... value_alt = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @ NewDirective () class Calc ( Calculation [ int ]): value = CalculationArgument ( int , directives = [ NewDirective ()]) # Alternatively... value_alt = CalculationArgument ( int ) @ NewDirective () def __call__ ( self , info : GQLInfo ) -> DjangoExpression : return Value ( self . value ) In schema definition: 1 2 3 4 5 6 7 8 9 10 11 directive @new on ARGUMENT_DEFINITION directive @version ( value: String! @new ) on FIELD_DEFINITION type TaskType { calc ( value : Int ! @ new ) : Int ! }","title":"ARGUMENT_DEFINITION"},{"location":"directives/#interface","text":"The INTERFACE location corresponds to the interfaces defined in the schema. In Undine, InterfaceType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ], schema_name = \"new\" ): ... class Named ( InterfaceType , directives = [ NewDirective ()]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) # Alternatively... @NewDirective () class NamedAlt ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) In schema definition: 1 2 3 4 5 directive @new on INTERFACE interface Named @new { name : String ! }","title":"INTERFACE"},{"location":"directives/#union","text":"The UNION location corresponds to the unions defined in the schema. In Undine, UnionType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class NewDirective ( Directive , locations = [ DirectiveLocation . UNION ], schema_name = \"new\" ): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObject ( UnionType [ TaskType , ProjectType ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class SearchObjectAlt ( UnionType [ TaskType , ProjectType ]): ... In schema definition: 1 2 3 directive @new on UNION union SearchObject @new = TaskType | ProjectType","title":"UNION"},{"location":"directives/#enum","text":"The ENUM location corresponds to the enums defined in the schema. In Undine, OrderSet accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation from undine import OrderSet from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . ENUM ], schema_name = \"new\" ): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class TaskOrderSetAlt ( OrderSet [ Task ]): ... In schema definition: 1 2 3 4 5 6 directive @new on ENUM enum TaskOrderSet @new { nameAsc nameDesc }","title":"ENUM"},{"location":"directives/#enum_value","text":"The ENUM_VALUE location corresponds to the enum values defined in the schema. In Undine, Order accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ], schema_name = \"new\" ): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" , directives = [ NewDirective ()]) # Alternatively... name_alt = Order ( \"name\" ) @ NewDirective () In schema definition: 1 2 3 4 5 6 directive @new on ENUM_VALUE enum TaskOrderSet { nameAsc @new nameDesc @new }","title":"ENUM_VALUE"},{"location":"directives/#input_object","text":"The INPUT_OBJECT location corresponds to the input objects defined in the schema. In Undine, MutationType and FilterSet accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from graphql import DirectiveLocation from undine import FilterSet , MutationType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ], schema_name = \"new\" ): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ NewDirective ()]): ... class CreateTaskMutation ( MutationType [ Task ], directives = [ NewDirective ()]): ... # Alternatively... @NewDirective () class TaskFilterSetAlt ( FilterSet [ Task ]): ... @NewDirective () class CreateTaskMutationAlt ( MutationType [ Task ]): ... In schema definition: 1 2 3 4 5 6 7 8 9 directive @new on INPUT_OBJECT input TaskFilterSet @new { name : String } input TaskCreateMutation @new { name : String }","title":"INPUT_OBJECT"},{"location":"directives/#input_field_definition","text":"The INPUT_FIELD_DEFINITION location corresponds to the input field definitions defined in the schema. In Undine, Input and Filter accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from graphql import DirectiveLocation from undine import Filter , FilterSet , Input , MutationType from undine.directives import Directive from .models import Task class NewDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ], schema_name = \"new\" ): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ NewDirective ()]) # Alternatively... name_alt = Filter () @ NewDirective () class CreateTaskMutation ( MutationType [ Task ]): name = Input ( directives = [ NewDirective ()]) # Alternatively... name_alt = Input () @ NewDirective () In schema definition: 1 2 3 4 5 6 7 8 9 directive @new on INPUT_FIELD_DEFINITION input TaskFilterSet { name : String @new } input TaskCreateMutation { name: String @new }","title":"INPUT_FIELD_DEFINITION"},{"location":"directives/#is-repeatable","text":"A directive can be declared as repeatable using the is_repeatable argument. This means that the directive can be used multiple times in the same location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" , is_repeatable = True , ): ... class Query ( RootType ): @Entrypoint ( directives = [ NewDirective (), NewDirective ()]) def example ( self ) -> str : return \"Example\" # Alternatively... @NewDirective () @NewDirective () @Entrypoint () def example_alt ( self ) -> str : return \"Example\" In schema definition: 1 2 3 4 5 directive @new repeatable on FIELD_DEFINITION type Query { example : String ! @new @new }","title":"Is repeatable"},{"location":"directives/#schema-name","text":"By default, the name of the generated GraphQL directive for a Directive class is the name of the Directive class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): ...","title":"Schema name"},{"location":"directives/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Directive from certain users by using the __is_visible__ method. Hiding the Directive means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Directive didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation from undine.directives import Directive from undine.typing import DjangoRequestProtocol class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): @classmethod def __visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"directives/#extensions","text":"You can provide custom extensions for the Directive by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Directive . 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ... Directive extensions are made available in the GraphQL directive extensions after the schema is created. The Directive itself is found in the GraphQL directive extensions under a key defined by the DIRECTIVE_EXTENSIONS_KEY setting.","title":"Extensions"},{"location":"directives/#directiveargument","text":"A Directive can optionally have a number of DirectiveArguments defined in the class body. These define the arguments that can or must be used with the directive. A DirectiveArgument always requires input type of the argument, which needs to be a GraphQL input type. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ))","title":"DirectiveArgument"},{"location":"directives/#schema-name_1","text":"By default, the name of the GraphQL directive argument generated from a DirectiveArgument is the same as the name of the DirectiveArgument on the Directive class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the GraphQL directive argument separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), schema_name = \"value\" ) This can be useful when the desired name of the GraphQL directive argument is a Python keyword and cannot be used as the DirectiveArgument attribute name.","title":"Schema name"},{"location":"directives/#description","text":"A description for a DirectiveArgument can be provided in on of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), description = \"Version value.\" ) 2) As class attribute docstring, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) \"\"\"Version value.\"\"\"","title":"Description"},{"location":"directives/#default-value","text":"A default_value can be provided to set the default value for the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), default_value = \"1.0.0\" )","title":"Default value"},{"location":"directives/#deprecation-reason","text":"A deprecation_reason can be provided to mark the DirectiveArgument as deprecated. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"directives/#directives_1","text":"You can add directives to the DirectiveArgument by providing them using the directives argument. The directive must be usable in the ARGUMENT_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ NewDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @ NewDirective ()","title":"Directives"},{"location":"directives/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a DirectiveArgument from certain users by decorating a method with the <arg_name>.visible decorator. Hiding a DirectiveArgument means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the DirectiveArgument didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument from undine.typing import DjangoRequestProtocol class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) @value . visible def value_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the DirectiveArgument . The self argument is not an instance of the Directive , but the instance of the DirectiveArgument that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"directives/#extensions_1","text":"You can provide custom extensions for the DirectiveArgument by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) DirectiveArgument extensions are made available in the GraphQL argument extensions after the schema is created. The DirectiveArgument itself is found in the GraphQL argument extensions under a key defined by the DIRECTIVE_ARGUMENT_EXTENSIONS_KEY setting.","title":"Extensions"},{"location":"faq/","text":"FAQ \ud83d\udd17 Here are some common questions you might have when it comes to using Undine or why it's designed the way it is. If you don't find an answer here, please ask a question on the discussion page . Why are all the methods dunder method on, e.g., the QueryType class? \ud83d\udd17 This is to avoid name collisions with possible names of Fields that can be added to the class body of a QueryType class. In GraphQL, all names starting with two underscores are reserved by GraphQL, e.g. __typename , so by this logic, all dunder methods cannot collide with any fields you might want.","title":"FAQ"},{"location":"faq/#faq","text":"Here are some common questions you might have when it comes to using Undine or why it's designed the way it is. If you don't find an answer here, please ask a question on the discussion page .","title":"FAQ"},{"location":"faq/#why-are-all-the-methods-dunder-method-on-eg-the-querytype-class","text":"This is to avoid name collisions with possible names of Fields that can be added to the class body of a QueryType class. In GraphQL, all names starting with two underscores are reserved by GraphQL, e.g. __typename , so by this logic, all dunder methods cannot collide with any fields you might want.","title":"Why are all the methods dunder method on, e.g., the QueryType class?"},{"location":"file-upload/","text":"File Upload \ud83d\udd17 In this section, we'll cover the everything necessary for adding support for file uploads to your GraphQL schema using the GraphQL multipart request specification . Setup \ud83d\udd17 Undine supports file uploads, but they disabled by default due to security reasons. Specifically, since file uploads are sent using a multipart/form-data request, they may be sent without a CORS preflight request if the browser determines the requests meets the criteria for a \"simple request\" . Therefore, you should make sure CSRF protection is enabled on the GraphQL endpoint if you want to use file uploads. This can be done by making sure that The GraphQL view is decorated with @csrf_protect , OR CsrfViewMiddleware exists in your MIDDLEWARE setting (and the GraphQL view is not decorated with @csrf_exempt ) 1 2 3 4 5 MIDDLEWARE = [ # ... \"django.middleware.csrf.CsrfViewMiddleware\" , # ... ] Then you can enable file uploads by adding the following to your settings: 1 2 3 UNDINE = { \"FILE_UPLOAD_ENABLED\" : True , } Uploading files \ud83d\udd17 Undine has two Scalars for uploading files: File and Image . They correspond to Django's FileField and ImageField respectively. The File scalar if for general files while the Image scalar validates that the file is an image file. Like Django's ImageField , using the Image scalar requires the Pillow library to be installed. You can install it together with Undine using pip install undine[image] . Now, let's suppose you have the following Model. 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) image = models . ImageField () If you add a create mutation to the GraphQL schema like this 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) ...the TaskCreateMutation mutation InputObjectType will look like this: 1 2 3 4 input TaskCreateMutation { name : String ! image : Image ! } Now the client can send a request that conforms to the GraphQL multipart request specification , and Undine's GraphQL view will parse the request and slot the files into the correct locations in the input data. Example request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 POST /graphql/ HTTP/1.1 Content-Type: multipart/form-data; boundary=--BoUnDaRyStRiNg Content-Length: 490 --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"operations\" {\"query\": \"mutation($input: TaskCreateMutation!) { createTask(input: $input) { pk } }\", \"variables\": {\"input\": {\"name\": \"Task\", \"image\": null}}} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"map\" {\"0\": [\"variables.input.image\"]} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"0\"; filename=\"image.png\" \\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x02\\x00\\x00\\x00\\x90wS\\xde\\x00\\x00\\x00\\x0cIDATx\\x01c```\\x00\\x00\\x00\\x04\\x00\\x01\\xe4\\x94\\x84\\x06\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82 --BoUnDaRyStRiNg-- See the Implementations section in the GraphQL multipart request specification for client side libraries that support file uploads.","title":"File Upload"},{"location":"file-upload/#file-upload","text":"In this section, we'll cover the everything necessary for adding support for file uploads to your GraphQL schema using the GraphQL multipart request specification .","title":"File Upload"},{"location":"file-upload/#setup","text":"Undine supports file uploads, but they disabled by default due to security reasons. Specifically, since file uploads are sent using a multipart/form-data request, they may be sent without a CORS preflight request if the browser determines the requests meets the criteria for a \"simple request\" . Therefore, you should make sure CSRF protection is enabled on the GraphQL endpoint if you want to use file uploads. This can be done by making sure that The GraphQL view is decorated with @csrf_protect , OR CsrfViewMiddleware exists in your MIDDLEWARE setting (and the GraphQL view is not decorated with @csrf_exempt ) 1 2 3 4 5 MIDDLEWARE = [ # ... \"django.middleware.csrf.CsrfViewMiddleware\" , # ... ] Then you can enable file uploads by adding the following to your settings: 1 2 3 UNDINE = { \"FILE_UPLOAD_ENABLED\" : True , }","title":"Setup"},{"location":"file-upload/#uploading-files","text":"Undine has two Scalars for uploading files: File and Image . They correspond to Django's FileField and ImageField respectively. The File scalar if for general files while the Image scalar validates that the file is an image file. Like Django's ImageField , using the Image scalar requires the Pillow library to be installed. You can install it together with Undine using pip install undine[image] . Now, let's suppose you have the following Model. 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) image = models . ImageField () If you add a create mutation to the GraphQL schema like this 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) ...the TaskCreateMutation mutation InputObjectType will look like this: 1 2 3 4 input TaskCreateMutation { name : String ! image : Image ! } Now the client can send a request that conforms to the GraphQL multipart request specification , and Undine's GraphQL view will parse the request and slot the files into the correct locations in the input data. Example request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 POST /graphql/ HTTP/1.1 Content-Type: multipart/form-data; boundary=--BoUnDaRyStRiNg Content-Length: 490 --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"operations\" {\"query\": \"mutation($input: TaskCreateMutation!) { createTask(input: $input) { pk } }\", \"variables\": {\"input\": {\"name\": \"Task\", \"image\": null}}} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"map\" {\"0\": [\"variables.input.image\"]} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"0\"; filename=\"image.png\" \\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x02\\x00\\x00\\x00\\x90wS\\xde\\x00\\x00\\x00\\x0cIDATx\\x01c```\\x00\\x00\\x00\\x04\\x00\\x01\\xe4\\x94\\x84\\x06\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82 --BoUnDaRyStRiNg-- See the Implementations section in the GraphQL multipart request specification for client side libraries that support file uploads.","title":"Uploading files"},{"location":"filtering/","text":"Filtering \ud83d\udd17 In this section, we'll cover the everything necessary for filtering results returned by your QueryTypes . FilterSet \ud83d\udd17 A FilterSet is a collection of Filter objects that represents an InputObjectType in the GraphQL schema. When added to a QueryType , it creates an input argument (as determined by the QUERY_TYPE_FILTER_INPUT_KEY setting) on any list Entrypoint or many-related Field that is created using that QueryType . That input can then be used to filter the results returned by the Entrypoint or Field . A basic FilterSet is created by subclassing FilterSet and adding a Django Model to it as a generic type parameter. You must also add at least one Filter to the class body of the FilterSet . Then the FilterSet can be added to a QueryType using the filterset argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): name = Field () You can also add the FilterSet to the QueryType using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @TaskFilterSet class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 A FilterSet can automatically introspect its Django Model and convert the Model's fields to Filters on the FilterSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) An auto-generated FilterSet will have all of the Task Model's fields and those fields' lookups translated into input arguments. Here is the generated InputObjectType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 input TaskFilterSet { createdAt : DateTime createdAtDate : Date createdAtDateGt : Date createdAtDateGte : Date createdAtDateIn : [ Date !] createdAtDateLt : Date createdAtDateLte : Date createdAtDateRange : [ Date !] createdAtDay : Int createdAtDayContains : Int createdAtDayEndsWith : Int createdAtDayGt : Int createdAtDayGte : Int createdAtDayIn : [ Int !] createdAtDayLt : Int createdAtDayLte : Int createdAtDayRange : [ Int !] createdAtDayStartsWith : Int createdAtGt : DateTime createdAtGte : DateTime createdAtHour : Int createdAtHourContains : Int createdAtHourEndsWith : Int createdAtHourGt : Int createdAtHourGte : Int createdAtHourIn : [ Int !] createdAtHourLt : Int createdAtHourLte : Int createdAtHourRange : [ Int !] createdAtHourStartsWith : Int createdAtIn : [ DateTime !] createdAtIsoWeekDay : Int createdAtIsoWeekDayContains : Int createdAtIsoWeekDayEndsWith : Int createdAtIsoWeekDayGt : Int createdAtIsoWeekDayGte : Int createdAtIsoWeekDayIn : [ Int !] createdAtIsoWeekDayLt : Int createdAtIsoWeekDayLte : Int createdAtIsoWeekDayRange : [ Int !] createdAtIsoWeekDayStartsWith : Int createdAtIsoYear : Int createdAtIsoYearContains : Int createdAtIsoYearEndsWith : Int createdAtIsoYearGt : Int createdAtIsoYearGte : Int createdAtIsoYearIn : [ Int !] createdAtIsoYearLt : Int createdAtIsoYearLte : Int createdAtIsoYearRange : [ Int !] createdAtIsoYearStartsWith : Int createdAtLt : DateTime createdAtLte : DateTime createdAtMinute : Int createdAtMinuteContains : Int createdAtMinuteEndsWith : Int createdAtMinuteGt : Int createdAtMinuteGte : Int createdAtMinuteIn : [ Int !] createdAtMinuteLt : Int createdAtMinuteLte : Int createdAtMinuteRange : [ Int !] createdAtMinuteStartsWith : Int createdAtMonth : Int createdAtMonthContains : Int createdAtMonthEndsWith : Int createdAtMonthGt : Int createdAtMonthGte : Int createdAtMonthIn : [ Int !] createdAtMonthLt : Int createdAtMonthLte : Int createdAtMonthRange : [ Int !] createdAtMonthStartsWith : Int createdAtQuarter : Int createdAtQuarterContains : Int createdAtQuarterEndsWith : Int createdAtQuarterGt : Int createdAtQuarterGte : Int createdAtQuarterIn : [ Int !] createdAtQuarterLt : Int createdAtQuarterLte : Int createdAtQuarterRange : [ Int !] createdAtQuarterStartsWith : Int createdAtRange : [ DateTime !] createdAtSecond : Int createdAtSecondContains : Int createdAtSecondEndsWith : Int createdAtSecondGt : Int createdAtSecondGte : Int createdAtSecondIn : [ Int !] createdAtSecondLt : Int createdAtSecondLte : Int createdAtSecondRange : [ Int !] createdAtSecondStartsWith : Int createdAtTime : Time createdAtTimeContains : Time createdAtTimeEndsWith : Time createdAtTimeGt : Time createdAtTimeGte : Time createdAtTimeIn : [ Time !] createdAtTimeLt : Time createdAtTimeLte : Time createdAtTimeRange : [ Time !] createdAtTimeStartsWith : Time createdAtWeek : Int createdAtWeekContains : Int createdAtWeekDay : Int createdAtWeekDayContains : Int createdAtWeekDayEndsWith : Int createdAtWeekDayGt : Int createdAtWeekDayGte : Int createdAtWeekDayIn : [ Int !] createdAtWeekDayLt : Int createdAtWeekDayLte : Int createdAtWeekDayRange : [ Int !] createdAtWeekDayStartsWith : Int createdAtWeekEndsWith : Int createdAtWeekGt : Int createdAtWeekGte : Int createdAtWeekIn : [ Int !] createdAtWeekLt : Int createdAtWeekLte : Int createdAtWeekRange : [ Int !] createdAtWeekStartsWith : Int createdAtYear : Int createdAtYearContains : Int createdAtYearEndsWith : Int createdAtYearGt : Int createdAtYearGte : Int createdAtYearIn : [ Int !] createdAtYearLt : Int createdAtYearLte : Int createdAtYearRange : [ Int !] createdAtYearStartsWith : Int done : Boolean name : String nameContains : String nameContainsExact : String nameEndsWith : String nameEndsWithExact : String nameExact : String nameIn : [ String !] nameStartsWith : String nameStartsWithExact : String pk : Int pkContains : Int pkEndsWith : Int pkGt : Int pkGte : Int pkIn : [ Int !] pkLt : Int pkLte : Int pkRange : [ Int !] pkStartsWith : Int project : Int projectGt : Int projectGte : Int projectIn : [ Int !] projectIsNull : Boolean projectLt : Int projectLte : Int NOT : TaskFilterSet AND : TaskFilterSet OR : TaskFilterSet XOR : TaskFilterSet } About Filter names Usually the names of the Filters generated by auto-generation correspond to the lookup in Django, but for text-based fields, names are changed slightly to lean towards using case-insensitive lookups first: Filter name uses __iexact and nameExact uses __exact . Similarly, nameStartsWith uses __istartswith while nameStartsWithExact uses __startswith , etc. To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the FilterSet class definition. With this, you can leave the FilterSet class body empty. 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True , exclude = [ \"created_at\" ]): ... You can also exclude specific model lookups, e.g. created_at__gte . Logical operators \ud83d\udd17 A FilterSet always provides the logical operators NOT , AND , OR , XOR , allowing users to freely create more complex filter conditions from defined Filters . Let's assume you've added an auto-generated TaskFilterSet for a QueryType named TaskType . Normally, when multiple Filters are used, you'll get results that match all filter conditions. 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameStartsWith : \"a\" done : true } ) { name } } By putting the filter conditions inside an OR block, we can get results that match any of the conditions. 1 2 3 4 5 6 7 8 9 10 11 12 query { tasks ( filter : { OR : { nameStartsWith : \"a\" done : true } } ) { name } } Note that only the results inside the conditional block will use that logical combinator. For example, in the following example, only tasks that contains an \"e\" AND EITHER start with \"a\" OR are done will be returned: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { nameContains : \"e\" OR : { nameStartsWith : \"a\" done : true } } ) { name } } Filter queryset \ud83d\udd17 In addition to Filters , FilterSet also includes a __filter_queryset__ classmethod, which can be used to add filtering that should always be applied when fetching objects through QueryTypes using the given FilterSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_staff : return queryset . none () return queryset Note that QueryTypes also have a __filter_queryset__ classmethod, which is run before any FilterSet Filters , and that FilterSet's __filter_queryset__ is run after . See the Optimizer's order of operations for more details. Schema name \ud83d\udd17 By default, the name of the generated GraphQL InputObjectType for a FilterSet class is the name of the FilterSet class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], schema_name = \"TaskFilterInput\" ): name = Filter () Description \ud83d\udd17 You can provide a description for a FilterSet by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): \"\"\"Description.\"\"\" name = Filter () Directives \ud83d\udd17 You can add directives to a FilterSet by providing them using the directives argument. The directive must be usable in the INPUT_OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ MyDirective ()]): name = Filter () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... @MyDirective () class TaskFilterSet ( FilterSet [ Task ]): name = Filter () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a FilterSet from certain users by using the __is_visible__ method. Hiding the FilterSet means that it will not be included in introspection queries for that user, and trying to use it in operations will result in an error that looks exactly like the argument for the FilterSet didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the FilterSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the FilterSet . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Filter () FilterSet extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The FilterSet itself is found in the GraphQL InputObjectType extensions under a key defined by the FILTERSET_EXTENSIONS_KEY setting. Filter \ud83d\udd17 A Filter defines a way of filtering the results returned by an Entrypoint or Field using a QueryType . A Filter corresponds to anything that can be passed to a queryset.filter() call, usually a lookup expression on the Django Model of the FilterSet it belongs to. In GraphQL, a Filter represents a GraphQLInputField on an InputObjectType . A Filter always requires a reference from which it will create the proper GraphQL resolver and input type for the Filter . Model field references \ud83d\udd17 For Filters corresponding to Django Model fields, the Filter can be used without passing in a reference, as its attribute name on the FilterSet class body can be used to identify the corresponding Model field. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): title = Filter ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as Filter references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_upper = Filter ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Filter , FilterSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): copies = Filter ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Function references \ud83d\udd17 Functions (or methods) can also be used to create Filters . This can be done by decorating a method with the Filter class. 1 2 3 4 5 6 7 8 9 10 11 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : return Q ( name__iexact = value ) These types of Filters should return a Q expression. The type of the value argument is used as the input type for the Filter , so typing it is required. About method signature The decorated method is treated as a static method by the Filter . The self argument is not an instance of the FilterSet , but the instance of the Filter that is being used. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument is the value provided for the filter. It should always be named \"value\", and is required to be a keyword only argument. Lookup \ud83d\udd17 By default, when a Filter is defined on a FilterSet , the \"exact\" lookup expression is used. This can be changed by providing the lookup argument to the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( lookup = \"icontains\" ) Many \ud83d\udd17 The many argument changes the behavior of a Filter such that it takes a list of values instead of a single value. Then, each of the given values are combined as defined by the match argument to form a single filter condition. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" ) This would create the following filter input: 1 2 3 input TaskFilterSet { name : [ String !] } So if a query is filtered using this filter with the value [\"foo\", \"bar\"] , the filter condition would be Q(name__icontains=\"foo\") | Q(name__icontains=\"bar\") . Match \ud83d\udd17 The match argument changes the behavior of the many argument to combine the provided values with a different operation. The default is any , which means that the filter condition will include an item if it matches any of the provided values. The match argument can be set to all if all of the values should match, or one_of if only one of the values should match. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" , match = \"all\" ) Distinct \ud83d\udd17 If using a Filter would require a call to queryset.distinct() to remove duplicates (e.g. lookups spanning \"to-many\" relations), you can set the distinct argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( distinct = True ) Required \ud83d\udd17 By default, all Filters are non-required (nullable in GraphQL terms). If you want to make a Filter required, you can do so by setting the required argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( required = True ) Making a Filter required means that if any filtering is done on an Entrypoint of related Field using a QueryType with the FilterSet this Filter belongs to, this Filter must be used in addition to any other Filters you might want to use. It must also be used in any logical blocks that users might want to make. Aliases \ud83d\udd17 Sometimes a Filter may require additional expressions to be added as aliases to the queryset when the Filter is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import F , OuterRef , Q from undine import DjangoExpression , Filter , FilterSet , GQLInfo from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): has_more_copies = Filter ( Q ( copies__gt = F ( \"non_copies\" ))) @has_more_copies . aliases def has_more_copies_aliases ( self , info : GQLInfo , * , value : bool ) -> dict [ str , DjangoExpression ]: return { \"copies\" : SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))), \"non_copies\" : SubqueryCount ( Task . objects . exclude ( name = OuterRef ( \"name\" ))), } Empty values \ud83d\udd17 By default, Filters will ignore some values which are considered \"empty\" in the context of filtering. These values are set globally by the EMPTY_VALUES setting. Usually this is what you want, as it allows you to set default values in your GraphQL variables. If you wish to change what's considered an empty value for an individual Filter , you can do so by setting the empty_values argument to a list of values. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): # Allow filtering with the empty string or None title = Filter ( empty_values = []) Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django Model field that the Filter corresponds to. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): field_name = Filter ( field_name = \"name\" ) This can be useful when the Model field corresponding to the Filter has a different name and type in the GraphQL schema than in the Model. Schema name \ud83d\udd17 By default, the name of the InputObjectType field generated from a Filter is the same as the name of the Filter on the FilterSet class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the InputObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( schema_name = \"title\" ) This can be useful when the desired name of the InputObjectType field is a Python keyword and cannot be used as the Input attribute name. Description \ud83d\udd17 By default, a Filter is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( description = \"Get only tasks with the given name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () \"\"\"Get only tasks with the given name.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : \"\"\"Get only tasks with the given name.\"\"\" return Q ( name__iexact = value ) Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Filter as deprecated. This is for documentation purposes only, and does not affect the use of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( deprecation_reason = \"Use something else.\" ) Permissions \ud83d\udd17 You can add permissions check to individual Filters by using Filter functions and adding the permission check inline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import GraphQLPermissionError from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : msg = \"Only authenticated users can filter by task names.\" raise GraphQLPermissionError ( msg ) return Q ( name__icontains = value ) A special EmptyFilterResult exception can also be raised to indicate that an empty queryset should be returned instead of an error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import EmptyFilterResult from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : raise EmptyFilterResult return Q ( name__icontains = value ) Directives \ud83d\udd17 You can add directives to the Filter by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Filter from certain users by decorating a method with the <filter_name>.visible decorator. Hiding a Filter means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Filter didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Filter by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( extensions = { \"foo\" : \"bar\" }) Filter extensions are made available in the GraphQL InputObjectType field extensions after the schema is created. The Filter itself is found in the GraphQL input field extensions under a key defined by the FILTER_EXTENSIONS_KEY setting.","title":"Filtering"},{"location":"filtering/#filtering","text":"In this section, we'll cover the everything necessary for filtering results returned by your QueryTypes .","title":"Filtering"},{"location":"filtering/#filterset","text":"A FilterSet is a collection of Filter objects that represents an InputObjectType in the GraphQL schema. When added to a QueryType , it creates an input argument (as determined by the QUERY_TYPE_FILTER_INPUT_KEY setting) on any list Entrypoint or many-related Field that is created using that QueryType . That input can then be used to filter the results returned by the Entrypoint or Field . A basic FilterSet is created by subclassing FilterSet and adding a Django Model to it as a generic type parameter. You must also add at least one Filter to the class body of the FilterSet . Then the FilterSet can be added to a QueryType using the filterset argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): name = Field () You can also add the FilterSet to the QueryType using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @TaskFilterSet class TaskType ( QueryType [ Task ]): name = Field ()","title":"FilterSet"},{"location":"filtering/#auto-generation","text":"A FilterSet can automatically introspect its Django Model and convert the Model's fields to Filters on the FilterSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) An auto-generated FilterSet will have all of the Task Model's fields and those fields' lookups translated into input arguments. Here is the generated InputObjectType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 input TaskFilterSet { createdAt : DateTime createdAtDate : Date createdAtDateGt : Date createdAtDateGte : Date createdAtDateIn : [ Date !] createdAtDateLt : Date createdAtDateLte : Date createdAtDateRange : [ Date !] createdAtDay : Int createdAtDayContains : Int createdAtDayEndsWith : Int createdAtDayGt : Int createdAtDayGte : Int createdAtDayIn : [ Int !] createdAtDayLt : Int createdAtDayLte : Int createdAtDayRange : [ Int !] createdAtDayStartsWith : Int createdAtGt : DateTime createdAtGte : DateTime createdAtHour : Int createdAtHourContains : Int createdAtHourEndsWith : Int createdAtHourGt : Int createdAtHourGte : Int createdAtHourIn : [ Int !] createdAtHourLt : Int createdAtHourLte : Int createdAtHourRange : [ Int !] createdAtHourStartsWith : Int createdAtIn : [ DateTime !] createdAtIsoWeekDay : Int createdAtIsoWeekDayContains : Int createdAtIsoWeekDayEndsWith : Int createdAtIsoWeekDayGt : Int createdAtIsoWeekDayGte : Int createdAtIsoWeekDayIn : [ Int !] createdAtIsoWeekDayLt : Int createdAtIsoWeekDayLte : Int createdAtIsoWeekDayRange : [ Int !] createdAtIsoWeekDayStartsWith : Int createdAtIsoYear : Int createdAtIsoYearContains : Int createdAtIsoYearEndsWith : Int createdAtIsoYearGt : Int createdAtIsoYearGte : Int createdAtIsoYearIn : [ Int !] createdAtIsoYearLt : Int createdAtIsoYearLte : Int createdAtIsoYearRange : [ Int !] createdAtIsoYearStartsWith : Int createdAtLt : DateTime createdAtLte : DateTime createdAtMinute : Int createdAtMinuteContains : Int createdAtMinuteEndsWith : Int createdAtMinuteGt : Int createdAtMinuteGte : Int createdAtMinuteIn : [ Int !] createdAtMinuteLt : Int createdAtMinuteLte : Int createdAtMinuteRange : [ Int !] createdAtMinuteStartsWith : Int createdAtMonth : Int createdAtMonthContains : Int createdAtMonthEndsWith : Int createdAtMonthGt : Int createdAtMonthGte : Int createdAtMonthIn : [ Int !] createdAtMonthLt : Int createdAtMonthLte : Int createdAtMonthRange : [ Int !] createdAtMonthStartsWith : Int createdAtQuarter : Int createdAtQuarterContains : Int createdAtQuarterEndsWith : Int createdAtQuarterGt : Int createdAtQuarterGte : Int createdAtQuarterIn : [ Int !] createdAtQuarterLt : Int createdAtQuarterLte : Int createdAtQuarterRange : [ Int !] createdAtQuarterStartsWith : Int createdAtRange : [ DateTime !] createdAtSecond : Int createdAtSecondContains : Int createdAtSecondEndsWith : Int createdAtSecondGt : Int createdAtSecondGte : Int createdAtSecondIn : [ Int !] createdAtSecondLt : Int createdAtSecondLte : Int createdAtSecondRange : [ Int !] createdAtSecondStartsWith : Int createdAtTime : Time createdAtTimeContains : Time createdAtTimeEndsWith : Time createdAtTimeGt : Time createdAtTimeGte : Time createdAtTimeIn : [ Time !] createdAtTimeLt : Time createdAtTimeLte : Time createdAtTimeRange : [ Time !] createdAtTimeStartsWith : Time createdAtWeek : Int createdAtWeekContains : Int createdAtWeekDay : Int createdAtWeekDayContains : Int createdAtWeekDayEndsWith : Int createdAtWeekDayGt : Int createdAtWeekDayGte : Int createdAtWeekDayIn : [ Int !] createdAtWeekDayLt : Int createdAtWeekDayLte : Int createdAtWeekDayRange : [ Int !] createdAtWeekDayStartsWith : Int createdAtWeekEndsWith : Int createdAtWeekGt : Int createdAtWeekGte : Int createdAtWeekIn : [ Int !] createdAtWeekLt : Int createdAtWeekLte : Int createdAtWeekRange : [ Int !] createdAtWeekStartsWith : Int createdAtYear : Int createdAtYearContains : Int createdAtYearEndsWith : Int createdAtYearGt : Int createdAtYearGte : Int createdAtYearIn : [ Int !] createdAtYearLt : Int createdAtYearLte : Int createdAtYearRange : [ Int !] createdAtYearStartsWith : Int done : Boolean name : String nameContains : String nameContainsExact : String nameEndsWith : String nameEndsWithExact : String nameExact : String nameIn : [ String !] nameStartsWith : String nameStartsWithExact : String pk : Int pkContains : Int pkEndsWith : Int pkGt : Int pkGte : Int pkIn : [ Int !] pkLt : Int pkLte : Int pkRange : [ Int !] pkStartsWith : Int project : Int projectGt : Int projectGte : Int projectIn : [ Int !] projectIsNull : Boolean projectLt : Int projectLte : Int NOT : TaskFilterSet AND : TaskFilterSet OR : TaskFilterSet XOR : TaskFilterSet } About Filter names Usually the names of the Filters generated by auto-generation correspond to the lookup in Django, but for text-based fields, names are changed slightly to lean towards using case-insensitive lookups first: Filter name uses __iexact and nameExact uses __exact . Similarly, nameStartsWith uses __istartswith while nameStartsWithExact uses __startswith , etc. To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the FilterSet class definition. With this, you can leave the FilterSet class body empty. 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True , exclude = [ \"created_at\" ]): ... You can also exclude specific model lookups, e.g. created_at__gte .","title":"Auto-generation"},{"location":"filtering/#logical-operators","text":"A FilterSet always provides the logical operators NOT , AND , OR , XOR , allowing users to freely create more complex filter conditions from defined Filters . Let's assume you've added an auto-generated TaskFilterSet for a QueryType named TaskType . Normally, when multiple Filters are used, you'll get results that match all filter conditions. 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameStartsWith : \"a\" done : true } ) { name } } By putting the filter conditions inside an OR block, we can get results that match any of the conditions. 1 2 3 4 5 6 7 8 9 10 11 12 query { tasks ( filter : { OR : { nameStartsWith : \"a\" done : true } } ) { name } } Note that only the results inside the conditional block will use that logical combinator. For example, in the following example, only tasks that contains an \"e\" AND EITHER start with \"a\" OR are done will be returned: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { nameContains : \"e\" OR : { nameStartsWith : \"a\" done : true } } ) { name } }","title":"Logical operators"},{"location":"filtering/#filter-queryset","text":"In addition to Filters , FilterSet also includes a __filter_queryset__ classmethod, which can be used to add filtering that should always be applied when fetching objects through QueryTypes using the given FilterSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_staff : return queryset . none () return queryset Note that QueryTypes also have a __filter_queryset__ classmethod, which is run before any FilterSet Filters , and that FilterSet's __filter_queryset__ is run after . See the Optimizer's order of operations for more details.","title":"Filter queryset"},{"location":"filtering/#schema-name","text":"By default, the name of the generated GraphQL InputObjectType for a FilterSet class is the name of the FilterSet class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], schema_name = \"TaskFilterInput\" ): name = Filter ()","title":"Schema name"},{"location":"filtering/#description","text":"You can provide a description for a FilterSet by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): \"\"\"Description.\"\"\" name = Filter ()","title":"Description"},{"location":"filtering/#directives","text":"You can add directives to a FilterSet by providing them using the directives argument. The directive must be usable in the INPUT_OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ MyDirective ()]): name = Filter () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... @MyDirective () class TaskFilterSet ( FilterSet [ Task ]): name = Filter () See the Directives section for more details on directives.","title":"Directives"},{"location":"filtering/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a FilterSet from certain users by using the __is_visible__ method. Hiding the FilterSet means that it will not be included in introspection queries for that user, and trying to use it in operations will result in an error that looks exactly like the argument for the FilterSet didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"filtering/#graphql-extensions","text":"You can provide custom extensions for the FilterSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the FilterSet . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Filter () FilterSet extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The FilterSet itself is found in the GraphQL InputObjectType extensions under a key defined by the FILTERSET_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"filtering/#filter","text":"A Filter defines a way of filtering the results returned by an Entrypoint or Field using a QueryType . A Filter corresponds to anything that can be passed to a queryset.filter() call, usually a lookup expression on the Django Model of the FilterSet it belongs to. In GraphQL, a Filter represents a GraphQLInputField on an InputObjectType . A Filter always requires a reference from which it will create the proper GraphQL resolver and input type for the Filter .","title":"Filter"},{"location":"filtering/#model-field-references","text":"For Filters corresponding to Django Model fields, the Filter can be used without passing in a reference, as its attribute name on the FilterSet class body can be used to identify the corresponding Model field. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): title = Filter ( \"name\" )","title":"Model field references"},{"location":"filtering/#expression-references","text":"Django ORM expressions can also be used as Filter references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_upper = Filter ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Filter , FilterSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): copies = Filter ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"filtering/#function-references","text":"Functions (or methods) can also be used to create Filters . This can be done by decorating a method with the Filter class. 1 2 3 4 5 6 7 8 9 10 11 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : return Q ( name__iexact = value ) These types of Filters should return a Q expression. The type of the value argument is used as the input type for the Filter , so typing it is required. About method signature The decorated method is treated as a static method by the Filter . The self argument is not an instance of the FilterSet , but the instance of the Filter that is being used. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument is the value provided for the filter. It should always be named \"value\", and is required to be a keyword only argument.","title":"Function references"},{"location":"filtering/#lookup","text":"By default, when a Filter is defined on a FilterSet , the \"exact\" lookup expression is used. This can be changed by providing the lookup argument to the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( lookup = \"icontains\" )","title":"Lookup"},{"location":"filtering/#many","text":"The many argument changes the behavior of a Filter such that it takes a list of values instead of a single value. Then, each of the given values are combined as defined by the match argument to form a single filter condition. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" ) This would create the following filter input: 1 2 3 input TaskFilterSet { name : [ String !] } So if a query is filtered using this filter with the value [\"foo\", \"bar\"] , the filter condition would be Q(name__icontains=\"foo\") | Q(name__icontains=\"bar\") .","title":"Many"},{"location":"filtering/#match","text":"The match argument changes the behavior of the many argument to combine the provided values with a different operation. The default is any , which means that the filter condition will include an item if it matches any of the provided values. The match argument can be set to all if all of the values should match, or one_of if only one of the values should match. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" , match = \"all\" )","title":"Match"},{"location":"filtering/#distinct","text":"If using a Filter would require a call to queryset.distinct() to remove duplicates (e.g. lookups spanning \"to-many\" relations), you can set the distinct argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( distinct = True )","title":"Distinct"},{"location":"filtering/#required","text":"By default, all Filters are non-required (nullable in GraphQL terms). If you want to make a Filter required, you can do so by setting the required argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( required = True ) Making a Filter required means that if any filtering is done on an Entrypoint of related Field using a QueryType with the FilterSet this Filter belongs to, this Filter must be used in addition to any other Filters you might want to use. It must also be used in any logical blocks that users might want to make.","title":"Required"},{"location":"filtering/#aliases","text":"Sometimes a Filter may require additional expressions to be added as aliases to the queryset when the Filter is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import F , OuterRef , Q from undine import DjangoExpression , Filter , FilterSet , GQLInfo from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): has_more_copies = Filter ( Q ( copies__gt = F ( \"non_copies\" ))) @has_more_copies . aliases def has_more_copies_aliases ( self , info : GQLInfo , * , value : bool ) -> dict [ str , DjangoExpression ]: return { \"copies\" : SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))), \"non_copies\" : SubqueryCount ( Task . objects . exclude ( name = OuterRef ( \"name\" ))), }","title":"Aliases"},{"location":"filtering/#empty-values","text":"By default, Filters will ignore some values which are considered \"empty\" in the context of filtering. These values are set globally by the EMPTY_VALUES setting. Usually this is what you want, as it allows you to set default values in your GraphQL variables. If you wish to change what's considered an empty value for an individual Filter , you can do so by setting the empty_values argument to a list of values. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): # Allow filtering with the empty string or None title = Filter ( empty_values = [])","title":"Empty values"},{"location":"filtering/#field-name","text":"A field_name can be provided to explicitly set the Django Model field that the Filter corresponds to. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): field_name = Filter ( field_name = \"name\" ) This can be useful when the Model field corresponding to the Filter has a different name and type in the GraphQL schema than in the Model.","title":"Field name"},{"location":"filtering/#schema-name_1","text":"By default, the name of the InputObjectType field generated from a Filter is the same as the name of the Filter on the FilterSet class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the InputObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( schema_name = \"title\" ) This can be useful when the desired name of the InputObjectType field is a Python keyword and cannot be used as the Input attribute name.","title":"Schema name"},{"location":"filtering/#description_1","text":"By default, a Filter is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( description = \"Get only tasks with the given name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () \"\"\"Get only tasks with the given name.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : \"\"\"Get only tasks with the given name.\"\"\" return Q ( name__iexact = value )","title":"Description"},{"location":"filtering/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Filter as deprecated. This is for documentation purposes only, and does not affect the use of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"filtering/#permissions","text":"You can add permissions check to individual Filters by using Filter functions and adding the permission check inline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import GraphQLPermissionError from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : msg = \"Only authenticated users can filter by task names.\" raise GraphQLPermissionError ( msg ) return Q ( name__icontains = value ) A special EmptyFilterResult exception can also be raised to indicate that an empty queryset should be returned instead of an error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import EmptyFilterResult from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : raise EmptyFilterResult return Q ( name__icontains = value )","title":"Permissions"},{"location":"filtering/#directives_1","text":"You can add directives to the Filter by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"filtering/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Filter from certain users by decorating a method with the <filter_name>.visible decorator. Hiding a Filter means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Filter didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"filtering/#graphql-extensions_1","text":"You can provide custom extensions for the Filter by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( extensions = { \"foo\" : \"bar\" }) Filter extensions are made available in the GraphQL InputObjectType field extensions after the schema is created. The Filter itself is found in the GraphQL input field extensions under a key defined by the FILTER_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"getting-started/","text":"Getting Started \ud83d\udd17 New to GraphQL? \ud83d\udd17 It's recommended to read the official GraphQL docs first to get a better understanding of what GraphQL is and how it works, and use the GraphQL spec as a reference when necessary. New to Django? \ud83d\udd17 It's recommended to go through the official Django tutorial first before trying to learn Undine, since these docs assume you have some familiarity with Django. New to Undine? \ud83d\udd17 After going through the installation steps below, we have a tutorial that will walk you through creating a simple GraphQL server using Undine. Undine is built on top of graphql-core , which is port of the GraphQL.js reference implementation of GraphQL. Knowing how graphql-core works can help you understand how Undine works, but is not required to get started. Installation \ud83d\udd17 Undine is available on PyPI and can be installed with pip : 1 pip install undine Next, you'll need to add Undine it to your INSTALLED_APPS setting in your Django project's settings.py file: 1 2 3 4 INSTALLED_APPS = [ # ... \"undine\" , ] To test that Undine is working, you can run the following command: 1 python manage.py check undine You should see the message \"System check identified no issues (0 silenced).\" Undine requires the \"django.contrib.contenttypes\" app to be installed, but there is no need to place \"undine\" in any specific order in the INSTALLED_APPS setting.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#new-to-graphql","text":"It's recommended to read the official GraphQL docs first to get a better understanding of what GraphQL is and how it works, and use the GraphQL spec as a reference when necessary.","title":"New to GraphQL?"},{"location":"getting-started/#new-to-django","text":"It's recommended to go through the official Django tutorial first before trying to learn Undine, since these docs assume you have some familiarity with Django.","title":"New to Django?"},{"location":"getting-started/#new-to-undine","text":"After going through the installation steps below, we have a tutorial that will walk you through creating a simple GraphQL server using Undine. Undine is built on top of graphql-core , which is port of the GraphQL.js reference implementation of GraphQL. Knowing how graphql-core works can help you understand how Undine works, but is not required to get started.","title":"New to Undine?"},{"location":"getting-started/#installation","text":"Undine is available on PyPI and can be installed with pip : 1 pip install undine Next, you'll need to add Undine it to your INSTALLED_APPS setting in your Django project's settings.py file: 1 2 3 4 INSTALLED_APPS = [ # ... \"undine\" , ] To test that Undine is working, you can run the following command: 1 python manage.py check undine You should see the message \"System check identified no issues (0 silenced).\" Undine requires the \"django.contrib.contenttypes\" app to be installed, but there is no need to place \"undine\" in any specific order in the INSTALLED_APPS setting.","title":"Installation"},{"location":"global-object-ids/","text":"Global Object IDs \ud83d\udd17 In this section, we'll cover how you can add support for object refetching and client caching using the Global Object Identification specification. For Relay-compliant clients, see the Connection section for adding support for pagination with Connections . Node Interface \ud83d\udd17 Your QueryTypes can implement the Node interface to add support for Global Object IDs . 1 2 3 4 5 6 7 from undine import QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... This will add an id field to the TaskType for resolving Global Object IDs . 1 2 3 4 5 6 7 8 9 10 interface Node { id : ID ! } type TaskType implements Node { id : ID ! pk : Int ! name : String ! # Rest of the fields... } Note that most Django models already contain an id field for as the primary key of the table, and that implementing this interface will override it with the Global Object ID field. To access the model id field, you can use the pk field instead. Node Entrypoint \ud83d\udd17 A Global Object ID can be used for refetching objects from a special Node Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , QueryType from undine.relay import Connection , Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... class Query ( QueryType ): node = Entrypoint ( Node ) tasks = Entrypoint ( Connection ( TaskType )) To use this Entrypoint , we must first query the schema in some other way, for example using the tasks Connection Entrypoint in the above example. Then, we can use the fetched Global Object ID to refetch the Task from the Node Entrypoint . 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType { name } } } Note that Global Object IDs (e.g. U3Vyc29yOnVzZXJuYW1lOjE= in the above example) are meant to be opaque to the client, meaning they aren't supposed to know what they contain or how to parse them.","title":"Global Object IDs"},{"location":"global-object-ids/#global-object-ids","text":"In this section, we'll cover how you can add support for object refetching and client caching using the Global Object Identification specification. For Relay-compliant clients, see the Connection section for adding support for pagination with Connections .","title":"Global Object IDs"},{"location":"global-object-ids/#node-interface","text":"Your QueryTypes can implement the Node interface to add support for Global Object IDs . 1 2 3 4 5 6 7 from undine import QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... This will add an id field to the TaskType for resolving Global Object IDs . 1 2 3 4 5 6 7 8 9 10 interface Node { id : ID ! } type TaskType implements Node { id : ID ! pk : Int ! name : String ! # Rest of the fields... } Note that most Django models already contain an id field for as the primary key of the table, and that implementing this interface will override it with the Global Object ID field. To access the model id field, you can use the pk field instead.","title":"Node Interface"},{"location":"global-object-ids/#node-entrypoint","text":"A Global Object ID can be used for refetching objects from a special Node Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , QueryType from undine.relay import Connection , Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... class Query ( QueryType ): node = Entrypoint ( Node ) tasks = Entrypoint ( Connection ( TaskType )) To use this Entrypoint , we must first query the schema in some other way, for example using the tasks Connection Entrypoint in the above example. Then, we can use the fetched Global Object ID to refetch the Task from the Node Entrypoint . 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType { name } } } Note that Global Object IDs (e.g. U3Vyc29yOnVzZXJuYW1lOjE= in the above example) are meant to be opaque to the client, meaning they aren't supposed to know what they contain or how to parse them.","title":"Node Entrypoint"},{"location":"hacking-undine/","text":"Hacking Undine \ud83d\udd17 While Undine aims to offer a batteries-included solution for building GraphQL APIs on top of Django, it is designed to be easy to modify and extend to suit the needs of any project. For example, your project may include custom Model fields, or require dates or times to be parsed in a specific way. Converters \ud83d\udd17 In this section, we will go through Undine's many converters, which are used by Undine to process values in various parts of its objects. These converters are implemented using single-dispatch generic functions . A singe-dispatch generic function is a function that has different implementations based on the type of the argument it receives. You can think of it as a dynamic switch statement. You may know the @singledispatch decorator from the python standard library, which implements this pattern. Undine implements its own version of it, which allows for more flexible dispatching. This pattern allows users to override and extend the behavior of any converter without having to modify Undine's code directly. The different converters available are listed below. convert_to_graphql_type \ud83d\udd17 This function is used to convert a value to a GraphQL input or output type. For example, a QueryType Field may be based on a model field, and so the Field needs to know which GraphQL type corresponds to the model's field. In addition to the value to convert, the function also accepts a model parameter, which is the Django Model associated with the value, and a is_input parameter, which is a boolean indicating whether the converter should return an input or output type. convert_to_graphql_argument_map \ud83d\udd17 This function is used to convert a value to a GraphQL argument map. It's used by Fields and Entrypoints to figure out which parameters their GraphQL fields should have. For example, if a QueryType is used in a list Entrypoint , it should get its FilterSet and/or OrderSet as arguments. Similarly, a Connection should get its pagination arguments from this converter. In addition to the value to convert, the function also accepts a many parameter, which is a boolean indicating whether the converter should return a list of arguments or not, and a entrypoint parameter, which is a boolean indicating whether the converter is used in an Entrypoint or not. convert_lookup_to_graphql_type \ud83d\udd17 This function is used to convert a lookup expression to a GraphQL type. It's used in Filters to figure out the Filter's input type after the its lookup expression has been added. For example a __date lookup changes the expected input for a DateTimeField Filter from DateTime to Date . In addition to the lookup expression to convert, the function also accepts a default_type parameter, which is the GraphQLType for the parent field the lookup is for. convert_to_model_field_to_python_type \ud83d\udd17 This function is used to convert a model fields to a Python type. It's used in parsing Model relation types, which are used by various parts of Undine when working with Model relations. convert_to_entrypoint_ref \ud83d\udd17 This function is used by Entrypoints to handle their given reference. Most of the time, registering an implementation for this converter is only required to allow a new kind of Entrypoint reference to be used, but may also be used to add additional handling for the reference. In addition to the value to convert, the function also accepts a caller parameter, which is the Entrypoint instance that is calling this function. This allows the converter to access the Entrypoint's attributes however it sees fit. convert_to_field_ref \ud83d\udd17 This function is used by Fields to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Field instance. convert_to_input_ref \ud83d\udd17 This function is used by Inputs to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Input instance. convert_to_order_ref \ud83d\udd17 This function is used by Orders to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Order instance. convert_to_filter_ref \ud83d\udd17 This function is used by Filters to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Filter instance. convert_to_field_resolver \ud83d\udd17 This function is used to convert a value to a GraphQL field resolver. It's used by Fields to figure out which resolver function should be used to resolve the field during a query. For example, related fields require a different resolver from a regular field. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. convert_to_entrypoint_resolver \ud83d\udd17 This function is the Entrypoint equivalent of the convert_to_field_resolver converter. A separate converter is needed since Entrypoints may resolve differently than Fields , or they can run the Optimizer. convert_to_filter_resolver \ud83d\udd17 This function is used to convert a value to a Filter expression resolver. It's used by Filters to figure out which resolver function should be used for filtering. A Filter resolver function always returns a Django expression. In addition to the value to convert, the function also accepts a caller parameter, which is the Filter instance that is calling this function. convert_to_entrypoint_subscription \ud83d\udd17 This function is used to convert a value to a GraphQL subscription resolver. It's used by Entrypoints to figure out which resolver function should be used for subscriptions. convert_to_description \ud83d\udd17 This function is used to convert a value to a GraphQL description. It's used by Fields , Inputs , Filters and Orders to figure out the description to use for their GraphQL types. For example, the description for a Model field is its help_text attribute. convert_to_default_value \ud83d\udd17 This function is used to convert a value to a GraphQL default value. It's used by Inputs to figure out the default value for their GraphQL types. For example, a Model field's default value is its default attribute. However, a default value is only added to an Input for a create mutation. convert_to_bad_lookups \ud83d\udd17 This function is used to convert a given Model field to a list of lookups that are not supported by the field, even if the given lookup is registered for it. For example, if you check BooleanField.get_lookups() , it show many generic lookups registered for the base Field class, which don't actually work on a BooleanField (e.g. contains or iendswith ). This function is used to remove those lookups when auto-generating Filters for a FilterSet . convert_to_field_complexity \ud83d\udd17 This function is used to convert a Field reference to its complexity value. By default, any reference passed to it has a complexity of 0 if not specified. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. is_field_nullable \ud83d\udd17 This function is used by Fields to determine whether their reference is nullable or not. For example, a Model field reference is nullable if its null attribute is True . In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. is_input_hidden \ud83d\udd17 This function is used by Inputs to determine whether their reference indicates a hidden input, meaning an input that is not included in the schema. For example, a Model field can be hidden if its hidden attribute is True , for example for the reverse side of a ForeignKey that starts with a \"+\". In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_input_only \ud83d\udd17 This function is used by Inputs to determine whether their reference is only used for input, or also saved on the Model instance that is the target of the mutation. For example, a non-Model field is input-only since it doesn't get saved to the database. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_input_required \ud83d\udd17 This function is used by Inputs to determine whether their reference is required. For example, a Model field is required depending on the mutation it's used in, if it has a default value, if it has null=True , etc. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_many \ud83d\udd17 This function is used to determine whether a value indicates a list of objects or not. For example, a \"many-to-many\" field would return True . In addition to the value to convert, the function also accepts a model parameter, which is the Django Model associated with the value, and a name parameter, which is a name associated with the value (e.g. field name). extend_expression \ud83d\udd17 This function is used to rewrite a Django expression as if it was referenced from a given Model field. For example, an F expression F(\"name\") can be rewritten to extend from field_name as F(\"field_name__name\") , and similarly, a Q(name__exact=\"foo\") can be rewritten as Q(field_name__name__exact=\"foo\") . This is used by the optimizer to rewrite expressions from \"to-one\" fields to the fields if the related Model can be fetched using select_related . In addition to the expression to convert, the function also accepts a field_name parameter, which is the name of the field to extend the expression from. Registering implementations \ud83d\udd17 To register new implementations for a converter, you need to decorate a function using the <converter>.register method. 1 2 3 4 5 6 7 8 9 10 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : type [ str ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString With this implementation registered fo the convert_to_graphql_type converter, calling convert_to_graphql_type(str) will return a GraphQLString object. However, calling convert_to_graphql_type(\"foo\") will not, since registration distinguishes between types and instances of types. To register for an instance, do this instead: 1 2 3 4 5 6 7 8 9 10 11 12 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type from undine.utils.model_utils import get_model_field @convert_to_graphql_type . register def _ ( ref : str , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : model_field = get_model_field ( model = kwargs [ \"model\" ], lookup = ref ) return convert_to_graphql_type ( model_field , ** kwargs ) A converter implementation should always accept **kwargs: Any , since those can be used to pass any additional arguments required by the converter. For example, the convert_to_graphql_type converter gets a model parameter, which indicates the Django model associated with the value. If an implementation can be used for many different types, you can register it using a type union. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from django.db.models import CharField , TextField from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : CharField | TextField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If the implementation of a superclass is can be used for a child class, you don't need to register implementations for the child class. Converters will automatically look up implementations based on the method resolution order of a class if an implementation is not found for the exact type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from typing import Any from django.db.models import BooleanField , NullBooleanField from graphql import GraphQLBoolean , GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : BooleanField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLBoolean # Uses the implementation for BooleanField, since NullBooleanField inherits from BooleanField. convert_to_graphql_type ( NullBooleanField ()) Implementations can be registered for literal values as well, in which case an implementation is registered for all the possible values of the Literal . When the converter is called with a value which can be a literal value, the converter will first check for any implementations for literals before checking for implementations for the type itself. 1 2 3 4 5 6 7 8 9 10 from typing import Any , Literal from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : Literal [ \"foo\" , \"bar\" ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If you need a different implementation for lambda functions as opposed to regular functions, you can register an implementation for the special Lambda type. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type from undine.typing import Lambda @convert_to_graphql_type . register def _ ( _ : Lambda , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString You can also register a default implementation for a converter using Any . Usually this is not needed and should be left for Undine to handle, since its likely you want an error to be raised by a converter for an unsupported type. Supporting new references \ud83d\udd17 Using the converters described above, we can extend the functionality of Undine objects to support new references by registering new implementations for specific converters. A new implementation might not be required for all converters if the new type is a subtype of some existing type, which already has a implementation that works for it. Entrypoints \ud83d\udd17 Here are the converters that a new Entrypoint reference might need to implement: convert_to_entrypoint_ref to allow the new reference to be used in Entrypoints . convert_to_entrypoint_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_subscription to convert the reference to a GraphQL subscription resolver function. convert_to_description to convert the reference to a description. Fields \ud83d\udd17 Here are the converters that a new Field reference might need to implement: convert_to_field_ref to allow the new reference to be used in Fields . convert_to_field_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_field_complexity to know the complexity of resolving the field. convert_to_description to convert the reference to a description. is_field_nullable to know whether the reference is nullable or not. is_many to know whether the reference contains many objects or not. Inputs \ud83d\udd17 Here are the converters that a new Input reference might need to implement: convert_to_input_ref to allow the new reference to be used in Inputs . convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_default_value to determine the default value of the input. convert_to_description to convert the reference to a description. is_input_only to know whether the reference is only used for input or not. is_input_hidden to know whether the reference is hidden from the schema or not. is_input_required to know whether the reference is required or not. is_many to know whether the reference contains many objects or not. Filters \ud83d\udd17 Here are the converters that a new Filter reference might need to implement: convert_to_filter_ref to allow the new reference to be used in Filters . convert_to_filter_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_description to convert the reference to a description. Orders \ud83d\udd17 Here are the converters that a new Order reference might need to implement: convert_to_order_ref to allow the new reference to be used in Orders . convert_to_description to convert the reference to a description. Interfaces \ud83d\udd17 Here are the converters that a new InterfaceType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function. Unions \ud83d\udd17 Here are the converters that a new UnionType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Hacking Undine"},{"location":"hacking-undine/#hacking-undine","text":"While Undine aims to offer a batteries-included solution for building GraphQL APIs on top of Django, it is designed to be easy to modify and extend to suit the needs of any project. For example, your project may include custom Model fields, or require dates or times to be parsed in a specific way.","title":"Hacking Undine"},{"location":"hacking-undine/#converters","text":"In this section, we will go through Undine's many converters, which are used by Undine to process values in various parts of its objects. These converters are implemented using single-dispatch generic functions . A singe-dispatch generic function is a function that has different implementations based on the type of the argument it receives. You can think of it as a dynamic switch statement. You may know the @singledispatch decorator from the python standard library, which implements this pattern. Undine implements its own version of it, which allows for more flexible dispatching. This pattern allows users to override and extend the behavior of any converter without having to modify Undine's code directly. The different converters available are listed below.","title":"Converters"},{"location":"hacking-undine/#convert_to_graphql_type","text":"This function is used to convert a value to a GraphQL input or output type. For example, a QueryType Field may be based on a model field, and so the Field needs to know which GraphQL type corresponds to the model's field. In addition to the value to convert, the function also accepts a model parameter, which is the Django Model associated with the value, and a is_input parameter, which is a boolean indicating whether the converter should return an input or output type.","title":"convert_to_graphql_type"},{"location":"hacking-undine/#convert_to_graphql_argument_map","text":"This function is used to convert a value to a GraphQL argument map. It's used by Fields and Entrypoints to figure out which parameters their GraphQL fields should have. For example, if a QueryType is used in a list Entrypoint , it should get its FilterSet and/or OrderSet as arguments. Similarly, a Connection should get its pagination arguments from this converter. In addition to the value to convert, the function also accepts a many parameter, which is a boolean indicating whether the converter should return a list of arguments or not, and a entrypoint parameter, which is a boolean indicating whether the converter is used in an Entrypoint or not.","title":"convert_to_graphql_argument_map"},{"location":"hacking-undine/#convert_lookup_to_graphql_type","text":"This function is used to convert a lookup expression to a GraphQL type. It's used in Filters to figure out the Filter's input type after the its lookup expression has been added. For example a __date lookup changes the expected input for a DateTimeField Filter from DateTime to Date . In addition to the lookup expression to convert, the function also accepts a default_type parameter, which is the GraphQLType for the parent field the lookup is for.","title":"convert_lookup_to_graphql_type"},{"location":"hacking-undine/#convert_to_model_field_to_python_type","text":"This function is used to convert a model fields to a Python type. It's used in parsing Model relation types, which are used by various parts of Undine when working with Model relations.","title":"convert_to_model_field_to_python_type"},{"location":"hacking-undine/#convert_to_entrypoint_ref","text":"This function is used by Entrypoints to handle their given reference. Most of the time, registering an implementation for this converter is only required to allow a new kind of Entrypoint reference to be used, but may also be used to add additional handling for the reference. In addition to the value to convert, the function also accepts a caller parameter, which is the Entrypoint instance that is calling this function. This allows the converter to access the Entrypoint's attributes however it sees fit.","title":"convert_to_entrypoint_ref"},{"location":"hacking-undine/#convert_to_field_ref","text":"This function is used by Fields to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Field instance.","title":"convert_to_field_ref"},{"location":"hacking-undine/#convert_to_input_ref","text":"This function is used by Inputs to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Input instance.","title":"convert_to_input_ref"},{"location":"hacking-undine/#convert_to_order_ref","text":"This function is used by Orders to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Order instance.","title":"convert_to_order_ref"},{"location":"hacking-undine/#convert_to_filter_ref","text":"This function is used by Filters to handle their given reference. Otherwise, it works the same as convert_to_entrypoint_ref , with the caller parameter set to the Filter instance.","title":"convert_to_filter_ref"},{"location":"hacking-undine/#convert_to_field_resolver","text":"This function is used to convert a value to a GraphQL field resolver. It's used by Fields to figure out which resolver function should be used to resolve the field during a query. For example, related fields require a different resolver from a regular field. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"convert_to_field_resolver"},{"location":"hacking-undine/#convert_to_entrypoint_resolver","text":"This function is the Entrypoint equivalent of the convert_to_field_resolver converter. A separate converter is needed since Entrypoints may resolve differently than Fields , or they can run the Optimizer.","title":"convert_to_entrypoint_resolver"},{"location":"hacking-undine/#convert_to_filter_resolver","text":"This function is used to convert a value to a Filter expression resolver. It's used by Filters to figure out which resolver function should be used for filtering. A Filter resolver function always returns a Django expression. In addition to the value to convert, the function also accepts a caller parameter, which is the Filter instance that is calling this function.","title":"convert_to_filter_resolver"},{"location":"hacking-undine/#convert_to_entrypoint_subscription","text":"This function is used to convert a value to a GraphQL subscription resolver. It's used by Entrypoints to figure out which resolver function should be used for subscriptions.","title":"convert_to_entrypoint_subscription"},{"location":"hacking-undine/#convert_to_description","text":"This function is used to convert a value to a GraphQL description. It's used by Fields , Inputs , Filters and Orders to figure out the description to use for their GraphQL types. For example, the description for a Model field is its help_text attribute.","title":"convert_to_description"},{"location":"hacking-undine/#convert_to_default_value","text":"This function is used to convert a value to a GraphQL default value. It's used by Inputs to figure out the default value for their GraphQL types. For example, a Model field's default value is its default attribute. However, a default value is only added to an Input for a create mutation.","title":"convert_to_default_value"},{"location":"hacking-undine/#convert_to_bad_lookups","text":"This function is used to convert a given Model field to a list of lookups that are not supported by the field, even if the given lookup is registered for it. For example, if you check BooleanField.get_lookups() , it show many generic lookups registered for the base Field class, which don't actually work on a BooleanField (e.g. contains or iendswith ). This function is used to remove those lookups when auto-generating Filters for a FilterSet .","title":"convert_to_bad_lookups"},{"location":"hacking-undine/#convert_to_field_complexity","text":"This function is used to convert a Field reference to its complexity value. By default, any reference passed to it has a complexity of 0 if not specified. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"convert_to_field_complexity"},{"location":"hacking-undine/#is_field_nullable","text":"This function is used by Fields to determine whether their reference is nullable or not. For example, a Model field reference is nullable if its null attribute is True . In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"is_field_nullable"},{"location":"hacking-undine/#is_input_hidden","text":"This function is used by Inputs to determine whether their reference indicates a hidden input, meaning an input that is not included in the schema. For example, a Model field can be hidden if its hidden attribute is True , for example for the reverse side of a ForeignKey that starts with a \"+\". In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_hidden"},{"location":"hacking-undine/#is_input_only","text":"This function is used by Inputs to determine whether their reference is only used for input, or also saved on the Model instance that is the target of the mutation. For example, a non-Model field is input-only since it doesn't get saved to the database. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_only"},{"location":"hacking-undine/#is_input_required","text":"This function is used by Inputs to determine whether their reference is required. For example, a Model field is required depending on the mutation it's used in, if it has a default value, if it has null=True , etc. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_required"},{"location":"hacking-undine/#is_many","text":"This function is used to determine whether a value indicates a list of objects or not. For example, a \"many-to-many\" field would return True . In addition to the value to convert, the function also accepts a model parameter, which is the Django Model associated with the value, and a name parameter, which is a name associated with the value (e.g. field name).","title":"is_many"},{"location":"hacking-undine/#extend_expression","text":"This function is used to rewrite a Django expression as if it was referenced from a given Model field. For example, an F expression F(\"name\") can be rewritten to extend from field_name as F(\"field_name__name\") , and similarly, a Q(name__exact=\"foo\") can be rewritten as Q(field_name__name__exact=\"foo\") . This is used by the optimizer to rewrite expressions from \"to-one\" fields to the fields if the related Model can be fetched using select_related . In addition to the expression to convert, the function also accepts a field_name parameter, which is the name of the field to extend the expression from.","title":"extend_expression"},{"location":"hacking-undine/#registering-implementations","text":"To register new implementations for a converter, you need to decorate a function using the <converter>.register method. 1 2 3 4 5 6 7 8 9 10 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : type [ str ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString With this implementation registered fo the convert_to_graphql_type converter, calling convert_to_graphql_type(str) will return a GraphQLString object. However, calling convert_to_graphql_type(\"foo\") will not, since registration distinguishes between types and instances of types. To register for an instance, do this instead: 1 2 3 4 5 6 7 8 9 10 11 12 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type from undine.utils.model_utils import get_model_field @convert_to_graphql_type . register def _ ( ref : str , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : model_field = get_model_field ( model = kwargs [ \"model\" ], lookup = ref ) return convert_to_graphql_type ( model_field , ** kwargs ) A converter implementation should always accept **kwargs: Any , since those can be used to pass any additional arguments required by the converter. For example, the convert_to_graphql_type converter gets a model parameter, which indicates the Django model associated with the value. If an implementation can be used for many different types, you can register it using a type union. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from django.db.models import CharField , TextField from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : CharField | TextField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If the implementation of a superclass is can be used for a child class, you don't need to register implementations for the child class. Converters will automatically look up implementations based on the method resolution order of a class if an implementation is not found for the exact type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from typing import Any from django.db.models import BooleanField , NullBooleanField from graphql import GraphQLBoolean , GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : BooleanField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLBoolean # Uses the implementation for BooleanField, since NullBooleanField inherits from BooleanField. convert_to_graphql_type ( NullBooleanField ()) Implementations can be registered for literal values as well, in which case an implementation is registered for all the possible values of the Literal . When the converter is called with a value which can be a literal value, the converter will first check for any implementations for literals before checking for implementations for the type itself. 1 2 3 4 5 6 7 8 9 10 from typing import Any , Literal from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : Literal [ \"foo\" , \"bar\" ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If you need a different implementation for lambda functions as opposed to regular functions, you can register an implementation for the special Lambda type. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type from undine.typing import Lambda @convert_to_graphql_type . register def _ ( _ : Lambda , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString You can also register a default implementation for a converter using Any . Usually this is not needed and should be left for Undine to handle, since its likely you want an error to be raised by a converter for an unsupported type.","title":"Registering implementations"},{"location":"hacking-undine/#supporting-new-references","text":"Using the converters described above, we can extend the functionality of Undine objects to support new references by registering new implementations for specific converters. A new implementation might not be required for all converters if the new type is a subtype of some existing type, which already has a implementation that works for it.","title":"Supporting new references"},{"location":"hacking-undine/#entrypoints","text":"Here are the converters that a new Entrypoint reference might need to implement: convert_to_entrypoint_ref to allow the new reference to be used in Entrypoints . convert_to_entrypoint_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_subscription to convert the reference to a GraphQL subscription resolver function. convert_to_description to convert the reference to a description.","title":"Entrypoints"},{"location":"hacking-undine/#fields","text":"Here are the converters that a new Field reference might need to implement: convert_to_field_ref to allow the new reference to be used in Fields . convert_to_field_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_field_complexity to know the complexity of resolving the field. convert_to_description to convert the reference to a description. is_field_nullable to know whether the reference is nullable or not. is_many to know whether the reference contains many objects or not.","title":"Fields"},{"location":"hacking-undine/#inputs","text":"Here are the converters that a new Input reference might need to implement: convert_to_input_ref to allow the new reference to be used in Inputs . convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_default_value to determine the default value of the input. convert_to_description to convert the reference to a description. is_input_only to know whether the reference is only used for input or not. is_input_hidden to know whether the reference is hidden from the schema or not. is_input_required to know whether the reference is required or not. is_many to know whether the reference contains many objects or not.","title":"Inputs"},{"location":"hacking-undine/#filters","text":"Here are the converters that a new Filter reference might need to implement: convert_to_filter_ref to allow the new reference to be used in Filters . convert_to_filter_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_description to convert the reference to a description.","title":"Filters"},{"location":"hacking-undine/#orders","text":"Here are the converters that a new Order reference might need to implement: convert_to_order_ref to allow the new reference to be used in Orders . convert_to_description to convert the reference to a description.","title":"Orders"},{"location":"hacking-undine/#interfaces","text":"Here are the converters that a new InterfaceType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Interfaces"},{"location":"hacking-undine/#unions","text":"Here are the converters that a new UnionType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Unions"},{"location":"integrations/","text":"Integrations \ud83d\udd17 In this section, we'll cover the integrations to other libraries that Undine includes. channels \ud83d\udd17 1 pip install undine[channels] Undine provides support for GraphQL over WebSocket and GraphQL over SSE ( Single Connection mode ) by integrating with the channels library. Using the channels integration requires turning on Undine's Async Support . You'll need to configure Django in your project's asgi.py file so that requests are sent to Undine's channels consumers. There are three app wrappers available depending on which protocols you need. For WebSocket support only: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_enabled_app application = get_websocket_enabled_app ( django_application ) For SSE Single Connection mode only: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_sse_enabled_app application = get_sse_enabled_app ( django_application ) For both WebSocket and SSE Single Connection mode: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_and_sse_enabled_app application = get_websocket_and_sse_enabled_app ( django_application ) GraphiQL \ud83d\udd17 Undine includes a built-in GraphiQL interface for exploring and testing your GraphQL API. You can enable it using the GRAPHIQL_ENABLED setting. You should also set ALLOW_INTROSPECTION_QUERIES to True so that GraphiQL can introspect the schema. GraphiQL is then accessible by navigating to the GraphQL endpoint in a browser. GraphiQL includes the explorer and history plugins. The URL encodes the current document, variables, and headers, so it can be shared with others. By default, subscriptions use WebSockets . To use Server-Sent Events instead, use the GRAPHIQL_SSE_ENABLED setting. Single connection mode can be enabled with the GRAPHIQL_SSE_SINGLE_CONNECTION setting. django-debug-toolbar \ud83d\udd17 1 pip install undine[debug] Undine integrates with django-debug-toolbar by modifying the toolbar HTML so that it integrates with GraphiQL . After installing django-debug-toolbar , Undine should automatically patch it without any additional configuration. django-modeltranslation \ud83d\udd17 Undine integrates with django-modeltranslation by allowing you to modify how autogenerated Fields , Inputs , Filters and Orders are created. Specifically, this happens using two settings: MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS . Let's say you the following Model (with MODELTRANSLATION_LANGUAGES = (\"en\", \"fi\") ) 1 2 3 4 5 6 7 8 9 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) # Created by modeltranslation name_en : str | None name_fi : str | None ...and the following translation options 1 2 3 4 5 6 7 8 9 from modeltranslation.decorators import register from modeltranslation.translator import TranslationOptions from .models import Task @register ( Task ) class TaskTranslationOptions ( TranslationOptions ): fields = [ \"name\" ] Based on the Model's translation options, django-modeltranslation adds additional fields for each language defined by the MODELTRANSLATION_LANGUAGES setting. Let's call the added fields the \"translatable\" fields, and the fields they are based on the \"translation\" fields. Using the MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS settings, you can control which of these fields undine will add to your schema when using autogeneration. By default, only the translation fields are added. You can of course always add the translatable fields manually. Note that due to the way that django-modeltranslation works, the translation fields are always nullable, even for the default language. pytest \ud83d\udd17 Undine comes with a pytest plugin that includes a testing client and few fixtures to help you write tests for your GraphQL APIs. The GraphQLClient class is wrapper around Django's test client that makes testing your GraphQL API easier. It can be added to a test using the graphql fixture. Here is a simple example: 1 2 3 4 5 6 def test_example ( graphql ) -> None : query = \"query { test }\" response = graphql ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } GraphQL requests can be made by calling the client as shown above. This makes a request to the GraphQL endpoint set by the GRAPHQL_PATH setting. GraphQL variables can be passed using the variables argument. If these variables include any files, the client will automatically create a GraphQL multipart request instead of a normal GraphQL request. 1 2 3 4 5 6 7 def test_example ( graphql ) -> None : mutation = \"mutation($input: TestInput!) { test(input: $input) }\" data = { \"name\" : \"World\" } response = graphql ( mutation , variables = { \"input\" : data }) assert response . data == { \"hello\" : \"Hello, World!\" } The client returns a custom response object GraphQLClientResponse , which has a number of useful properties for introspecting the response. The response object also has details on the database queries that were executed during the request, which can be useful for debugging the performance of your GraphQL API. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def test_example ( graphql ) -> None : query = \"query { test { edges { node { id } } } }\" response = graphql ( query , count_queries = True ) # The whole response assert response . json == { \"data\" : { \"test\" : { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]}}, \"errors\" : [{ \"message\" : \"Error message\" , \"path\" : [ \"test\" ]}], } # Error properties assert response . has_errors is True assert response . errors == [{ \"message\" : \"Error message\" , \"path\" : [ \"test\" ]}] assert response . error_message ( 0 ) == \"Error message\" # Data properties assert response . data == { \"test\" : { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]}} assert response . results == { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]} # Connection specific properties assert response . edges == [{ \"node\" : { \"id\" : \"1\" }}] assert response . node ( 0 ) == { \"id\" : \"1\" } # Check queries (requires `count_queries=True`) assert response . query_count == 1 assert response . queries == [ \"SELECT 1;\" ] response . assert_query_count ( 1 ) An async version of the client is also available, which can be accessed from the graphql_async fixture. 1 2 3 4 5 6 7 8 9 10 11 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_example ( graphql_async ) -> None : query = \"query { test }\" response = await graphql_async ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } The plugin also includes a undine_settings fixture that allows modifying Undine's settings during testing more easily. 1 2 def test_example ( undine_settings ) -> None : undine_settings . NO_ERROR_LOCATION = True If the channels integration is installed, the test client can also send GraphQL over WebSocket requests using the over_websocket method. 1 2 3 4 5 6 7 8 9 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_graphql ( graphql ) -> None : query = \"query { test }\" async for response in graphql . over_websocket ( query ): assert response . data == { \"test\" : \"Hello, World!\" }","title":"Integrations"},{"location":"integrations/#integrations","text":"In this section, we'll cover the integrations to other libraries that Undine includes.","title":"Integrations"},{"location":"integrations/#channels","text":"1 pip install undine[channels] Undine provides support for GraphQL over WebSocket and GraphQL over SSE ( Single Connection mode ) by integrating with the channels library. Using the channels integration requires turning on Undine's Async Support . You'll need to configure Django in your project's asgi.py file so that requests are sent to Undine's channels consumers. There are three app wrappers available depending on which protocols you need. For WebSocket support only: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_enabled_app application = get_websocket_enabled_app ( django_application ) For SSE Single Connection mode only: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_sse_enabled_app application = get_sse_enabled_app ( django_application ) For both WebSocket and SSE Single Connection mode: 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_and_sse_enabled_app application = get_websocket_and_sse_enabled_app ( django_application )","title":"channels"},{"location":"integrations/#graphiql","text":"Undine includes a built-in GraphiQL interface for exploring and testing your GraphQL API. You can enable it using the GRAPHIQL_ENABLED setting. You should also set ALLOW_INTROSPECTION_QUERIES to True so that GraphiQL can introspect the schema. GraphiQL is then accessible by navigating to the GraphQL endpoint in a browser. GraphiQL includes the explorer and history plugins. The URL encodes the current document, variables, and headers, so it can be shared with others. By default, subscriptions use WebSockets . To use Server-Sent Events instead, use the GRAPHIQL_SSE_ENABLED setting. Single connection mode can be enabled with the GRAPHIQL_SSE_SINGLE_CONNECTION setting.","title":"GraphiQL"},{"location":"integrations/#django-debug-toolbar","text":"1 pip install undine[debug] Undine integrates with django-debug-toolbar by modifying the toolbar HTML so that it integrates with GraphiQL . After installing django-debug-toolbar , Undine should automatically patch it without any additional configuration.","title":"django-debug-toolbar"},{"location":"integrations/#django-modeltranslation","text":"Undine integrates with django-modeltranslation by allowing you to modify how autogenerated Fields , Inputs , Filters and Orders are created. Specifically, this happens using two settings: MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS . Let's say you the following Model (with MODELTRANSLATION_LANGUAGES = (\"en\", \"fi\") ) 1 2 3 4 5 6 7 8 9 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) # Created by modeltranslation name_en : str | None name_fi : str | None ...and the following translation options 1 2 3 4 5 6 7 8 9 from modeltranslation.decorators import register from modeltranslation.translator import TranslationOptions from .models import Task @register ( Task ) class TaskTranslationOptions ( TranslationOptions ): fields = [ \"name\" ] Based on the Model's translation options, django-modeltranslation adds additional fields for each language defined by the MODELTRANSLATION_LANGUAGES setting. Let's call the added fields the \"translatable\" fields, and the fields they are based on the \"translation\" fields. Using the MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS settings, you can control which of these fields undine will add to your schema when using autogeneration. By default, only the translation fields are added. You can of course always add the translatable fields manually. Note that due to the way that django-modeltranslation works, the translation fields are always nullable, even for the default language.","title":"django-modeltranslation"},{"location":"integrations/#pytest","text":"Undine comes with a pytest plugin that includes a testing client and few fixtures to help you write tests for your GraphQL APIs. The GraphQLClient class is wrapper around Django's test client that makes testing your GraphQL API easier. It can be added to a test using the graphql fixture. Here is a simple example: 1 2 3 4 5 6 def test_example ( graphql ) -> None : query = \"query { test }\" response = graphql ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } GraphQL requests can be made by calling the client as shown above. This makes a request to the GraphQL endpoint set by the GRAPHQL_PATH setting. GraphQL variables can be passed using the variables argument. If these variables include any files, the client will automatically create a GraphQL multipart request instead of a normal GraphQL request. 1 2 3 4 5 6 7 def test_example ( graphql ) -> None : mutation = \"mutation($input: TestInput!) { test(input: $input) }\" data = { \"name\" : \"World\" } response = graphql ( mutation , variables = { \"input\" : data }) assert response . data == { \"hello\" : \"Hello, World!\" } The client returns a custom response object GraphQLClientResponse , which has a number of useful properties for introspecting the response. The response object also has details on the database queries that were executed during the request, which can be useful for debugging the performance of your GraphQL API. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def test_example ( graphql ) -> None : query = \"query { test { edges { node { id } } } }\" response = graphql ( query , count_queries = True ) # The whole response assert response . json == { \"data\" : { \"test\" : { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]}}, \"errors\" : [{ \"message\" : \"Error message\" , \"path\" : [ \"test\" ]}], } # Error properties assert response . has_errors is True assert response . errors == [{ \"message\" : \"Error message\" , \"path\" : [ \"test\" ]}] assert response . error_message ( 0 ) == \"Error message\" # Data properties assert response . data == { \"test\" : { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]}} assert response . results == { \"edges\" : [{ \"node\" : { \"id\" : \"1\" }}]} # Connection specific properties assert response . edges == [{ \"node\" : { \"id\" : \"1\" }}] assert response . node ( 0 ) == { \"id\" : \"1\" } # Check queries (requires `count_queries=True`) assert response . query_count == 1 assert response . queries == [ \"SELECT 1;\" ] response . assert_query_count ( 1 ) An async version of the client is also available, which can be accessed from the graphql_async fixture. 1 2 3 4 5 6 7 8 9 10 11 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_example ( graphql_async ) -> None : query = \"query { test }\" response = await graphql_async ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } The plugin also includes a undine_settings fixture that allows modifying Undine's settings during testing more easily. 1 2 def test_example ( undine_settings ) -> None : undine_settings . NO_ERROR_LOCATION = True If the channels integration is installed, the test client can also send GraphQL over WebSocket requests using the over_websocket method. 1 2 3 4 5 6 7 8 9 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_graphql ( graphql ) -> None : query = \"query { test }\" async for response in graphql . over_websocket ( query ): assert response . data == { \"test\" : \"Hello, World!\" }","title":"pytest"},{"location":"interfaces/","text":"Interfaces \ud83d\udd17 In this section, we'll cover how GraphQL Interfaces work in Undine. Interfaces are abstract GraphQL types that represent a group of fields that an ObjectType can implement. InterfaceType \ud83d\udd17 In Undine, a GraphQL Interface is implemented using the InterfaceType class and defining a number of InterfaceFields in its class body. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) QueryTypes can implement InterfaceTypes by adding them to the QueryType using the interfaces argument in their class definition. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... You can also use decorator syntax to add an InterfaceType to a QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... Note that InterfaceTypes can also implement other InterfaceTypes . 1 2 3 4 5 6 7 8 9 10 11 from graphql import GraphQLInt , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class Person ( InterfaceType , interfaces = [ Named ]): age = InterfaceField ( GraphQLNonNull ( GraphQLInt )) Usage in Entrypoints \ud83d\udd17 An Entrypoint created using an InterfaceType as the reference will return all implementations of the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 12 query { named { name ... on TaskType { createdAt } ... on StepType { done } __typename } } Filtering \ud83d\udd17 By default, an InterfaceType Entrypoint will return all instances of the QueryTypes that implement it. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the InterfaceType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , FilterSet , InterfaceField , InterfaceType , OrderSet , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... @Named @TaskFilterSet @TaskOrderSet class TaskType ( QueryType [ Task ]): ... class StepFilterSet ( FilterSet [ Step ]): ... class StepOrderSet ( OrderSet [ Step ]): ... @Named @StepFilterSet @StepOrderSet class StepType ( QueryType [ Step ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { named ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterStep : StepFilterSet orderByStep : [ StepOrderSet !] ): [ Named !]! } This allows filtering the different types of models in the InterfaceType separately. Pagination \ud83d\udd17 InterfaceTypes can be paginated just like any QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from undine.relay import Connection from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... @Named class StepType ( QueryType [ Step ]): ... class Query ( RootType ): named = Entrypoint ( Connection ( Named )) See the Pagination section for more details on pagination. Schema name \ud83d\udd17 By default, the name of the generated GraphQL Interface for a InterfaceType class is the name of the InterfaceType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , schema_name = \"HasName\" ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Description \ud83d\udd17 You can provide a description for the InterfaceType by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): \"\"\"Description.\"\"\" name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Directives \ud83d\udd17 You can add directives to the InterfaceType by providing them using the directives argument. The directive must be usable in the INTERFACE location. 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ]): ... class Named ( InterfaceType , directives = [ MyDirective ()]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ]): ... @MyDirective () class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an InterfaceType from certain users by using the __is_visible__ method. Hiding the InterfaceType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the QueryTypes or other InterfaceTypes didn't implement the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.typing import DjangoRequestProtocol class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the InterfaceType by providing an extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceType . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , extensions = { \"foo\" : \"bar\" }): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) InterfaceType extensions are made available in the GraphQL Interface extensions after the schema is created. The InterfaceType itself is found in the GraphQL Interface extensions under a key defined by the INTERFACE_TYPE_EXTENSIONS_KEY setting. InterfaceField \ud83d\udd17 When a QueryType implements an InterfaceType , all of the InterfaceFields on the InterfaceType are converted to Fields on the QueryType . The converted Field must correspond to a Model field on the QueryType Model, and the InterfaceField output type must match the GraphQL output type converted from Model field. In other words, all InterfaceFields must correspond to Model fields when implemented on a QueryType . An InterfaceField always requires its desired GraphQL output type to be defined. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Optionally, you can define arguments that the InterfaceField requires. If defined, these must also match the Model field of the implementing QueryType . 1 2 3 4 5 6 7 8 9 10 from graphql import GraphQLArgument , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), args = { \"name\" : GraphQLArgument ( GraphQLNonNull ( GraphQLString ))}, ) Field name \ud83d\udd17 By default, the name of the field in the Django model is the same as the name of the InterfaceField . If you want to change the name of the field in the Django model separately, you can do so by setting the field_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), field_name = \"name\" ) Schema name \ud83d\udd17 By default, the name of the Interface field generated from a InterfaceField is the same as the name of the InterfaceField on the InterfaceType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the Interface field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), schema_name = \"name\" ) This can be useful when the desired name of the Interface field is a Python keyword and cannot be used as the Field attribute name. Description \ud83d\udd17 A description for a field can be provided in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), description = \"The name of the object.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) \"\"\"The name of the object.\"\"\" Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the InterfaceField as deprecated. This is for documentation purposes only, and does not affect the use of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use `title` instead.\" ) Directives \ud83d\udd17 You can add directives to the IntefaceField by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a InterfaceField from certain users by decorating a method with the <interface_field_name>.visible decorator. Hiding a InterfaceField means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the InterfaceField or any QueryType Field inherited from the InterfaceField didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.typing import DjangoRequestProtocol class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the InterfaceField . The self argument is not an instance of the InterfaceType , but the instance of the InterfaceField that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the InterfaceField by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) InterfaceField extensions are made available in the GraphQL Interface field extensions after the schema is created. The InterfaceField itself is found in the GraphQL Interface field extensions under a key defined by the INTERFACE_FIELD_EXTENSIONS_KEY setting.","title":"Interfaces"},{"location":"interfaces/#interfaces","text":"In this section, we'll cover how GraphQL Interfaces work in Undine. Interfaces are abstract GraphQL types that represent a group of fields that an ObjectType can implement.","title":"Interfaces"},{"location":"interfaces/#interfacetype","text":"In Undine, a GraphQL Interface is implemented using the InterfaceType class and defining a number of InterfaceFields in its class body. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) QueryTypes can implement InterfaceTypes by adding them to the QueryType using the interfaces argument in their class definition. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... You can also use decorator syntax to add an InterfaceType to a QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... Note that InterfaceTypes can also implement other InterfaceTypes . 1 2 3 4 5 6 7 8 9 10 11 from graphql import GraphQLInt , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class Person ( InterfaceType , interfaces = [ Named ]): age = InterfaceField ( GraphQLNonNull ( GraphQLInt ))","title":"InterfaceType"},{"location":"interfaces/#usage-in-entrypoints","text":"An Entrypoint created using an InterfaceType as the reference will return all implementations of the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 12 query { named { name ... on TaskType { createdAt } ... on StepType { done } __typename } }","title":"Usage in Entrypoints"},{"location":"interfaces/#filtering","text":"By default, an InterfaceType Entrypoint will return all instances of the QueryTypes that implement it. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the InterfaceType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , FilterSet , InterfaceField , InterfaceType , OrderSet , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... @Named @TaskFilterSet @TaskOrderSet class TaskType ( QueryType [ Task ]): ... class StepFilterSet ( FilterSet [ Step ]): ... class StepOrderSet ( OrderSet [ Step ]): ... @Named @StepFilterSet @StepOrderSet class StepType ( QueryType [ Step ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { named ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterStep : StepFilterSet orderByStep : [ StepOrderSet !] ): [ Named !]! } This allows filtering the different types of models in the InterfaceType separately.","title":"Filtering"},{"location":"interfaces/#pagination","text":"InterfaceTypes can be paginated just like any QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from undine.relay import Connection from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... @Named class StepType ( QueryType [ Step ]): ... class Query ( RootType ): named = Entrypoint ( Connection ( Named )) See the Pagination section for more details on pagination.","title":"Pagination"},{"location":"interfaces/#schema-name","text":"By default, the name of the generated GraphQL Interface for a InterfaceType class is the name of the InterfaceType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , schema_name = \"HasName\" ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ))","title":"Schema name"},{"location":"interfaces/#description","text":"You can provide a description for the InterfaceType by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): \"\"\"Description.\"\"\" name = InterfaceField ( GraphQLNonNull ( GraphQLString ))","title":"Description"},{"location":"interfaces/#directives","text":"You can add directives to the InterfaceType by providing them using the directives argument. The directive must be usable in the INTERFACE location. 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ]): ... class Named ( InterfaceType , directives = [ MyDirective ()]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ]): ... @MyDirective () class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) See the Directives section for more details on directives.","title":"Directives"},{"location":"interfaces/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an InterfaceType from certain users by using the __is_visible__ method. Hiding the InterfaceType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the QueryTypes or other InterfaceTypes didn't implement the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.typing import DjangoRequestProtocol class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"interfaces/#graphql-extensions","text":"You can provide custom extensions for the InterfaceType by providing an extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceType . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , extensions = { \"foo\" : \"bar\" }): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) InterfaceType extensions are made available in the GraphQL Interface extensions after the schema is created. The InterfaceType itself is found in the GraphQL Interface extensions under a key defined by the INTERFACE_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"interfaces/#interfacefield","text":"When a QueryType implements an InterfaceType , all of the InterfaceFields on the InterfaceType are converted to Fields on the QueryType . The converted Field must correspond to a Model field on the QueryType Model, and the InterfaceField output type must match the GraphQL output type converted from Model field. In other words, all InterfaceFields must correspond to Model fields when implemented on a QueryType . An InterfaceField always requires its desired GraphQL output type to be defined. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Optionally, you can define arguments that the InterfaceField requires. If defined, these must also match the Model field of the implementing QueryType . 1 2 3 4 5 6 7 8 9 10 from graphql import GraphQLArgument , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), args = { \"name\" : GraphQLArgument ( GraphQLNonNull ( GraphQLString ))}, )","title":"InterfaceField"},{"location":"interfaces/#field-name","text":"By default, the name of the field in the Django model is the same as the name of the InterfaceField . If you want to change the name of the field in the Django model separately, you can do so by setting the field_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), field_name = \"name\" )","title":"Field name"},{"location":"interfaces/#schema-name_1","text":"By default, the name of the Interface field generated from a InterfaceField is the same as the name of the InterfaceField on the InterfaceType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the Interface field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), schema_name = \"name\" ) This can be useful when the desired name of the Interface field is a Python keyword and cannot be used as the Field attribute name.","title":"Schema name"},{"location":"interfaces/#description_1","text":"A description for a field can be provided in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), description = \"The name of the object.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) \"\"\"The name of the object.\"\"\"","title":"Description"},{"location":"interfaces/#deprecation-reason","text":"A deprecation_reason can be provided to mark the InterfaceField as deprecated. This is for documentation purposes only, and does not affect the use of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use `title` instead.\" )","title":"Deprecation reason"},{"location":"interfaces/#directives_1","text":"You can add directives to the IntefaceField by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"interfaces/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a InterfaceField from certain users by decorating a method with the <interface_field_name>.visible decorator. Hiding a InterfaceField means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the InterfaceField or any QueryType Field inherited from the InterfaceField didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.typing import DjangoRequestProtocol class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the InterfaceField . The self argument is not an instance of the InterfaceType , but the instance of the InterfaceField that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"interfaces/#graphql-extensions_1","text":"You can provide custom extensions for the InterfaceField by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) InterfaceField extensions are made available in the GraphQL Interface field extensions after the schema is created. The InterfaceField itself is found in the GraphQL Interface field extensions under a key defined by the INTERFACE_FIELD_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"lifecycle-hooks/","text":"Lifecycle Hooks \ud83d\udd17 In this section, we'll cover Undine's lifecycle hooks, which allow you to hook into the execution of a GraphQL request. LifecycleHook \ud83d\udd17 A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation according to the GraphQL AST. LifecycleHooks allow you to hook into the these steps. To implement a hook, you need to create a class that inherits from LifecycleHook and implement the the appropriate methods based on the steps you want to hook into. The points you can hook into are: on_operation / on_operation_async : Encompasses the entire GraphQL operation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_operation ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_operation_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_parse / on_parse_async : Encompasses the parsing step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_parse ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_parse_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_validation / on_validation_async : Encompasses the validation step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_validation ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_validation_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_execution / on_execution_async : Encompasses the execution step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_execution ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_execution_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) resolve : Encompasses each field resolver (see graphql-core custom middleware ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from typing import Any from graphql import GraphQLFieldResolver from undine import GQLInfo from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" # The 'resolve' hook only has a synchronous interface. def resolve ( self , resolver : GraphQLFieldResolver , root : Any , info : GQLInfo , ** kwargs : Any ) -> Any : print ( \"before\" ) result = resolver ( root , info , ** kwargs ) print ( \"after\" ) return result Created hooks need to be registered using the LIFECYCLE_HOOKS setting. When there are multiple hooks that run logic on the same step, they will be run in the order they are added in the LIFECYCLE_HOOKS setting list. Specifically, the first hook registered will have its \"before\" portion run first and its \"after\" portion run last. You can think of them as a stack of context managers. LifecycleHookContext \ud83d\udd17 Each hook is passed a LifecycleHookContext object ( self.context ), which contains information about the current state of the GraphQL request. This includes: source : Source GraphQL document string. document : Parsed GraphQL AST. Available after parsing is complete. variables : Variables passed to the GraphQL operation. operation_name : The name of the GraphQL operation to run from the document. Can be empty if there is only one operation in the document. extensions : GraphQL operation extensions received from the client. request : Django request during which the GraphQL operation is being executed. result : Execution result of the GraphQL operation. Adding a result to this in a LifecycleHook will cause the operation to exit early with the result. lifecycle_hooks : LifecycleHooks in use for this operation. Examples \ud83d\udd17 Here's some more complex examples of possible lifecycle hooks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import json from collections.abc import Generator from django.core.cache import cache from graphql import ExecutionResult from undine.hooks import LifecycleHook class CachingHook ( LifecycleHook ): \"\"\"Cache execution results.\"\"\" TIMEOUT = 60 def on_operation ( self ) -> Generator [ None , None , None ]: cache_key = f \"undine: { self . context . source } : { json . dumps ( self . context . variables ) } : { self . context . request . user . pk } \" was_cached = False # Check if the result is already cached. if cache_key in cache : data = cache . get ( cache_key ) was_cached = True # Setting results early will cause the hooking point to not run # and the graphql execution to exit early with this result. self . context . result = ExecutionResult ( data = data ) yield # If results where cached, the hooking point will not run, but the # hook's \"after\" portion will. Therefore, don't re-cache the result # if it was already cached. if was_cached : return if self . context . result is not None and self . context . result . data is not None : cache . set ( cache_key , self . context . result . data , timeout = self . TIMEOUT ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 from collections.abc import Generator from time import perf_counter_ns from typing import Any from graphql import GraphQLFieldResolver from undine import GQLInfo from undine.hooks import LifecycleHook , LifecycleHookContext class TimingHook ( LifecycleHook ): \"\"\"Time the execution of each step of the GraphQL operation.\"\"\" def __init__ ( self , context : LifecycleHookContext ) -> None : super () . __init__ ( context ) self . parse_timing : float | None = None self . validation_timing : float | None = None self . execution_timing : float | None = None self . resolver_timings : dict [ str , float ] = {} def on_operation ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : end = perf_counter_ns () timings = { \"operation\" : end - start , \"parse\" : self . parse_timing , \"validation\" : self . validation_timing , \"execution\" : self . execution_timing , \"resolvers\" : self . resolver_timings , } if self . context . result is not None : self . context . result . extensions [ \"timings\" ] = timings def on_parse ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . parse_timing = perf_counter_ns () - start def on_validation ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . validation_timing = perf_counter_ns () - start def on_execution ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . execution_timing = perf_counter_ns () - start def resolve ( self , resolver : GraphQLFieldResolver , root : Any , info : GQLInfo , ** kwargs : Any ) -> Any : start = perf_counter_ns () try : return resolver ( root , info , ** kwargs ) finally : key = \".\" . join ( str ( key ) for key in info . path . as_list ()) self . resolver_timings [ key ] = perf_counter_ns () - start","title":"Lifecycle Hooks"},{"location":"lifecycle-hooks/#lifecycle-hooks","text":"In this section, we'll cover Undine's lifecycle hooks, which allow you to hook into the execution of a GraphQL request.","title":"Lifecycle Hooks"},{"location":"lifecycle-hooks/#lifecyclehook","text":"A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation according to the GraphQL AST. LifecycleHooks allow you to hook into the these steps. To implement a hook, you need to create a class that inherits from LifecycleHook and implement the the appropriate methods based on the steps you want to hook into. The points you can hook into are: on_operation / on_operation_async : Encompasses the entire GraphQL operation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_operation ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_operation_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_parse / on_parse_async : Encompasses the parsing step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_parse ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_parse_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_validation / on_validation_async : Encompasses the validation step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_validation ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_validation_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) on_execution / on_execution_async : Encompasses the execution step. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" def on_execution ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) # Async hook uses synchronous version if not implemented. async def on_execution_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) resolve : Encompasses each field resolver (see graphql-core custom middleware ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from typing import Any from graphql import GraphQLFieldResolver from undine import GQLInfo from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): \"\"\"Example hook\"\"\" # The 'resolve' hook only has a synchronous interface. def resolve ( self , resolver : GraphQLFieldResolver , root : Any , info : GQLInfo , ** kwargs : Any ) -> Any : print ( \"before\" ) result = resolver ( root , info , ** kwargs ) print ( \"after\" ) return result Created hooks need to be registered using the LIFECYCLE_HOOKS setting. When there are multiple hooks that run logic on the same step, they will be run in the order they are added in the LIFECYCLE_HOOKS setting list. Specifically, the first hook registered will have its \"before\" portion run first and its \"after\" portion run last. You can think of them as a stack of context managers.","title":"LifecycleHook"},{"location":"lifecycle-hooks/#lifecyclehookcontext","text":"Each hook is passed a LifecycleHookContext object ( self.context ), which contains information about the current state of the GraphQL request. This includes: source : Source GraphQL document string. document : Parsed GraphQL AST. Available after parsing is complete. variables : Variables passed to the GraphQL operation. operation_name : The name of the GraphQL operation to run from the document. Can be empty if there is only one operation in the document. extensions : GraphQL operation extensions received from the client. request : Django request during which the GraphQL operation is being executed. result : Execution result of the GraphQL operation. Adding a result to this in a LifecycleHook will cause the operation to exit early with the result. lifecycle_hooks : LifecycleHooks in use for this operation.","title":"LifecycleHookContext"},{"location":"lifecycle-hooks/#examples","text":"Here's some more complex examples of possible lifecycle hooks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import json from collections.abc import Generator from django.core.cache import cache from graphql import ExecutionResult from undine.hooks import LifecycleHook class CachingHook ( LifecycleHook ): \"\"\"Cache execution results.\"\"\" TIMEOUT = 60 def on_operation ( self ) -> Generator [ None , None , None ]: cache_key = f \"undine: { self . context . source } : { json . dumps ( self . context . variables ) } : { self . context . request . user . pk } \" was_cached = False # Check if the result is already cached. if cache_key in cache : data = cache . get ( cache_key ) was_cached = True # Setting results early will cause the hooking point to not run # and the graphql execution to exit early with this result. self . context . result = ExecutionResult ( data = data ) yield # If results where cached, the hooking point will not run, but the # hook's \"after\" portion will. Therefore, don't re-cache the result # if it was already cached. if was_cached : return if self . context . result is not None and self . context . result . data is not None : cache . set ( cache_key , self . context . result . data , timeout = self . TIMEOUT ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 from collections.abc import Generator from time import perf_counter_ns from typing import Any from graphql import GraphQLFieldResolver from undine import GQLInfo from undine.hooks import LifecycleHook , LifecycleHookContext class TimingHook ( LifecycleHook ): \"\"\"Time the execution of each step of the GraphQL operation.\"\"\" def __init__ ( self , context : LifecycleHookContext ) -> None : super () . __init__ ( context ) self . parse_timing : float | None = None self . validation_timing : float | None = None self . execution_timing : float | None = None self . resolver_timings : dict [ str , float ] = {} def on_operation ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : end = perf_counter_ns () timings = { \"operation\" : end - start , \"parse\" : self . parse_timing , \"validation\" : self . validation_timing , \"execution\" : self . execution_timing , \"resolvers\" : self . resolver_timings , } if self . context . result is not None : self . context . result . extensions [ \"timings\" ] = timings def on_parse ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . parse_timing = perf_counter_ns () - start def on_validation ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . validation_timing = perf_counter_ns () - start def on_execution ( self ) -> Generator [ None , None , None ]: start = perf_counter_ns () try : yield finally : self . execution_timing = perf_counter_ns () - start def resolve ( self , resolver : GraphQLFieldResolver , root : Any , info : GQLInfo , ** kwargs : Any ) -> Any : start = perf_counter_ns () try : return resolver ( root , info , ** kwargs ) finally : key = \".\" . join ( str ( key ) for key in info . path . as_list ()) self . resolver_timings [ key ] = perf_counter_ns () - start","title":"Examples"},{"location":"mutations/","text":"Mutations \ud83d\udd17 In this section, we'll cover Undine's MutationTypes which allow you to create mutations base on your Django Models. For mutations not concerning your Django Models, you can create function Entrypoints . MutationTypes \ud83d\udd17 A MutationType represents a GraphQL InputObjectType for mutating a Django Model in the GraphQL schema. A basic MutationType is created by subclassing MutationType and adding a Django Model to it as a generic type parameter. You must also add at least one Input to the class body of the MutationType . 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () done = Input () Mutation kind \ud83d\udd17 How a mutation using a MutationType resolves is determined by its kind . The basic types of mutations are create , update , and delete , which can be used to create, update and delete instances of a MutationType's Model respectively. There are also two special mutation kinds: custom and related , which are covered in custom mutations and related mutations respectively. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () kind can also be omitted, in which case the MutationType will determine the mutation kind using these rules: If the word create can be found in the name of the MutationType , kind will be create . If the word update can be found in the name of the MutationType , kind will be update . If the word delete can be found in the name of the MutationType , kind will be delete . If either the __mutate__ or __bulk_mutate__ method has been defined on the MutationType , kind will be custom . Otherwise, an error will be raised. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task # Create mutation, since has \"create\" in the name. class TaskCreateMutation ( MutationType [ Task ]): name = Input () Auto-generation \ud83d\udd17 A MutationType can automatically introspect its Django Model and convert the Model's fields to Inputs on the MutationType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL InputObjectType for a MutationType for a create mutation using auto-generation would be: 1 2 3 4 5 input TaskCreateMutation { name : String ! done : Boolean ! = true # `createdAt` not included since it has `auto_now_add=True` } For an update mutation, the pk field is included for selecting the mutation target, the rest of the fields are all made nullable (=not required), and no default values are added. This is essentially a fully partial update mutation. 1 2 3 4 5 input TaskUpdateMutation { pk : Int ! name : String done : Boolean } For a delete mutation, only the pk field is included for selecting the instance to delete. 1 2 3 input TaskDeleteMutation { pk : Int ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the MutationType class definition. With this, you can leave the MutationType class body empty. 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True , exclude = [ \"name\" ]): ... Output type \ud83d\udd17 By default, a MutationType uses a QueryType with the same Model as its output type. This means that one must be created, even if not used for querying outside of the MutationType . You don't need to explicitly link the QueryType to the MutationType since the MutationType will automatically look up the QueryType from the QueryType registry . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task # This QueryType is registered and then used # by TaskCreateMutation as its output type since # they have the same Django Model. class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following mutation in the GraphQL schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } input TaskCreateMutation { name : String ! done : Boolean ! = false } type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } If you wanted to link the QueryType explicitly, you could do so by overriding the __query_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , Input , MutationType , QueryType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __query_type__ ( cls ) -> type [ QueryType ]: return TaskType If you wanted a fully custom output type, you can override the __output_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields ) Permissions \ud83d\udd17 You can add mutation-level permission checks to mutations executed using a MutationType by defining the __permissions__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can create tasks.\" raise GraphQLPermissionError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model. Note that this also means that it doesn't have a primary key yet. For update and delete mutations, instance is the existing model instance that is being mutated. This method will be called for each instance of Task that is mutated by this MutationType . You can raise any GraphQLError when a permission check fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Validation \ud83d\udd17 You can add mutation-level validation to mutations executed using a MutationType by defining the __validate__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if len ( input_data [ \"name\" ]) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model. Note that this also means that it doesn't have a primary key yet. For update and delete mutations, instance is the existing model instance that is being mutated. You can raise any GraphQLError when a validation check fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module. After mutation handling \ud83d\udd17 You can add custom handling that happens after the mutation is done by defining the __after__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : pass # Some post-mutation handling here About method signature For create and update mutations, instance is the model instance that was either created or updated. For delete mutations, instance is the instance that was deleted. This means that its relations have been disconnected, and its primary key has been set to None . input_data contains the input data that was used in the mutation. This can be useful for doing things like sending emails. Custom mutations \ud83d\udd17 You can define your own custom logic by defining the __mutate__ or __bulk_mutate__ method on the MutationType class for single or bulk mutations respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance @classmethod def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> list [ Task ]: # Some custom bulk mutation logic here return instances In the above example, the MutationType still a create mutation, just with some custom mutation logic. The MutationType kind still affects auto-generation , which resolvers are used (whether the mutation creates a new instance or modifies an existing one), as well as some inference rules for its Inputs . You can also use a special custom mutation kind when using custom resolvers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"custom\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance This affects the creation of the MutationType in the following ways: Auto-generation is not used, even if it is enabled No Input is input-only by default Custom mutations will resolve like create or update mutations, depending on if an Input named pk is present on the MutationType . By default, the output type of a custom mutation is still the ObjectType from the QueryType matching the MutationType's Model. If your custom mutation returns an instance of that Model, it will work without additional changes. However, if you want to return a different type, you can do so by overriding the __output_type__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields ) Related mutations \ud83d\udd17 Let's say you have the following models: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) If you wanted to create both a Task and its related Project in a single mutation, you could link two mutation types using a special related kind of MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProject ) This creates the following InputObjectTypes : 1 2 3 4 5 6 7 8 9 10 input TaskProject { pk : Int name : String } input TaskCreateMutation { name : String ! done : Boolean ! = false project : TaskProject ! } Auto-generation and inference rules for related MutationTypes are the same as for update MutationTypes , except the pk field is also not required. This allows you to create, update, link, or unlink new or existing related models during the mutation as you see fit. Let's give a few examples. Assuming you added the TaskCreateMutation to the schema with an Entrypoint create_task , you can create a new Task together with a new Project like this: 1 2 3 4 5 6 7 8 9 10 11 12 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { pk } } Or you can link an existing Project to a new Task like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { pk name } } Or you can link an existing project while modifying it: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Updated project\" } } ) { pk name } } Permission an validation checks are run for related MutationTypes and their Inputs as well, although existing instances are not fetched from the database even if the input contains its primary key (for performance reasons). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo , input_data : dict [ str , Any ]) -> None : # Some permission check logic here return class TaskCreateMutation ( MutationType [ Task ]): name = Input () project = Input ( TaskProject ) Note that if the Input connecting the related MutationType defines a permission or validation check, that check is run instead of the related MutationType permission or validation check. Related mutation action \ud83d\udd17 When updating an instance and its relations using a related mutation, that instance may already have existing related objects. For some relations, it's clear what should happen to relations that are not selected in the related mutation. Forward one-to-one relation : Selects the new related object to attach to, or set the relation to null. Reverse one-to-one relation can always be missing. Forward foreign key (many-to-one) relation : Selects the new related object to attach to, or set the relation to null. Reverse relations do not have any constraints. Many-to-many relations : Selects the new related objects that the current instance should be linked to. Non-selected objects are unlinked, meaning through table rows are deleted. For other relations, you might need different behavior depending on the situation: Reverse one-to-one relation : You might want to delete the exiting related object, or set the relation to null (although the forward part of the relation might not be nullable). Reverse foreign key (one-to-many) relation : You might want to delete exiting related objects, or set their relation to null (although the forward part of the relation might not be nullable). You might even want to leave the existing relations as they are. The action that should be taken for the relations is defined by the MutationType related_action argument. The actions are as follows: null : Set the relaton to null. If the relation is not nullable, an error is raised. Default action. delete : Delete the related objects. ignore : Leave the existing relations as they are. For one-to-one relations, an error is raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Input , MutationType from .models import Project , Task class ProjectTask ( MutationType [ Task ], kind = \"related\" ): pk = Input () name = Input () class ProjectUpdateMutation ( MutationType [ Project ], related_action = \"delete\" ): pk = Input () name = Input () done = Input () tasks = Input ( ProjectTask ) Note that this action applies to all related mutations executed from the \"parent\" MutationType . If you need more granular control, you should make the mutation a custom mutation instead. Order of operations \ud83d\udd17 The order of operations for executing a mutation using a MutationType is as follows: Model inputs have their Model instances fetched. Hidden inputs are be added to the input data. Function inputs are run. MutationType permissions and Input permissions are checked. MutationType validation and Input validation are run. Input-only inputs are removed from the input data. Mutation is executed. MutationType after handling is run. If multiple GraphQLErrors are raised in the permission or validation steps for different inputs, those errors are returned together. The error's path will point to the Input where the exception was raised. Example result with multiple errors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"name\" ] }, { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"done\" ] } ] } Schema name \ud83d\udd17 By default, the name of the generated GraphQL InputObjectType for a MutationType class is the name of the MutationType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], schema_name = \"CreateTask\" ): name = Input () Description \ud83d\udd17 To provide a description for the MutationType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): \"\"\"Description.\"\"\" name = Input () Directives \ud83d\udd17 You can add directives to the MutationType by providing them using the directives argument. The directive must be usable in the INPUT_OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskCreateMutation ( MutationType [ Task ], directives = [ MyDirective ()]): name = Input () You can also add them using the decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... @MyDirective () class TaskCreateMutation ( MutationType [ Task ]): name = Input () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a MutationType from certain users using the __is_visible__ method. Hiding an MutationType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint or Input using the MutationType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the MutationType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Input () MutationType extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The MutationType itself is found in the GraphQL InputObjectType extensions under a key defined by the MUTATION_TYPE_EXTENSIONS_KEY setting. Inputs \ud83d\udd17 An Input is used to define a possible input in a MutationType . Usually Inputs correspond to fields on the Django Model for their respective MutationType . In GraphQL, an Input represents a GraphQLInputField on an InputObjectType . An Input always requires a reference from which it will create the proper input type and default value for the Input . Model field references \ud83d\udd17 For Inputs corresponding to Django Model fields, the Input can be used without passing in a reference, as its attribute name in the MutationType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( Task . name ) Function references \ud83d\udd17 Functions (or methods) can also be used to create Inputs . This can be done by decorating a method with the Input class. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : return value . upper () About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the Model instance that is being mutated. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument determines the input given by the user, which can then be transformed into the input data for the mutation in the function. The type of the value argument determines the input type of the function input in. The value argument can also be left out, in which case the input will become a hidden input. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def current_user ( self , info : GQLInfo ) -> int | None : return info . context . user . id Model references \ud83d\udd17 A Model class can also be used as an Input reference. In this case, a Model instance will be fetched to the input data from a primary key provided to the Input before permission and validation checks (see order of operation ). If an instance is not found, the Input will raise an error before any other checks are run. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Project , Task class TaskCreateMutation ( MutationType [ Task ]): project = Input ( Project ) The Model doesn't necessarily need to be a related Model of the parent MutationType Model, but if it is not, the input will be an input-only input by default. Permissions \ud83d\udd17 You can restrict the use of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can set task names.\" raise GraphQLPermissionError ( msg ) About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Validation \ud83d\udd17 You can validate the value of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.validate decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module. Conversion \ud83d\udd17 Normally, values for Inputs are parsed and converted based on the Input's Scalar . However, you can add additional convertion for an individual Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.convert decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . convert def convert_name ( self , value : str ) -> str : return value . upper () About method signature The self argument is not an instance of the MutationType , but the Input whose value is being converted. The value argument is the value provided for the Input . Note that conversion functions are also run for default values . Default values \ud83d\udd17 By default, an Input is able to determine its default value based on its reference. For example, for a Model field , the default value is taken from its default attribute. However, default values are only added automatically for create mutations, as update mutations should only update fields that have been provided. If you want to set the default value for an Input manually, you can set the default_value argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( default_value = \"New task\" ) Note that the default value needs to be a valid GraphQL default value, i.e., a string, integer, float, boolean, or null, or a list or dictionary of these. Note that you, indeed, can use lists and dictionaries as default values, even though they are mutable. Undine will make a copy of any non-hashable default value before mutating it, so that you won't accidentally change the default value. Input-only inputs \ud83d\udd17 Input-only Inputs show up in the GraphQL schema, but their values are removed from the mutation data before the actual mutation (see order of operations ), usually because they are not part of the Model being mutated. They can be used as additional data for validation and permissions checks, e.g. flags to control the behavior of the mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): logging_enabled = Input ( bool , input_only = True ) @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data . get ( \"logging_enabled\" ): print ( \"Logging enabled\" ) Notice that the Input reference is bool . This is to indicate the input type, as there is no Model field to infer the type from. Hidden inputs \ud83d\udd17 Hidden Inputs are not included in the GraphQL schema, but their values are added before the mutation is executed (see order of operations ). They can be used, for example, to set default values for fields that should not be overridden by users. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( hidden = True , default_value = \"New task\" ) One common use case for hidden inputs is to set the current user as the default value for a relational field. Let's suppose that the Task model has a foreign key user to the User Model. To assign a new task to the current user during creation, you can define a hidden input for the user field: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.contrib.auth.models import User from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def user ( self , info : GQLInfo ) -> User | None : if info . context . user . is_anonymous : return None return info . context . user See Function References for more details. Required inputs \ud83d\udd17 By default, an Input is able to determine whether it's required or not based on its reference, as well as the kind of MutationType it's used in. If you want to set this manually, you can set the required argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( required = True ) Note that due to GraphQL implementation details, there is no distinction between required and nullable . Therefore, non-required Inputs can always accept null values, and required inputs cannot accept null values. Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django Model field that the Input corresponds to. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): title = Input ( field_name = \"name\" ) This can be useful when the Input has a different name and type in the GraphQL schema than in the Model. Schema name \ud83d\udd17 By default, the name of the InputObjectType field generated from an Input is the same as the name of the Input on the MutationType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the InputObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( schema_name = \"title\" ) This can be useful when the desired name of the InputObjectType field is a Python keyword and cannot be used as the Input attribute name. Descriptions \ud83d\udd17 By default, an Input is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : \"\"\"Name of the task.\"\"\" return value . upper () Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Input as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the Input by providing them using the directives argument. The directive must be usable in the INPUT_FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input () @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Input from certain users by decorating a method with the <input_name>.visible decorator. Hiding an Input means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Input didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the instance of the Input that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Input by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( extensions = { \"foo\" : \"bar\" }) Input extensions are made available in the GraphQL InputObjectType field extensions after the schema is created. The Input itself is found in the GraphQL input field extensions under a key defined by the INPUT_EXTENSIONS_KEY setting. Atomic mutations \ud83d\udd17 If you want to execute multiple mutations in a single operation atomically, you can use the @atomic directive on the mutation. Let's say you have the following schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Project , Task class TaskType ( QueryType [ Task ], auto = True ): ... class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... class ProjectType ( QueryType [ Project ], auto = True ): ... class ProjectCreateMutation ( MutationType [ Project ], auto = True ): ... class Query ( RootType ): tasks = Entrypoint ( TaskType ) projects = Entrypoint ( ProjectType ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) create_project = Entrypoint ( ProjectCreateMutation ) You can create both a Task and a Project atomically by adding the @atomic directive to the mutation: 1 2 3 4 5 6 7 8 mutation ( $taskInput : TaskCreateMutation ! $projectInput : ProjectCreateMutation !) @ atomic { createTask ( input : $taskInput ) { pk } createProject ( input : $projectInput ) { pk } } Now if any of the mutations fail, all created objects during the execution phase of the mutation will be rolled back. Specifically, a rollback will be triggered if any errors are thrown from top-level resolvers of a mutation operation. Note that atomic mutations are not supported when async mode is enabled.","title":"Mutations"},{"location":"mutations/#mutations","text":"In this section, we'll cover Undine's MutationTypes which allow you to create mutations base on your Django Models. For mutations not concerning your Django Models, you can create function Entrypoints .","title":"Mutations"},{"location":"mutations/#mutationtypes","text":"A MutationType represents a GraphQL InputObjectType for mutating a Django Model in the GraphQL schema. A basic MutationType is created by subclassing MutationType and adding a Django Model to it as a generic type parameter. You must also add at least one Input to the class body of the MutationType . 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () done = Input ()","title":"MutationTypes"},{"location":"mutations/#mutation-kind","text":"How a mutation using a MutationType resolves is determined by its kind . The basic types of mutations are create , update , and delete , which can be used to create, update and delete instances of a MutationType's Model respectively. There are also two special mutation kinds: custom and related , which are covered in custom mutations and related mutations respectively. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () kind can also be omitted, in which case the MutationType will determine the mutation kind using these rules: If the word create can be found in the name of the MutationType , kind will be create . If the word update can be found in the name of the MutationType , kind will be update . If the word delete can be found in the name of the MutationType , kind will be delete . If either the __mutate__ or __bulk_mutate__ method has been defined on the MutationType , kind will be custom . Otherwise, an error will be raised. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task # Create mutation, since has \"create\" in the name. class TaskCreateMutation ( MutationType [ Task ]): name = Input ()","title":"Mutation kind"},{"location":"mutations/#auto-generation","text":"A MutationType can automatically introspect its Django Model and convert the Model's fields to Inputs on the MutationType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL InputObjectType for a MutationType for a create mutation using auto-generation would be: 1 2 3 4 5 input TaskCreateMutation { name : String ! done : Boolean ! = true # `createdAt` not included since it has `auto_now_add=True` } For an update mutation, the pk field is included for selecting the mutation target, the rest of the fields are all made nullable (=not required), and no default values are added. This is essentially a fully partial update mutation. 1 2 3 4 5 input TaskUpdateMutation { pk : Int ! name : String done : Boolean } For a delete mutation, only the pk field is included for selecting the instance to delete. 1 2 3 input TaskDeleteMutation { pk : Int ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the MutationType class definition. With this, you can leave the MutationType class body empty. 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True , exclude = [ \"name\" ]): ...","title":"Auto-generation"},{"location":"mutations/#output-type","text":"By default, a MutationType uses a QueryType with the same Model as its output type. This means that one must be created, even if not used for querying outside of the MutationType . You don't need to explicitly link the QueryType to the MutationType since the MutationType will automatically look up the QueryType from the QueryType registry . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task # This QueryType is registered and then used # by TaskCreateMutation as its output type since # they have the same Django Model. class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following mutation in the GraphQL schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } input TaskCreateMutation { name : String ! done : Boolean ! = false } type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } If you wanted to link the QueryType explicitly, you could do so by overriding the __query_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , Input , MutationType , QueryType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __query_type__ ( cls ) -> type [ QueryType ]: return TaskType If you wanted a fully custom output type, you can override the __output_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields )","title":"Output type"},{"location":"mutations/#permissions","text":"You can add mutation-level permission checks to mutations executed using a MutationType by defining the __permissions__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can create tasks.\" raise GraphQLPermissionError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model. Note that this also means that it doesn't have a primary key yet. For update and delete mutations, instance is the existing model instance that is being mutated. This method will be called for each instance of Task that is mutated by this MutationType . You can raise any GraphQLError when a permission check fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module.","title":"Permissions"},{"location":"mutations/#validation","text":"You can add mutation-level validation to mutations executed using a MutationType by defining the __validate__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if len ( input_data [ \"name\" ]) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model. Note that this also means that it doesn't have a primary key yet. For update and delete mutations, instance is the existing model instance that is being mutated. You can raise any GraphQLError when a validation check fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module.","title":"Validation"},{"location":"mutations/#after-mutation-handling","text":"You can add custom handling that happens after the mutation is done by defining the __after__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : pass # Some post-mutation handling here About method signature For create and update mutations, instance is the model instance that was either created or updated. For delete mutations, instance is the instance that was deleted. This means that its relations have been disconnected, and its primary key has been set to None . input_data contains the input data that was used in the mutation. This can be useful for doing things like sending emails.","title":"After mutation handling"},{"location":"mutations/#custom-mutations","text":"You can define your own custom logic by defining the __mutate__ or __bulk_mutate__ method on the MutationType class for single or bulk mutations respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance @classmethod def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> list [ Task ]: # Some custom bulk mutation logic here return instances In the above example, the MutationType still a create mutation, just with some custom mutation logic. The MutationType kind still affects auto-generation , which resolvers are used (whether the mutation creates a new instance or modifies an existing one), as well as some inference rules for its Inputs . You can also use a special custom mutation kind when using custom resolvers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"custom\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance This affects the creation of the MutationType in the following ways: Auto-generation is not used, even if it is enabled No Input is input-only by default Custom mutations will resolve like create or update mutations, depending on if an Input named pk is present on the MutationType . By default, the output type of a custom mutation is still the ObjectType from the QueryType matching the MutationType's Model. If your custom mutation returns an instance of that Model, it will work without additional changes. However, if you want to return a different type, you can do so by overriding the __output_type__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields )","title":"Custom mutations"},{"location":"mutations/#related-mutations","text":"Let's say you have the following models: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) If you wanted to create both a Task and its related Project in a single mutation, you could link two mutation types using a special related kind of MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProject ) This creates the following InputObjectTypes : 1 2 3 4 5 6 7 8 9 10 input TaskProject { pk : Int name : String } input TaskCreateMutation { name : String ! done : Boolean ! = false project : TaskProject ! } Auto-generation and inference rules for related MutationTypes are the same as for update MutationTypes , except the pk field is also not required. This allows you to create, update, link, or unlink new or existing related models during the mutation as you see fit. Let's give a few examples. Assuming you added the TaskCreateMutation to the schema with an Entrypoint create_task , you can create a new Task together with a new Project like this: 1 2 3 4 5 6 7 8 9 10 11 12 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { pk } } Or you can link an existing Project to a new Task like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { pk name } } Or you can link an existing project while modifying it: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Updated project\" } } ) { pk name } } Permission an validation checks are run for related MutationTypes and their Inputs as well, although existing instances are not fetched from the database even if the input contains its primary key (for performance reasons). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo , input_data : dict [ str , Any ]) -> None : # Some permission check logic here return class TaskCreateMutation ( MutationType [ Task ]): name = Input () project = Input ( TaskProject ) Note that if the Input connecting the related MutationType defines a permission or validation check, that check is run instead of the related MutationType permission or validation check.","title":"Related mutations"},{"location":"mutations/#related-mutation-action","text":"When updating an instance and its relations using a related mutation, that instance may already have existing related objects. For some relations, it's clear what should happen to relations that are not selected in the related mutation. Forward one-to-one relation : Selects the new related object to attach to, or set the relation to null. Reverse one-to-one relation can always be missing. Forward foreign key (many-to-one) relation : Selects the new related object to attach to, or set the relation to null. Reverse relations do not have any constraints. Many-to-many relations : Selects the new related objects that the current instance should be linked to. Non-selected objects are unlinked, meaning through table rows are deleted. For other relations, you might need different behavior depending on the situation: Reverse one-to-one relation : You might want to delete the exiting related object, or set the relation to null (although the forward part of the relation might not be nullable). Reverse foreign key (one-to-many) relation : You might want to delete exiting related objects, or set their relation to null (although the forward part of the relation might not be nullable). You might even want to leave the existing relations as they are. The action that should be taken for the relations is defined by the MutationType related_action argument. The actions are as follows: null : Set the relaton to null. If the relation is not nullable, an error is raised. Default action. delete : Delete the related objects. ignore : Leave the existing relations as they are. For one-to-one relations, an error is raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Input , MutationType from .models import Project , Task class ProjectTask ( MutationType [ Task ], kind = \"related\" ): pk = Input () name = Input () class ProjectUpdateMutation ( MutationType [ Project ], related_action = \"delete\" ): pk = Input () name = Input () done = Input () tasks = Input ( ProjectTask ) Note that this action applies to all related mutations executed from the \"parent\" MutationType . If you need more granular control, you should make the mutation a custom mutation instead.","title":"Related mutation action"},{"location":"mutations/#order-of-operations","text":"The order of operations for executing a mutation using a MutationType is as follows: Model inputs have their Model instances fetched. Hidden inputs are be added to the input data. Function inputs are run. MutationType permissions and Input permissions are checked. MutationType validation and Input validation are run. Input-only inputs are removed from the input data. Mutation is executed. MutationType after handling is run. If multiple GraphQLErrors are raised in the permission or validation steps for different inputs, those errors are returned together. The error's path will point to the Input where the exception was raised. Example result with multiple errors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"name\" ] }, { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"done\" ] } ] }","title":"Order of operations"},{"location":"mutations/#schema-name","text":"By default, the name of the generated GraphQL InputObjectType for a MutationType class is the name of the MutationType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], schema_name = \"CreateTask\" ): name = Input ()","title":"Schema name"},{"location":"mutations/#description","text":"To provide a description for the MutationType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): \"\"\"Description.\"\"\" name = Input ()","title":"Description"},{"location":"mutations/#directives","text":"You can add directives to the MutationType by providing them using the directives argument. The directive must be usable in the INPUT_OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskCreateMutation ( MutationType [ Task ], directives = [ MyDirective ()]): name = Input () You can also add them using the decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... @MyDirective () class TaskCreateMutation ( MutationType [ Task ]): name = Input () See the Directives section for more details on directives.","title":"Directives"},{"location":"mutations/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a MutationType from certain users using the __is_visible__ method. Hiding an MutationType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint or Input using the MutationType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"mutations/#graphql-extensions","text":"You can provide custom extensions for the MutationType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Input () MutationType extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The MutationType itself is found in the GraphQL InputObjectType extensions under a key defined by the MUTATION_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"mutations/#inputs","text":"An Input is used to define a possible input in a MutationType . Usually Inputs correspond to fields on the Django Model for their respective MutationType . In GraphQL, an Input represents a GraphQLInputField on an InputObjectType . An Input always requires a reference from which it will create the proper input type and default value for the Input .","title":"Inputs"},{"location":"mutations/#model-field-references","text":"For Inputs corresponding to Django Model fields, the Input can be used without passing in a reference, as its attribute name in the MutationType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( Task . name )","title":"Model field references"},{"location":"mutations/#function-references","text":"Functions (or methods) can also be used to create Inputs . This can be done by decorating a method with the Input class. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : return value . upper () About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the Model instance that is being mutated. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument determines the input given by the user, which can then be transformed into the input data for the mutation in the function. The type of the value argument determines the input type of the function input in. The value argument can also be left out, in which case the input will become a hidden input. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def current_user ( self , info : GQLInfo ) -> int | None : return info . context . user . id","title":"Function references"},{"location":"mutations/#model-references","text":"A Model class can also be used as an Input reference. In this case, a Model instance will be fetched to the input data from a primary key provided to the Input before permission and validation checks (see order of operation ). If an instance is not found, the Input will raise an error before any other checks are run. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Project , Task class TaskCreateMutation ( MutationType [ Task ]): project = Input ( Project ) The Model doesn't necessarily need to be a related Model of the parent MutationType Model, but if it is not, the input will be an input-only input by default.","title":"Model references"},{"location":"mutations/#permissions_1","text":"You can restrict the use of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can set task names.\" raise GraphQLPermissionError ( msg ) About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module.","title":"Permissions"},{"location":"mutations/#validation_1","text":"You can validate the value of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.validate decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module.","title":"Validation"},{"location":"mutations/#conversion","text":"Normally, values for Inputs are parsed and converted based on the Input's Scalar . However, you can add additional convertion for an individual Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.convert decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . convert def convert_name ( self , value : str ) -> str : return value . upper () About method signature The self argument is not an instance of the MutationType , but the Input whose value is being converted. The value argument is the value provided for the Input . Note that conversion functions are also run for default values .","title":"Conversion"},{"location":"mutations/#default-values","text":"By default, an Input is able to determine its default value based on its reference. For example, for a Model field , the default value is taken from its default attribute. However, default values are only added automatically for create mutations, as update mutations should only update fields that have been provided. If you want to set the default value for an Input manually, you can set the default_value argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( default_value = \"New task\" ) Note that the default value needs to be a valid GraphQL default value, i.e., a string, integer, float, boolean, or null, or a list or dictionary of these. Note that you, indeed, can use lists and dictionaries as default values, even though they are mutable. Undine will make a copy of any non-hashable default value before mutating it, so that you won't accidentally change the default value.","title":"Default values"},{"location":"mutations/#input-only-inputs","text":"Input-only Inputs show up in the GraphQL schema, but their values are removed from the mutation data before the actual mutation (see order of operations ), usually because they are not part of the Model being mutated. They can be used as additional data for validation and permissions checks, e.g. flags to control the behavior of the mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): logging_enabled = Input ( bool , input_only = True ) @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data . get ( \"logging_enabled\" ): print ( \"Logging enabled\" ) Notice that the Input reference is bool . This is to indicate the input type, as there is no Model field to infer the type from.","title":"Input-only inputs"},{"location":"mutations/#hidden-inputs","text":"Hidden Inputs are not included in the GraphQL schema, but their values are added before the mutation is executed (see order of operations ). They can be used, for example, to set default values for fields that should not be overridden by users. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( hidden = True , default_value = \"New task\" ) One common use case for hidden inputs is to set the current user as the default value for a relational field. Let's suppose that the Task model has a foreign key user to the User Model. To assign a new task to the current user during creation, you can define a hidden input for the user field: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.contrib.auth.models import User from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def user ( self , info : GQLInfo ) -> User | None : if info . context . user . is_anonymous : return None return info . context . user See Function References for more details.","title":"Hidden inputs"},{"location":"mutations/#required-inputs","text":"By default, an Input is able to determine whether it's required or not based on its reference, as well as the kind of MutationType it's used in. If you want to set this manually, you can set the required argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( required = True ) Note that due to GraphQL implementation details, there is no distinction between required and nullable . Therefore, non-required Inputs can always accept null values, and required inputs cannot accept null values.","title":"Required inputs"},{"location":"mutations/#field-name","text":"A field_name can be provided to explicitly set the Django Model field that the Input corresponds to. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): title = Input ( field_name = \"name\" ) This can be useful when the Input has a different name and type in the GraphQL schema than in the Model.","title":"Field name"},{"location":"mutations/#schema-name_1","text":"By default, the name of the InputObjectType field generated from an Input is the same as the name of the Input on the MutationType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the InputObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( schema_name = \"title\" ) This can be useful when the desired name of the InputObjectType field is a Python keyword and cannot be used as the Input attribute name.","title":"Schema name"},{"location":"mutations/#descriptions","text":"By default, an Input is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : \"\"\"Name of the task.\"\"\" return value . upper ()","title":"Descriptions"},{"location":"mutations/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Input as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"mutations/#directives_1","text":"You can add directives to the Input by providing them using the directives argument. The directive must be usable in the INPUT_FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input () @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"mutations/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Input from certain users by decorating a method with the <input_name>.visible decorator. Hiding an Input means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Input didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the instance of the Input that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"mutations/#graphql-extensions_1","text":"You can provide custom extensions for the Input by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( extensions = { \"foo\" : \"bar\" }) Input extensions are made available in the GraphQL InputObjectType field extensions after the schema is created. The Input itself is found in the GraphQL input field extensions under a key defined by the INPUT_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"mutations/#atomic-mutations","text":"If you want to execute multiple mutations in a single operation atomically, you can use the @atomic directive on the mutation. Let's say you have the following schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Project , Task class TaskType ( QueryType [ Task ], auto = True ): ... class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... class ProjectType ( QueryType [ Project ], auto = True ): ... class ProjectCreateMutation ( MutationType [ Project ], auto = True ): ... class Query ( RootType ): tasks = Entrypoint ( TaskType ) projects = Entrypoint ( ProjectType ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) create_project = Entrypoint ( ProjectCreateMutation ) You can create both a Task and a Project atomically by adding the @atomic directive to the mutation: 1 2 3 4 5 6 7 8 mutation ( $taskInput : TaskCreateMutation ! $projectInput : ProjectCreateMutation !) @ atomic { createTask ( input : $taskInput ) { pk } createProject ( input : $projectInput ) { pk } } Now if any of the mutations fail, all created objects during the execution phase of the mutation will be rolled back. Specifically, a rollback will be triggered if any errors are thrown from top-level resolvers of a mutation operation. Note that atomic mutations are not supported when async mode is enabled.","title":"Atomic mutations"},{"location":"optimizer/","text":"Optimizer \ud83d\udd17 This section covers Undine's query optimizer, which is responsible for optimizing queries to your GraphQL schema in order to reduce the amount of database queries that are made when resolving a request. The Problems \ud83d\udd17 Before we take a look at how the optimizer works, let's first understand why it exists by going over some common problems that arise when using GraphQL to fetch data from a relational database. The N+1 Problem \ud83d\udd17 Let's say you have a collection of Models like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) description = models . TextField () project = models . ForeignKey ( Project , on_delete = models . CASCADE ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE ) And a schema like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type ProjectType { pk : Int ! name : String ! } type StepType { pk : Int ! name : String ! done : Boolean ! } type TaskType { pk : Int ! name : String ! description : String ! project : ProjectType ! steps : [ StepType !]! } type Query { tasks : [ TaskType !]! } Now, let's say you query tasks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name description project { pk name } steps { pk name done } } } In GraphQL, each field in the query will be resolved separately, and most importantly, if a field returns a list of objects with subfields, the resolvers for those subfields will be called for each object in the list. Normally, a field's resolver knows nothing about the query it is in, and so it only fetches the data it needs. In this case, the top level resolver for tasks will fetch all Task objects, but won't make any joins to related Models its subfields might need. For example, when the subfield for the related Project resolves, that resolver will try to look up the Project from the root Task instance it received, but since the Project was not fetched along with the Task , it needs to make another query to the database. This means that for the whole query we first fetch all Tasks , and then all Projects and Steps for each Task . If we had 100 Tasks , each of which is linked to a Project , but also to 10 Steps . In total this would result in 201 queries to the database! It's important to notice that the amount of queries is proportional to the amount of Tasks in the database. You can imagine how this can get out of hand quickly, especially when you start nesting relations deeper and deeper. Each additional level of nesting will grow the number of queries exponentially! That's why it's called the N+1 problem : 1 query for the root object, and N queries for all subfields, where N is the amount of root objects. Over-fetching \ud83d\udd17 Another issue with resolving Django Models using normal resolvers is that when a Model is fetched from the database, all of its non-relational fields are also fetched by default. This means that we'll fetch fields that are not needed in the query. This can be expensive if the Model has many fields or fields that contain a lot of data. This is called over-fetching , in contrast to the N+1 problem, which is a problem of under-fetching . The Optimizer \ud83d\udd17 Undine includes an optimizer that fixes the above problems automatically by introspecting the incoming query and generating the appropriate QuerySet optimizations like prefetch_related and select_related calls. It plugs into the top-level resolvers in the schema, so in the above example, the resolver for the tasks Entrypoint , and makes the necessary optimizations to reduce the amount of database queries made. This way all subfields can resolve normally, knowing that the data they need is already fetched. For the most part, this is all you need to know about the optimizer. However, there are a few things you need to know to not break these optimizations. Be careful when overriding Field resolvers. If you define a custom resolver for Model field which uses Model data outside of the field itself, those fields may not have been fetched if they are not also part of the query. More generally, you need to be careful when using Models outside of the GraphQL context. A common place where this may happen is in permission checks, which often need to access Model data for object permissions, etc. To deal with this, Undine includes methods to specify additional optimizations manually, see the Manual Optimizations section below. Manual Optimizations \ud83d\udd17 The QueryType.__optimizations__ method is called by the optimizer when an Entrypoint or Field using the given QueryType is included in the query. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) data . add_select_related ( \"project\" , query_type = ProjectType ) data . add_prefetch_related ( \"steps\" , query_type = StepType ) class StepType ( QueryType [ Step ]): ... The <field_name>.optimize method is called by the optimizer when the given Field is included in the query. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) class StepType ( QueryType [ Step ]): ... Optimization data \ud83d\udd17 The OptimizationData object holds the optimizations that the optimizer gathers from the query. You can add new optimizations to the data to ensure that, e.g., required fields are fetched, even if they are otherwise not needed in the query. Let's go over the structure of the OptimizationData object. model \ud83d\udd17 This is the Model class which the optimizations in the data correspond to. Set by the optimizer and should not be modified. info \ud83d\udd17 The resolver info object for the request, as it applies for this OptimizationData . During field resolving, the field_name , field_nodes , return_type and parent_type of the resolver info object are different depending on the ObjectType being resolved, so each OptimizationData needs to know how the resolver info would look when its ObjectType is being resolved. Various methods in Undine get passed this info object so that users of the library can use it do their own introspections. related_field \ud83d\udd17 The related Model field being optimized. Can be None if the OptimizationData is for the root-level. parent \ud83d\udd17 If the OptimizationData is for a related Model, this links to the optimization data of the parent Model. Conversely, the parent OptimizationData has a link this OptimizationData using either select_related , prefetch_related or generic_prefetches . only_fields \ud83d\udd17 Contains fields that will be applied to QuerySet.only() . This prevents the over-fetching issue by only fetching the required fields for the query. If the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is True , these values will be ignored when the optimizations are applied. aliases \ud83d\udd17 Contains the Django ORM expressions that will be applied to QuerySet.alias() . Various methods in Undine can add to these aliases to enable more clearer use of for annotations . annotations \ud83d\udd17 Contains the Django ORM expressions that will be applied to QuerySet.annotate() . Fields that resolve using an expression will store their expression here. select_related \ud83d\udd17 Contains OptimizationData for related fields that should be fetched together using QuerySet.select_related() . New related fields should be added using add_select_related to ensure that the correct references are places in both OptimizationData . prefetch_related \ud83d\udd17 Contains OptimizationData for related fields that should be fetched together using QuerySet.prefetch_related() . New related fields should be added using add_prefetch_related to ensure that the correct references are places in both OptimizationData . Note that the key in the mapping can be either the name of the related field, or an alias that the data should be fetched with (using Prefetch(..., to_attr=<alias>) ). generic_prefetches \ud83d\udd17 Contains OptimizationData for generic foreign keys that should be fetched together using QuerySet.prefetch_related() . New generic prefetches should be added using add_generic_prefetch_related to ensure that the correct references are places in both OptimizationData . filters \ud83d\udd17 Contains Q expressions that will be applied to QuerySet.filter() . Normally, these are compiled from a FilterSet . order_by \ud83d\udd17 Contains OrderBy expressions that will be applied to QuerySet.order_by() . Normally, these are compiled from an OrderSet . distinct \ud83d\udd17 Whether QuerySet.distinct() should be applied. Normally, the optimizer is able to determine this based on the FilterSet Filters used in the query. none \ud83d\udd17 Whether QuerySet.none() should be applied. Note that using QuerySet.none() will result in an empty QuerySet regardless of other optimizations. Normally, this is only applied if a FilterSet Filter raises an EmptyFilterResult exception. pagination \ud83d\udd17 Contains the pagination information for the QuerySet in the form of a PaginationHandler object. Normally, this is set by the optimizer automatically based on if the field uses a pagination or not. queryset_callback \ud83d\udd17 A callback function that initializes the QuerySet for the OptimizationData . By default, this is set to use the Manager.get_queryset() method of the OptimizationData Model default manager, or the QueryType.__get_queryset__ method for related fields to other QueryTypes . pre_filter_callback \ud83d\udd17 A callback function that will be called before order_by , distinct , filters , or field_calculations are applied to the QuerySet . Normally, this is populated using the QueryType.__filter_queryset__ method. post_filter_callback \ud83d\udd17 A callback function that will be called after order_by , distinct , filters , and field_calculations are applied to the QuerySet . Normally, this is populated using the FilterSet.__filter_queryset__ method. field_calculations \ud83d\udd17 A list of Calculation instances that should be run and annotated to the QuerySet . Normally, the optimizer will automatically add Fields using Calculation objects to this list. add_select_related() \ud83d\udd17 A method for adding a new select_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use. This method will make sure that the created select_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well. add_prefetch_related() \ud83d\udd17 A method for adding a new prefetch_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use, as well as a to_attr for the prefetch alias. This method will make sure that the created prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well. The string passed in to_attr will be used in Prefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch many-related fields fetched with aliases or defined using custom schema names. add_generic_prefetch_related() \ud83d\udd17 A method for adding a new generic_prefetch_related optimization. Must provide the field_name for the model relation, the related_model that the generic prefetch should be done for, and optionally a QueryType that the relation should use, and to_attr for the prefetch alias. This method will make sure that the created generic_prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well. The string passed in to_attr will be used in GenericPrefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch generic relations fetched with aliases or defined using custom schema names. Optimization results \ud83d\udd17 Once the whole query has been analyzed, the OptimizationData is processed to OptimizationResults , which can then be applied to the QuerySet . This processing simply copies over most of the data from the OptimizationData , but notably, it also converts any select_related , prefetch_related , or generic_prefetch_related optimizations to values that can be applied to a QuerySet . For select_related , this means either promotion to a prefetch , or extending the related field's optimizations to the parent Model. For example, querying the name of a Project related to a Task will extend the lookup to the Task Model (i.e. project__name ). This lookup is then added to the Task Model's OptimizationResults.only_fields . For prefetch_related , the prefetch OptimizationResults are processed and applied to the queryset taken from OptimizationResults.queryset_callback . The resulting Prefetch() object is added to the parent OptimizationResults.prefetch_related . generic_prefetch_related is processed similarly to prefetch_related , expect a GenericPrefetch() object is created instead. Promotion to prefetch \ud83d\udd17 In certain cases, a select_related optimization must be promoted to a prefetch_related . This can happen for one of the following reasons: Any annotations (or aliases ) are requested from the relation. A prefetch must be made so that the annotation remains available in the related object. Any field_calculations are present. Calculation will become annotations, so the reason is the same as above. A pre_filter_callback or post_filter_callback is needed. Since these callbacks might filter out the related object, a prefetch must be done to ensure this. Note that this might result in a null value for a field that would otherwise not be null! Order of optimizations \ud83d\udd17 OptimizationResults properties are applied to a QuerySet in the following order: If none is True , return an empty QuerySet and exit early. If select_related is not empty, apply them using QuerySet.select_related() . If prefetch_related is not empty, apply them using QuerySet.prefetch_related() . If the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is False , and only_fields is not empty, apply them using QuerySet.only() . If aliases is not empty, apply them using QuerySet.alias() . If annotations is not empty, apply them using QuerySet.annotate() . If pre_filter_callback exists, call it. If order_by is not empty, apply them using QuerySet.order_by() . If distinct is True , call QuerySet.distinct() . If field_calculations are not empty, run them and annotate their results to the QuerySet . If filters is not empty, apply them using QuerySet.filter() If post_filter_callback exists, call it. If pagination data exists, run either pagination.paginate_queryset() or pagination.paginate_prefetch_queryset() depending on whether a related_field exists or not. Return the optimized QuerySet .","title":"Optimizer"},{"location":"optimizer/#optimizer","text":"This section covers Undine's query optimizer, which is responsible for optimizing queries to your GraphQL schema in order to reduce the amount of database queries that are made when resolving a request.","title":"Optimizer"},{"location":"optimizer/#the-problems","text":"Before we take a look at how the optimizer works, let's first understand why it exists by going over some common problems that arise when using GraphQL to fetch data from a relational database.","title":"The Problems"},{"location":"optimizer/#the-n1-problem","text":"Let's say you have a collection of Models like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) description = models . TextField () project = models . ForeignKey ( Project , on_delete = models . CASCADE ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE ) And a schema like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type ProjectType { pk : Int ! name : String ! } type StepType { pk : Int ! name : String ! done : Boolean ! } type TaskType { pk : Int ! name : String ! description : String ! project : ProjectType ! steps : [ StepType !]! } type Query { tasks : [ TaskType !]! } Now, let's say you query tasks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name description project { pk name } steps { pk name done } } } In GraphQL, each field in the query will be resolved separately, and most importantly, if a field returns a list of objects with subfields, the resolvers for those subfields will be called for each object in the list. Normally, a field's resolver knows nothing about the query it is in, and so it only fetches the data it needs. In this case, the top level resolver for tasks will fetch all Task objects, but won't make any joins to related Models its subfields might need. For example, when the subfield for the related Project resolves, that resolver will try to look up the Project from the root Task instance it received, but since the Project was not fetched along with the Task , it needs to make another query to the database. This means that for the whole query we first fetch all Tasks , and then all Projects and Steps for each Task . If we had 100 Tasks , each of which is linked to a Project , but also to 10 Steps . In total this would result in 201 queries to the database! It's important to notice that the amount of queries is proportional to the amount of Tasks in the database. You can imagine how this can get out of hand quickly, especially when you start nesting relations deeper and deeper. Each additional level of nesting will grow the number of queries exponentially! That's why it's called the N+1 problem : 1 query for the root object, and N queries for all subfields, where N is the amount of root objects.","title":"The N+1 Problem"},{"location":"optimizer/#over-fetching","text":"Another issue with resolving Django Models using normal resolvers is that when a Model is fetched from the database, all of its non-relational fields are also fetched by default. This means that we'll fetch fields that are not needed in the query. This can be expensive if the Model has many fields or fields that contain a lot of data. This is called over-fetching , in contrast to the N+1 problem, which is a problem of under-fetching .","title":"Over-fetching"},{"location":"optimizer/#the-optimizer","text":"Undine includes an optimizer that fixes the above problems automatically by introspecting the incoming query and generating the appropriate QuerySet optimizations like prefetch_related and select_related calls. It plugs into the top-level resolvers in the schema, so in the above example, the resolver for the tasks Entrypoint , and makes the necessary optimizations to reduce the amount of database queries made. This way all subfields can resolve normally, knowing that the data they need is already fetched. For the most part, this is all you need to know about the optimizer. However, there are a few things you need to know to not break these optimizations. Be careful when overriding Field resolvers. If you define a custom resolver for Model field which uses Model data outside of the field itself, those fields may not have been fetched if they are not also part of the query. More generally, you need to be careful when using Models outside of the GraphQL context. A common place where this may happen is in permission checks, which often need to access Model data for object permissions, etc. To deal with this, Undine includes methods to specify additional optimizations manually, see the Manual Optimizations section below.","title":"The Optimizer"},{"location":"optimizer/#manual-optimizations","text":"The QueryType.__optimizations__ method is called by the optimizer when an Entrypoint or Field using the given QueryType is included in the query. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) data . add_select_related ( \"project\" , query_type = ProjectType ) data . add_prefetch_related ( \"steps\" , query_type = StepType ) class StepType ( QueryType [ Step ]): ... The <field_name>.optimize method is called by the optimizer when the given Field is included in the query. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) class StepType ( QueryType [ Step ]): ...","title":"Manual Optimizations"},{"location":"optimizer/#optimization-data","text":"The OptimizationData object holds the optimizations that the optimizer gathers from the query. You can add new optimizations to the data to ensure that, e.g., required fields are fetched, even if they are otherwise not needed in the query. Let's go over the structure of the OptimizationData object.","title":"Optimization data"},{"location":"optimizer/#model","text":"This is the Model class which the optimizations in the data correspond to. Set by the optimizer and should not be modified.","title":"model"},{"location":"optimizer/#info","text":"The resolver info object for the request, as it applies for this OptimizationData . During field resolving, the field_name , field_nodes , return_type and parent_type of the resolver info object are different depending on the ObjectType being resolved, so each OptimizationData needs to know how the resolver info would look when its ObjectType is being resolved. Various methods in Undine get passed this info object so that users of the library can use it do their own introspections.","title":"info"},{"location":"optimizer/#related_field","text":"The related Model field being optimized. Can be None if the OptimizationData is for the root-level.","title":"related_field"},{"location":"optimizer/#parent","text":"If the OptimizationData is for a related Model, this links to the optimization data of the parent Model. Conversely, the parent OptimizationData has a link this OptimizationData using either select_related , prefetch_related or generic_prefetches .","title":"parent"},{"location":"optimizer/#only_fields","text":"Contains fields that will be applied to QuerySet.only() . This prevents the over-fetching issue by only fetching the required fields for the query. If the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is True , these values will be ignored when the optimizations are applied.","title":"only_fields"},{"location":"optimizer/#aliases","text":"Contains the Django ORM expressions that will be applied to QuerySet.alias() . Various methods in Undine can add to these aliases to enable more clearer use of for annotations .","title":"aliases"},{"location":"optimizer/#annotations","text":"Contains the Django ORM expressions that will be applied to QuerySet.annotate() . Fields that resolve using an expression will store their expression here.","title":"annotations"},{"location":"optimizer/#select_related","text":"Contains OptimizationData for related fields that should be fetched together using QuerySet.select_related() . New related fields should be added using add_select_related to ensure that the correct references are places in both OptimizationData .","title":"select_related"},{"location":"optimizer/#prefetch_related","text":"Contains OptimizationData for related fields that should be fetched together using QuerySet.prefetch_related() . New related fields should be added using add_prefetch_related to ensure that the correct references are places in both OptimizationData . Note that the key in the mapping can be either the name of the related field, or an alias that the data should be fetched with (using Prefetch(..., to_attr=<alias>) ).","title":"prefetch_related"},{"location":"optimizer/#generic_prefetches","text":"Contains OptimizationData for generic foreign keys that should be fetched together using QuerySet.prefetch_related() . New generic prefetches should be added using add_generic_prefetch_related to ensure that the correct references are places in both OptimizationData .","title":"generic_prefetches"},{"location":"optimizer/#filters","text":"Contains Q expressions that will be applied to QuerySet.filter() . Normally, these are compiled from a FilterSet .","title":"filters"},{"location":"optimizer/#order_by","text":"Contains OrderBy expressions that will be applied to QuerySet.order_by() . Normally, these are compiled from an OrderSet .","title":"order_by"},{"location":"optimizer/#distinct","text":"Whether QuerySet.distinct() should be applied. Normally, the optimizer is able to determine this based on the FilterSet Filters used in the query.","title":"distinct"},{"location":"optimizer/#none","text":"Whether QuerySet.none() should be applied. Note that using QuerySet.none() will result in an empty QuerySet regardless of other optimizations. Normally, this is only applied if a FilterSet Filter raises an EmptyFilterResult exception.","title":"none"},{"location":"optimizer/#pagination","text":"Contains the pagination information for the QuerySet in the form of a PaginationHandler object. Normally, this is set by the optimizer automatically based on if the field uses a pagination or not.","title":"pagination"},{"location":"optimizer/#queryset_callback","text":"A callback function that initializes the QuerySet for the OptimizationData . By default, this is set to use the Manager.get_queryset() method of the OptimizationData Model default manager, or the QueryType.__get_queryset__ method for related fields to other QueryTypes .","title":"queryset_callback"},{"location":"optimizer/#pre_filter_callback","text":"A callback function that will be called before order_by , distinct , filters , or field_calculations are applied to the QuerySet . Normally, this is populated using the QueryType.__filter_queryset__ method.","title":"pre_filter_callback"},{"location":"optimizer/#post_filter_callback","text":"A callback function that will be called after order_by , distinct , filters , and field_calculations are applied to the QuerySet . Normally, this is populated using the FilterSet.__filter_queryset__ method.","title":"post_filter_callback"},{"location":"optimizer/#field_calculations","text":"A list of Calculation instances that should be run and annotated to the QuerySet . Normally, the optimizer will automatically add Fields using Calculation objects to this list.","title":"field_calculations"},{"location":"optimizer/#add_select_related","text":"A method for adding a new select_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use. This method will make sure that the created select_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well.","title":"add_select_related()"},{"location":"optimizer/#add_prefetch_related","text":"A method for adding a new prefetch_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use, as well as a to_attr for the prefetch alias. This method will make sure that the created prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well. The string passed in to_attr will be used in Prefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch many-related fields fetched with aliases or defined using custom schema names.","title":"add_prefetch_related()"},{"location":"optimizer/#add_generic_prefetch_related","text":"A method for adding a new generic_prefetch_related optimization. Must provide the field_name for the model relation, the related_model that the generic prefetch should be done for, and optionally a QueryType that the relation should use, and to_attr for the prefetch alias. This method will make sure that the created generic_prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType as well. The string passed in to_attr will be used in GenericPrefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch generic relations fetched with aliases or defined using custom schema names.","title":"add_generic_prefetch_related()"},{"location":"optimizer/#optimization-results","text":"Once the whole query has been analyzed, the OptimizationData is processed to OptimizationResults , which can then be applied to the QuerySet . This processing simply copies over most of the data from the OptimizationData , but notably, it also converts any select_related , prefetch_related , or generic_prefetch_related optimizations to values that can be applied to a QuerySet . For select_related , this means either promotion to a prefetch , or extending the related field's optimizations to the parent Model. For example, querying the name of a Project related to a Task will extend the lookup to the Task Model (i.e. project__name ). This lookup is then added to the Task Model's OptimizationResults.only_fields . For prefetch_related , the prefetch OptimizationResults are processed and applied to the queryset taken from OptimizationResults.queryset_callback . The resulting Prefetch() object is added to the parent OptimizationResults.prefetch_related . generic_prefetch_related is processed similarly to prefetch_related , expect a GenericPrefetch() object is created instead.","title":"Optimization results"},{"location":"optimizer/#promotion-to-prefetch","text":"In certain cases, a select_related optimization must be promoted to a prefetch_related . This can happen for one of the following reasons: Any annotations (or aliases ) are requested from the relation. A prefetch must be made so that the annotation remains available in the related object. Any field_calculations are present. Calculation will become annotations, so the reason is the same as above. A pre_filter_callback or post_filter_callback is needed. Since these callbacks might filter out the related object, a prefetch must be done to ensure this. Note that this might result in a null value for a field that would otherwise not be null!","title":"Promotion to prefetch"},{"location":"optimizer/#order-of-optimizations","text":"OptimizationResults properties are applied to a QuerySet in the following order: If none is True , return an empty QuerySet and exit early. If select_related is not empty, apply them using QuerySet.select_related() . If prefetch_related is not empty, apply them using QuerySet.prefetch_related() . If the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is False , and only_fields is not empty, apply them using QuerySet.only() . If aliases is not empty, apply them using QuerySet.alias() . If annotations is not empty, apply them using QuerySet.annotate() . If pre_filter_callback exists, call it. If order_by is not empty, apply them using QuerySet.order_by() . If distinct is True , call QuerySet.distinct() . If field_calculations are not empty, run them and annotate their results to the QuerySet . If filters is not empty, apply them using QuerySet.filter() If post_filter_callback exists, call it. If pagination data exists, run either pagination.paginate_queryset() or pagination.paginate_prefetch_queryset() depending on whether a related_field exists or not. Return the optimized QuerySet .","title":"Order of optimizations"},{"location":"ordering/","text":"Ordering \ud83d\udd17 In this section, we'll cover the everything necessary for ordering results returned by your QueryTypes . OrderSet \ud83d\udd17 An OrderSet is a collection of Order objects that represents an Enum in the GraphQL schema. When added to a QueryType , it creates an input argument (as determined by the QUERY_TYPE_ORDER_INPUT_KEY setting) on any list Entrypoint or many-related Field that is created using that QueryType . That input can then be used to order the results returned by the Entrypoint or Field . A basic OrderSet is created by subclassing OrderSet and adding a Django Model to it as a generic type parameter. You must also add at least one Order to the class body of the OrderSet . Then, the OrderSet can be added to a QueryType using the orderset argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): name = Field () You can also add the OrderSet to the QueryType using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () @TaskOrderSet class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 An OrderSet can automatically introspect its Django Model and convert the Model's fields to Orders on the OrderSet . For example, if the Task Model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) An auto-generated OrderSet has all of the Task Model's fields translated into GraphQL Enum values, both in ascending and descending directions. 1 2 3 4 5 6 7 8 9 10 enum TaskOrderSet { pkAsc pkDesc nameAsc nameDesc doneAsc doneDesc createdAtAsc createdAtDesc } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the OrderSet class definition. With this, you can leave the OrderSet class body empty. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True ): name = Order () Your can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True , exclude = [ \"pk\" ]): ... Schema name \ud83d\udd17 By default, the name of the generated GraphQL Enum for an OrderSet class is the name of the OrderSet class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], schema_name = \"TaskOrderingChoices\" ): name = Order () Description \ud83d\udd17 You can provide a description for the OrderSet by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): \"\"\"Description.\"\"\" name = Order () Directives \ud83d\udd17 You can add directives to an OrderSet by providing them using the directives argument. The directive must be usable in the ENUM location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ MyDirective ()]): name = Order () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... @MyDirective () class TaskOrderSet ( OrderSet [ Task ]): name = Order () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an OrderSet from certain users by using the __is_visible__ method. Hiding the OrderSet means that it will not be included in introspection queries for that user, and trying to use it in operations will result in an error that looks exactly like the argument for the OrderSet didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the OrderSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the OrderSet . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Order () OrderSet extensions are made available in the GraphQL Enum extensions after the schema is created. The OrderSet itself is found in the GraphQL Enum extensions under a key defined by the ORDERSET_EXTENSIONS_KEY setting. Order \ud83d\udd17 An Order defines a way of ordering the results returned by an Entrypoint or Field using a QueryType . An Order corresponds to anything that can be passed to a queryset.order_by() call, usually a field on the Django Model of the OrderSet it belongs to. In GraphQL, an Order represent two EnumValues on a GraphQL Enum , one for ordering in ascending direction and one for ordering in descending direction. An Order always requires a reference which it will use to create the Django OrderBy expression for the Order . Model field references \ud83d\udd17 For Orders corresponding to Django Model fields, the Order can be used without passing in a reference, as its attribute name in the OrderSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as Filter references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Reverse from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Reverse ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Order , OrderSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskOrderSet ( OrderSet [ Task ]): copies = Order ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Null placement \ud83d\udd17 If the Model field or expression used by the Order is nullable, the null_placement argument can be used to specify the position of null values. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( null_placement = \"first\" ) created_at = Order ( null_placement = \"last\" ) By default, null values are placed according to your database default. Aliases \ud83d\udd17 Sometimes an Order may require additional expressions to be added as aliases to the queryset when the Order is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models.functions import Lower from undine import DjangoExpression , GQLInfo , Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name_lower\" ) @name . aliases def name_lower ( self , info : GQLInfo , * , descending : bool ) -> dict [ str , DjangoExpression ]: return { \"name_lower\" : Lower ( \"name\" )} Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django Model field name that the Order corresponds to. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( field_name = \"name\" ) This can be useful when the Model field corresponding to the Order has a different name and type in the GraphQL schema than on the Model. Schema name \ud83d\udd17 By default, the name of the generated Enum values for an Order use the name of the Order on the OrderSet class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled) as a base, with the full names having \"Asc\" and \"Desc\" suffixes added. If you want to change the base name of the Enum value separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( schema_name = \"title\" ) Description \ud83d\udd17 By default, an Order is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( description = \"Order by task name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () \"\"\"Order by task name.\"\"\" Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Order as deprecated. This is for documentation purposes only, and does not affect the use of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the Order by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order () @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Order from certain users by decorating a method with the <order_name>.visible decorator. Hiding an Order means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Order didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Order by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( extensions = { \"foo\" : \"bar\" }) Order extensions are made available in the GraphQL Enum value extensions after the schema is created. The Order itself is found in the Enum value extensions under a key defined by the ORDER_EXTENSIONS_KEY setting.","title":"Ordering"},{"location":"ordering/#ordering","text":"In this section, we'll cover the everything necessary for ordering results returned by your QueryTypes .","title":"Ordering"},{"location":"ordering/#orderset","text":"An OrderSet is a collection of Order objects that represents an Enum in the GraphQL schema. When added to a QueryType , it creates an input argument (as determined by the QUERY_TYPE_ORDER_INPUT_KEY setting) on any list Entrypoint or many-related Field that is created using that QueryType . That input can then be used to order the results returned by the Entrypoint or Field . A basic OrderSet is created by subclassing OrderSet and adding a Django Model to it as a generic type parameter. You must also add at least one Order to the class body of the OrderSet . Then, the OrderSet can be added to a QueryType using the orderset argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): name = Field () You can also add the OrderSet to the QueryType using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () @TaskOrderSet class TaskType ( QueryType [ Task ]): name = Field ()","title":"OrderSet"},{"location":"ordering/#auto-generation","text":"An OrderSet can automatically introspect its Django Model and convert the Model's fields to Orders on the OrderSet . For example, if the Task Model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) An auto-generated OrderSet has all of the Task Model's fields translated into GraphQL Enum values, both in ascending and descending directions. 1 2 3 4 5 6 7 8 9 10 enum TaskOrderSet { pkAsc pkDesc nameAsc nameDesc doneAsc doneDesc createdAtAsc createdAtDesc } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the OrderSet class definition. With this, you can leave the OrderSet class body empty. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True ): name = Order () Your can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True , exclude = [ \"pk\" ]): ...","title":"Auto-generation"},{"location":"ordering/#schema-name","text":"By default, the name of the generated GraphQL Enum for an OrderSet class is the name of the OrderSet class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], schema_name = \"TaskOrderingChoices\" ): name = Order ()","title":"Schema name"},{"location":"ordering/#description","text":"You can provide a description for the OrderSet by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): \"\"\"Description.\"\"\" name = Order ()","title":"Description"},{"location":"ordering/#directives","text":"You can add directives to an OrderSet by providing them using the directives argument. The directive must be usable in the ENUM location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ MyDirective ()]): name = Order () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... @MyDirective () class TaskOrderSet ( OrderSet [ Task ]): name = Order () See the Directives section for more details on directives.","title":"Directives"},{"location":"ordering/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an OrderSet from certain users by using the __is_visible__ method. Hiding the OrderSet means that it will not be included in introspection queries for that user, and trying to use it in operations will result in an error that looks exactly like the argument for the OrderSet didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"ordering/#graphql-extensions","text":"You can provide custom extensions for the OrderSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the OrderSet . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Order () OrderSet extensions are made available in the GraphQL Enum extensions after the schema is created. The OrderSet itself is found in the GraphQL Enum extensions under a key defined by the ORDERSET_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"ordering/#order","text":"An Order defines a way of ordering the results returned by an Entrypoint or Field using a QueryType . An Order corresponds to anything that can be passed to a queryset.order_by() call, usually a field on the Django Model of the OrderSet it belongs to. In GraphQL, an Order represent two EnumValues on a GraphQL Enum , one for ordering in ascending direction and one for ordering in descending direction. An Order always requires a reference which it will use to create the Django OrderBy expression for the Order .","title":"Order"},{"location":"ordering/#model-field-references","text":"For Orders corresponding to Django Model fields, the Order can be used without passing in a reference, as its attribute name in the OrderSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( \"name\" )","title":"Model field references"},{"location":"ordering/#expression-references","text":"Django ORM expressions can also be used as Filter references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Reverse from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Reverse ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Order , OrderSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskOrderSet ( OrderSet [ Task ]): copies = Order ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"ordering/#null-placement","text":"If the Model field or expression used by the Order is nullable, the null_placement argument can be used to specify the position of null values. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( null_placement = \"first\" ) created_at = Order ( null_placement = \"last\" ) By default, null values are placed according to your database default.","title":"Null placement"},{"location":"ordering/#aliases","text":"Sometimes an Order may require additional expressions to be added as aliases to the queryset when the Order is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models.functions import Lower from undine import DjangoExpression , GQLInfo , Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name_lower\" ) @name . aliases def name_lower ( self , info : GQLInfo , * , descending : bool ) -> dict [ str , DjangoExpression ]: return { \"name_lower\" : Lower ( \"name\" )}","title":"Aliases"},{"location":"ordering/#field-name","text":"A field_name can be provided to explicitly set the Django Model field name that the Order corresponds to. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( field_name = \"name\" ) This can be useful when the Model field corresponding to the Order has a different name and type in the GraphQL schema than on the Model.","title":"Field name"},{"location":"ordering/#schema-name_1","text":"By default, the name of the generated Enum values for an Order use the name of the Order on the OrderSet class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled) as a base, with the full names having \"Asc\" and \"Desc\" suffixes added. If you want to change the base name of the Enum value separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( schema_name = \"title\" )","title":"Schema name"},{"location":"ordering/#description_1","text":"By default, an Order is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( description = \"Order by task name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () \"\"\"Order by task name.\"\"\"","title":"Description"},{"location":"ordering/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Order as deprecated. This is for documentation purposes only, and does not affect the use of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"ordering/#directives_1","text":"You can add directives to the Order by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order () @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"ordering/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Order from certain users by decorating a method with the <order_name>.visible decorator. Hiding an Order means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Order didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"ordering/#graphql-extensions_1","text":"You can provide custom extensions for the Order by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( extensions = { \"foo\" : \"bar\" }) Order extensions are made available in the GraphQL Enum value extensions after the schema is created. The Order itself is found in the Enum value extensions under a key defined by the ORDER_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"pagination/","text":"Pagination \ud83d\udd17 In this section, we'll cover the everything necessary for adding pagination to your GraphQL schema. Undine supports both offset and cursor based pagination. Offset pagination \ud83d\udd17 Offset pagination is the simplest pagination method. It allows paginating a list by specifying an offset from the first item, and a limit for the number of items to return. Offset pagination works well for lists where each item's index never changes, e.g., a list sorted by a timestamp or an auto-incrementing primary key. If this is not the case, you should use cursor based pagination instead, because changes in the middle of the list between page queries can cause items to be skipped or duplicated. To add offset pagination to a QueryType Entrypoint , you need to wrap with the OffsetPagination class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.pagination import OffsetPagination from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( OffsetPagination ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type Query { pagedTasks ( offset : Int limit : Int ) : [ TaskType !]! } Offset pagination can also be used with many-related Fields . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.pagination import OffsetPagination from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( OffsetPagination ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( OffsetPagination ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type PersonType { pk : Int ! name : String ! email : Email ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! assignees ( offset : Int limit : Int ) : [ PersonType !]! } type Query { pagedTasks ( offset : Int limit : Int ) : [ TaskType !]! } Cursor pagination \ud83d\udd17 Cursor based pagination works by assigning items an opaque unique identifier called a \"cursor\". Pages can then be defined as starting before or after a given cursor. This makes cursor based pagination more resilient to changes in the paginated list, since the cursors themselves do not change when items are added or removed. Additionally, cursor based pagination wraps the paginated items as Edge objects inside a Connection object. These objects contain additional information about the pagination state, such as the total count of items, cursor values, or whether a next or previous page exists. For more information on cursor pagination, see the GraphQL Cursor Connections Specification . To add cursor pagination to a QueryType Entrypoint , you need to wrap with the Connection class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type TaskTypeEdge { cursor : String ! node : TaskType } type PageInfo { hasNextPage : Boolean ! hasPreviousPage : Boolean ! startCursor : String endCursor : String } type TaskTypeConnection { totalCount : Int ! pageInfo : PageInfo ! edges : [ TaskTypeEdge !]! } type Query { pagedTasks ( after : String before : String first : Int last : Int ) : TaskTypeConnection ! } Querying this Entrypoint will return a response like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \"data\" : { \"pagedTasks\" : { \"totalCount\" : 3 , \"pageInfo\" : { \"hasNextPage\" : false , \"hasPreviousPage\" : false , \"startCursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"endCursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" }, \"edges\" : [ { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"node\" : { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjE=\" , \"node\" : { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" , \"node\" : { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } } ] } } } Similarly, cursor pagination can also be used with many-related Fields . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.relay import Connection from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( Connection ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) For Relay-compliant clients, see the Global Object IDs section for adding support for the Node interface. Filtering and ordering \ud83d\udd17 If a FilterSet or an OrderSet has been added to a QueryType , their arguments will be added to the Entrypoint along with the pagination arguments for the specific pagination method. For example, for a Connection Entrypoint : 1 2 3 4 5 6 7 8 9 10 type Query { pagedTasks ( after : String before : String first : Int last : Int filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): TaskTypeConnection ! } Page size \ud83d\udd17 The default page size for all pagination methods is set by the PAGINATION_PAGE_SIZE setting. You can also use a different page size by using the page_size argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , page_size = 20 )) Setting page size to None will return all items in a single page. Custom pagination strategies \ud83d\udd17 The default pagination strategies are accurate and performant for both top-level and nested fields (although calculating totalCount for nested Connections can be slow, since it requires a subquery for each parent item). Still, if you need to modify the pagination behavior, you can do so by providing a custom PaginationHandler class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType from undine.pagination import PaginationHandler from undine.relay import Connection from .models import Task class CustomPaginationHandler ( PaginationHandler ): \"\"\"Custom pagination logic.\"\"\" class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , pagination_handler = CustomPaginationHandler ))","title":"Pagination"},{"location":"pagination/#pagination","text":"In this section, we'll cover the everything necessary for adding pagination to your GraphQL schema. Undine supports both offset and cursor based pagination.","title":"Pagination"},{"location":"pagination/#offset-pagination","text":"Offset pagination is the simplest pagination method. It allows paginating a list by specifying an offset from the first item, and a limit for the number of items to return. Offset pagination works well for lists where each item's index never changes, e.g., a list sorted by a timestamp or an auto-incrementing primary key. If this is not the case, you should use cursor based pagination instead, because changes in the middle of the list between page queries can cause items to be skipped or duplicated. To add offset pagination to a QueryType Entrypoint , you need to wrap with the OffsetPagination class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.pagination import OffsetPagination from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( OffsetPagination ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type Query { pagedTasks ( offset : Int limit : Int ) : [ TaskType !]! } Offset pagination can also be used with many-related Fields . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.pagination import OffsetPagination from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( OffsetPagination ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( OffsetPagination ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type PersonType { pk : Int ! name : String ! email : Email ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! assignees ( offset : Int limit : Int ) : [ PersonType !]! } type Query { pagedTasks ( offset : Int limit : Int ) : [ TaskType !]! }","title":"Offset pagination"},{"location":"pagination/#cursor-pagination","text":"Cursor based pagination works by assigning items an opaque unique identifier called a \"cursor\". Pages can then be defined as starting before or after a given cursor. This makes cursor based pagination more resilient to changes in the paginated list, since the cursors themselves do not change when items are added or removed. Additionally, cursor based pagination wraps the paginated items as Edge objects inside a Connection object. These objects contain additional information about the pagination state, such as the total count of items, cursor values, or whether a next or previous page exists. For more information on cursor pagination, see the GraphQL Cursor Connections Specification . To add cursor pagination to a QueryType Entrypoint , you need to wrap with the Connection class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) This creates the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type TaskTypeEdge { cursor : String ! node : TaskType } type PageInfo { hasNextPage : Boolean ! hasPreviousPage : Boolean ! startCursor : String endCursor : String } type TaskTypeConnection { totalCount : Int ! pageInfo : PageInfo ! edges : [ TaskTypeEdge !]! } type Query { pagedTasks ( after : String before : String first : Int last : Int ) : TaskTypeConnection ! } Querying this Entrypoint will return a response like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \"data\" : { \"pagedTasks\" : { \"totalCount\" : 3 , \"pageInfo\" : { \"hasNextPage\" : false , \"hasPreviousPage\" : false , \"startCursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"endCursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" }, \"edges\" : [ { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"node\" : { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjE=\" , \"node\" : { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" , \"node\" : { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } } ] } } } Similarly, cursor pagination can also be used with many-related Fields . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.relay import Connection from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( Connection ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) For Relay-compliant clients, see the Global Object IDs section for adding support for the Node interface.","title":"Cursor pagination"},{"location":"pagination/#filtering-and-ordering","text":"If a FilterSet or an OrderSet has been added to a QueryType , their arguments will be added to the Entrypoint along with the pagination arguments for the specific pagination method. For example, for a Connection Entrypoint : 1 2 3 4 5 6 7 8 9 10 type Query { pagedTasks ( after : String before : String first : Int last : Int filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): TaskTypeConnection ! }","title":"Filtering and ordering"},{"location":"pagination/#page-size","text":"The default page size for all pagination methods is set by the PAGINATION_PAGE_SIZE setting. You can also use a different page size by using the page_size argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , page_size = 20 )) Setting page size to None will return all items in a single page.","title":"Page size"},{"location":"pagination/#custom-pagination-strategies","text":"The default pagination strategies are accurate and performant for both top-level and nested fields (although calculating totalCount for nested Connections can be slow, since it requires a subquery for each parent item). Still, if you need to modify the pagination behavior, you can do so by providing a custom PaginationHandler class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType from undine.pagination import PaginationHandler from undine.relay import Connection from .models import Task class CustomPaginationHandler ( PaginationHandler ): \"\"\"Custom pagination logic.\"\"\" class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , pagination_handler = CustomPaginationHandler ))","title":"Custom pagination strategies"},{"location":"persisted-documents/","text":"Persisted Documents \ud83d\udd17 In this section, we'll cover Undine's support for persisted documents , which offer a way to persist known GraphQL documents on the server for caching, reducing network traffic, or to use as an operation allow-list. Installation \ud83d\udd17 To enable persisted documents, you must first add the undine.persisted_documents app to your INSTALLED_APPS : 1 2 3 4 5 6 INSTALLED_APPS = [ # ... \"undine\" , \"undine.persisted_documents\" , # ... ] Then, add the persisted document registration view to your URLconf: 1 2 3 4 5 6 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), path ( \"\" , include ( \"undine.persisted_documents.urls\" )), ] Before running migrations, you should have a look at the PersistedDocument Model in undine.persisted_documents.model . This Model can be swapped out with your own implementation using the UNDINE_PERSISTED_DOCUMENTS_MODEL setting, similar to how the User model can be swapped out with AUTH_USER_MODEL . Whether you decide to do this or not, remember to run migrations afterwards. Usage \ud83d\udd17 Once the app is installed, Undine is ready to accept persisted documents. Persisted documents work through the same GraphQL endpoint used for regular GraphQL requests, but instead of a query string, you must provide a documentId instead. 1 2 3 4 { \"documentId\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"variables\" : {} } A documentId can be obtained by registering a new persisted document using the persisted document registration view, as specified by the PERSISTED_DOCUMENTS_PATH setting. The view accepts a dictionary of documents like this 1 2 3 4 5 6 { \"documents\" : { \"foo\" : \"query { example }\" , \"bar\" : \"query { testing }\" } } ...and returns a dictionary of documentIds like this 1 2 3 4 5 6 7 8 { \"data\" : { \"documents\" : { \"foo\" : \"sha256:1ce1ad479d1905f8d89262a1bccb87b9b4fe6b85161cd8cecb00b87d21d8889f\" , \"bar\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" } } } ...where each key in the documents dictionary is defined by the user, so that a documentId corresponding to a document is returned in the same key. The keys are not used for anything else. Response for this view follows the GraphQL response format , so any errors are returned in the \"errors\" key. 1 2 3 4 5 6 7 8 9 10 11 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error\" , \"extensions\" : { \"status_code\" : 400 } } ] } Note that a document with the same selection set produces a different documentId if they have different whitespace, newlines, or comments. This is to ensure that error locations stay consistent. Permissions \ud83d\udd17 You'll likely want to protect the persisted documents registration view with a permission check so that only some users can register new persisted documents. This can be done by setting the PERSISTED_DOCUMENTS_PERMISSION_CALLBACK setting to a function that accepts a request and a document_map as arguments. 1 2 3 4 5 6 7 8 9 from django.http import HttpRequest from undine.exceptions import GraphQLPermissionError def persisted_documents_permissions ( request : HttpRequest , document_map : dict [ str , str ]) -> None : if not request . user . is_superuser : msg = \"You do not have permission to register persisted documents.\" raise GraphQLPermissionError ( msg ) Allow-list mode \ud83d\udd17 Persisted documents can be used to create an allow-list for GraphQL operations. Usually this is done to enhance security of a system by preventing malicious queries from being executed. Undine can be configured to only accept persisted documents by setting the PERSISTED_DOCUMENTS_ONLY setting to True . 1 2 3 UNDINE = { \"PERSISTED_DOCUMENTS_ONLY\" : True , } When operating in this mode, your clients should call PersistedDocumentsView during build time to register their queries and mutations.","title":"Persisted Documents"},{"location":"persisted-documents/#persisted-documents","text":"In this section, we'll cover Undine's support for persisted documents , which offer a way to persist known GraphQL documents on the server for caching, reducing network traffic, or to use as an operation allow-list.","title":"Persisted Documents"},{"location":"persisted-documents/#installation","text":"To enable persisted documents, you must first add the undine.persisted_documents app to your INSTALLED_APPS : 1 2 3 4 5 6 INSTALLED_APPS = [ # ... \"undine\" , \"undine.persisted_documents\" , # ... ] Then, add the persisted document registration view to your URLconf: 1 2 3 4 5 6 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), path ( \"\" , include ( \"undine.persisted_documents.urls\" )), ] Before running migrations, you should have a look at the PersistedDocument Model in undine.persisted_documents.model . This Model can be swapped out with your own implementation using the UNDINE_PERSISTED_DOCUMENTS_MODEL setting, similar to how the User model can be swapped out with AUTH_USER_MODEL . Whether you decide to do this or not, remember to run migrations afterwards.","title":"Installation"},{"location":"persisted-documents/#usage","text":"Once the app is installed, Undine is ready to accept persisted documents. Persisted documents work through the same GraphQL endpoint used for regular GraphQL requests, but instead of a query string, you must provide a documentId instead. 1 2 3 4 { \"documentId\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"variables\" : {} } A documentId can be obtained by registering a new persisted document using the persisted document registration view, as specified by the PERSISTED_DOCUMENTS_PATH setting. The view accepts a dictionary of documents like this 1 2 3 4 5 6 { \"documents\" : { \"foo\" : \"query { example }\" , \"bar\" : \"query { testing }\" } } ...and returns a dictionary of documentIds like this 1 2 3 4 5 6 7 8 { \"data\" : { \"documents\" : { \"foo\" : \"sha256:1ce1ad479d1905f8d89262a1bccb87b9b4fe6b85161cd8cecb00b87d21d8889f\" , \"bar\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" } } } ...where each key in the documents dictionary is defined by the user, so that a documentId corresponding to a document is returned in the same key. The keys are not used for anything else. Response for this view follows the GraphQL response format , so any errors are returned in the \"errors\" key. 1 2 3 4 5 6 7 8 9 10 11 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error\" , \"extensions\" : { \"status_code\" : 400 } } ] } Note that a document with the same selection set produces a different documentId if they have different whitespace, newlines, or comments. This is to ensure that error locations stay consistent.","title":"Usage"},{"location":"persisted-documents/#permissions","text":"You'll likely want to protect the persisted documents registration view with a permission check so that only some users can register new persisted documents. This can be done by setting the PERSISTED_DOCUMENTS_PERMISSION_CALLBACK setting to a function that accepts a request and a document_map as arguments. 1 2 3 4 5 6 7 8 9 from django.http import HttpRequest from undine.exceptions import GraphQLPermissionError def persisted_documents_permissions ( request : HttpRequest , document_map : dict [ str , str ]) -> None : if not request . user . is_superuser : msg = \"You do not have permission to register persisted documents.\" raise GraphQLPermissionError ( msg )","title":"Permissions"},{"location":"persisted-documents/#allow-list-mode","text":"Persisted documents can be used to create an allow-list for GraphQL operations. Usually this is done to enhance security of a system by preventing malicious queries from being executed. Undine can be configured to only accept persisted documents by setting the PERSISTED_DOCUMENTS_ONLY setting to True . 1 2 3 UNDINE = { \"PERSISTED_DOCUMENTS_ONLY\" : True , } When operating in this mode, your clients should call PersistedDocumentsView during build time to register their queries and mutations.","title":"Allow-list mode"},{"location":"queries/","text":"Queries \ud83d\udd17 In this section, we'll cover Undine's QueryTypes which allow you to expose your Django Models through the GraphQL schema for querying. For queries not concerning your Django Models, see the function references section in the Schema documentation. QueryTypes \ud83d\udd17 A QueryType represents a GraphQL ObjectType for querying data from a Django Model in the GraphQL schema. A basic QueryType is created by subclassing QueryType and adding a Django Model to it as a generic type parameter. You must also add at least one Field to the class body of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 A QueryType can automatically introspect its Django Model and convert the Model's fields to Fields on the QueryType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL ObjectType for the QueryType using auto-generation would be: 1 2 3 4 5 6 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the QueryType class definition. With this, you can leave the QueryType class body empty, as fields will be automatically added based on the Django Model. 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True , exclude = [ \"name\" ]): ... Filtering \ud83d\udd17 When a QueryType is used to return multiple items, either in a list Entrypoint or a many-related Field , its results can be filtered in one of two ways: 1) Adding a FilterSet to the QueryType . These are explained in detail in the Filtering section. 2) Defining a __filter_queryset__ classmethod. This method will always be called even if no other filtering is applied to the results. Use it to filter out items that should never be returned by the QueryType , e.g. archived items. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . filter ( archived = False ) Ordering \ud83d\udd17 When a QueryType is used to return multiple items, either in a list Entrypoint or a many-related Field , its results can be ordered in one of two ways: 1) Adding an OrderSet to the QueryType . These are explained in detail in the Ordering section. 2) Defining a __filter_queryset__ classmethod. Same as custom filtering , this ordering is always applied to results returned by the QueryType . However, since queryset ordering is reset when a new ordering is applied to the queryset, ordering added here serves as the default ordering for the QueryType , and is overridden if any ordering is applied using an OrderSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . order_by ( \"name\" ) Permissions \ud83d\udd17 You can add a permission check for querying data from a QueryType by adding a __permissions__ classmethod it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query tasks.\" raise GraphQLPermissionError ( msg ) This method will be called for each instance of Task that is returned by this QueryType in Entrypoints or related Fields . You can raise any GraphQLError when a permission check fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Instead of raising an exception from a permission check, you might want to filter out items the user doesn't have permission to access. You can do this using the __filter_queryset__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_authenticated : return queryset . none () return queryset Now, when the QueryType is used in a list Entrypoint or many related Field , items that the user doesn't have permission to access will be filtered out. For single-item entrypoints or \"to-one\" relations, a null value will be returned instead. Note that you'll need to manually check all Fields and Entrypoints where the QueryType is used and mark them as nullable if they would otherwise not be. If your permissions check requires data from outside of the GraphQL execution context, you should check the Optimizer section on how you can make sure permissions checks don't cause an excessive database queries. QueryType registry \ud83d\udd17 When a new QueryType is created, Undine automatically registers it for its given Model. This allows other QueryTypes to look up the QueryType for linking related Fields (see relations ), and MutationTypes to find out their matching output type (see mutation output types ). The QueryType registry only allows one QueryType to be registered for each Model. During QueryType registration, if a QueryType is already registered for the Model, an error will be raised. If you need to create multiple QueryTypes for the same Model, you can choose to not register a QueryType in the registry by setting the register argument to False in the QueryType class definition. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () class OtherTaskType ( QueryType [ Task ], register = False ): pk = Field () You'll then need to use this QueryType explicitly when required. Custom optimizations \ud83d\udd17 The optimizer is covered more thoroughly in the Optimizer section. Usually adding QueryType optimizations is not necessary, but if required, you can override the __optimizations__ classmethod on the QueryType to do so. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks. Schema name \ud83d\udd17 By default, the name of the generated GraphQL ObjectType for a QueryType class is the name of the QueryType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], schema_name = \"Task\" ): name = Field () Description \ud83d\udd17 You can provide a description for the QueryType by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): \"\"\"Description.\"\"\" name = Field () Interfaces \ud83d\udd17 You can add interfaces to the QueryType by providing them using the interfaces argument. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): name = Field () You can also add interfaces using decorator syntax. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from undine.relay import Node from .models import Task @Node class TaskType ( QueryType [ Task ]): name = Field () See the Interfaces section for more details on interfaces. Directives \ud83d\udd17 You can add directives to the QueryType by providing them using the directives argument. The directive must be usable in the OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class TaskType ( QueryType [ Task ], directives = [ MyDirective ()]): name = Field () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... @MyDirective () class TaskType ( QueryType [ Task ]): name = Field () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a QueryType from certain users by using the __is_visible__ method. Hiding the QueryType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint or Field using the QueryType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the QueryType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Field () QueryType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the GraphQL ObjectType extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting. Fields \ud83d\udd17 A Field is used to define a queryable value on a QueryType . Usually Fields correspond to fields on the Django Model for their respective QueryType . In GraphQL, a Field represents a GraphQLField on an ObjectType . A Field always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the Field . Model field references \ud83d\udd17 For Fields corresponding to Django Model fields, the Field can be used without passing in a reference, as its attribute name in the QueryType class body can be used to identify the corresponding Model field. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( Task . name ) Being explicit like this is only required if the name of the field in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as references. These create an annotation on the Model instances when fetched. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): upper_name = Field ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Field , QueryType from undine.utils.model_utils import SubqueryCount from .models import Task class TaskType ( QueryType [ Task ]): copies = Field ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Function references \ud83d\udd17 Functions (or methods) can also be used to create Fields . This can be done by decorating a method with the Field class. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo ) -> str : return \"Hello World!\" The Field will use the decorated method as its GraphQL resolver. The method's return type will be used as the output type for the Field , so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the Model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Arguments added to the function signatures will be added as Field arguments in the GraphQL schema. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo , * , name : str ) -> str : return f \"Hello, { name } !\" If the method requires fields from the root instance, you should add custom optimization rules for the Field so that the fields are available when the resolver is called. See custom optimizations for how to add these, although it might be simpler to use a Calculation reference . Calculation references \ud83d\udd17 A Calculation reference is like a combination of function references and expression references . They can accept data from input arguments like a function reference, and return an expression that should be annotated to a queryset like an expression reference. A Calculation references can be created by subclassing the Calculation class and adding the required CalculationArguments to its class body. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import Value from undine import Calculation , CalculationArgument , DjangoExpression , Field , GQLInfo , QueryType from .models import Task class ExampleCalculation ( Calculation [ int ]): value = CalculationArgument ( int ) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : # Some impressive calculation here return Value ( self . value ) class TaskType ( QueryType [ Task ]): calc = Field ( ExampleCalculation ) Calculation objects always require the generic type argument to be set, which describes the return type of the calculation. This should be a python type matching the Django ORM expression that is returned in the __call__ method. CalculationArguments can be defined in the class body of the Calculation class. These define the input arguments for the calculation. When the calculation is executed, the CalculationArguments can be used to access the input data for that specific argument. The __call__ method should always be defined in the Calculation class. This should return a Django ORM expression that can be annotated to a queryset. You may access other fields using F -expressions and use request-specific data from the info argument. The Field will look like this in the GraphQL schema: 1 2 3 type TaskType { calc ( value : Int ! ) : Int ! } A Calculation reference is a good replacement for a function reference when the calculation is expensive enough that resolving it for each field would be slow. However, the calculation needs to be able to be executed in the database since __call__ needs to return a Django ORM expression to be annotated to a queryset. A Calculation reference is a good replacement for an expression reference when the expression requires input data from the request. Relations \ud83d\udd17 Let's say there is a Task model with a ForeignKey to a Project model: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE ) You can then create QueryTypes for both models and add Fields for the related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Field , QueryType from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () The QueryTypes will be linked together in the GraphQL schema by their relations: 1 2 3 4 5 6 7 8 9 10 11 12 13 type ProjectType { pk : Int ! name : String ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! project : ProjectType ! } Undine will make sure that queries between the relations are optimized. Permissions \ud83d\udd17 You can add a permission check for querying any data from an individual Field by decorating a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query task names.\" raise GraphQLPermissionError ( msg ) If Field permissions are defined for a related field, the related QueryType permissions are overridden by the Field permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Project , Task class ProjectType ( QueryType [ Project ]): @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo ) -> None : # Not called if 'ProjectType' is accessed from 'TaskType.project' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class TaskType ( QueryType [ Task ]): project = Field () @project . permissions def project_permissions ( self , info : GQLInfo , value : Project ) -> None : if not info . context . user . is_authenticated : raise GraphQLPermissionError Instead of raising an exception, you might want a failed permission check to result in a null value instead of an error. You can do this overriding the Field's resolver and manually checking the permissions there, returning None when permission is denied. Note that you'll need to manually set the Field as nullable if it would otherwise not be. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = True ) @name . resolve def name_resolver ( self , info : GQLInfo ) -> str | None : if not info . context . user . is_authenticated : return None return self . name Many \ud83d\udd17 By default, a Field is able to determine whether it returns a list of items based on its reference. For example, for a Model field, a ManyToManyField will return a list of items. If you want to configure this manually, you can do so by adding the many argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( many = False ) Nullable \ud83d\udd17 By default, a Field is able to determine whether it's nullable or not based on its reference. For example, for a Model field, nullability is determined from its null attribute. If you want to configure this manually, you can do so by adding the nullable argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = False ) Complexity \ud83d\udd17 The complexity value of a Field is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. By default, a Field is able to determine its complexity based on its reference. For example, a related Model field has a complexity of 1, and a regular Model field has a complexity of 0. If you want to configure this manually, you can do so by adding the complexity argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( complexity = 1 ) Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django Model field that the Field corresponds to. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( field_name = \"name\" ) This can be useful when the Field has a different name and type in the GraphQL schema than in the Model. Schema name \ud83d\udd17 By default, the name of the ObjectType field generated from a Field is the same as the name of the Field on the QueryType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the ObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( schema_name = \"title\" ) This can be useful when the desired name of the ObjectType field is a Python keyword and cannot be used as the Field attribute name. Descriptions \ud83d\udd17 By default, a Field is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Field as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( deprecation_reason = \"Use something else.\" ) Custom resolvers \ud83d\udd17 Usually using a custom Field resolver is not necessary, and should be avoided if possible. This is because use of Model fields in resolvers without additional optimizations can result in a lot of database queries. You can override the resolver for a Field by adding a method to the class body of the QueryType and decorating it with the @<field_name>.resolve decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve def resolve_name ( self , info : GQLInfo ) -> str : return self . name . upper () About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Custom optimizations \ud83d\udd17 The optimizer is covered more thoroughly in the Optimizer section. Usually touching the Field optimizations is not necessary, but if required, you can do so by adding a method to the class body of the QueryType and decorating it with the @<field_name>.optimize decorator. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks. Directives \ud83d\udd17 You can add directives to the Field by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field () @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Field from certain users by decorating a method with the <field_name>.visible decorator. Hiding a Field means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Field didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but the instance of the Field that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Field by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( extensions = { \"foo\" : \"bar\" }) Field extensions are made available in the GraphQL ObjectType field extensions after the schema is created. The QueryType itself is found in the GraphQL field extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"Queries"},{"location":"queries/#queries","text":"In this section, we'll cover Undine's QueryTypes which allow you to expose your Django Models through the GraphQL schema for querying. For queries not concerning your Django Models, see the function references section in the Schema documentation.","title":"Queries"},{"location":"queries/#querytypes","text":"A QueryType represents a GraphQL ObjectType for querying data from a Django Model in the GraphQL schema. A basic QueryType is created by subclassing QueryType and adding a Django Model to it as a generic type parameter. You must also add at least one Field to the class body of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ()","title":"QueryTypes"},{"location":"queries/#auto-generation","text":"A QueryType can automatically introspect its Django Model and convert the Model's fields to Fields on the QueryType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL ObjectType for the QueryType using auto-generation would be: 1 2 3 4 5 6 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the QueryType class definition. With this, you can leave the QueryType class body empty, as fields will be automatically added based on the Django Model. 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... You can exclude some Model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True , exclude = [ \"name\" ]): ...","title":"Auto-generation"},{"location":"queries/#filtering","text":"When a QueryType is used to return multiple items, either in a list Entrypoint or a many-related Field , its results can be filtered in one of two ways: 1) Adding a FilterSet to the QueryType . These are explained in detail in the Filtering section. 2) Defining a __filter_queryset__ classmethod. This method will always be called even if no other filtering is applied to the results. Use it to filter out items that should never be returned by the QueryType , e.g. archived items. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . filter ( archived = False )","title":"Filtering"},{"location":"queries/#ordering","text":"When a QueryType is used to return multiple items, either in a list Entrypoint or a many-related Field , its results can be ordered in one of two ways: 1) Adding an OrderSet to the QueryType . These are explained in detail in the Ordering section. 2) Defining a __filter_queryset__ classmethod. Same as custom filtering , this ordering is always applied to results returned by the QueryType . However, since queryset ordering is reset when a new ordering is applied to the queryset, ordering added here serves as the default ordering for the QueryType , and is overridden if any ordering is applied using an OrderSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . order_by ( \"name\" )","title":"Ordering"},{"location":"queries/#permissions","text":"You can add a permission check for querying data from a QueryType by adding a __permissions__ classmethod it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query tasks.\" raise GraphQLPermissionError ( msg ) This method will be called for each instance of Task that is returned by this QueryType in Entrypoints or related Fields . You can raise any GraphQLError when a permission check fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Instead of raising an exception from a permission check, you might want to filter out items the user doesn't have permission to access. You can do this using the __filter_queryset__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_authenticated : return queryset . none () return queryset Now, when the QueryType is used in a list Entrypoint or many related Field , items that the user doesn't have permission to access will be filtered out. For single-item entrypoints or \"to-one\" relations, a null value will be returned instead. Note that you'll need to manually check all Fields and Entrypoints where the QueryType is used and mark them as nullable if they would otherwise not be. If your permissions check requires data from outside of the GraphQL execution context, you should check the Optimizer section on how you can make sure permissions checks don't cause an excessive database queries.","title":"Permissions"},{"location":"queries/#querytype-registry","text":"When a new QueryType is created, Undine automatically registers it for its given Model. This allows other QueryTypes to look up the QueryType for linking related Fields (see relations ), and MutationTypes to find out their matching output type (see mutation output types ). The QueryType registry only allows one QueryType to be registered for each Model. During QueryType registration, if a QueryType is already registered for the Model, an error will be raised. If you need to create multiple QueryTypes for the same Model, you can choose to not register a QueryType in the registry by setting the register argument to False in the QueryType class definition. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () class OtherTaskType ( QueryType [ Task ], register = False ): pk = Field () You'll then need to use this QueryType explicitly when required.","title":"QueryType registry"},{"location":"queries/#custom-optimizations","text":"The optimizer is covered more thoroughly in the Optimizer section. Usually adding QueryType optimizations is not necessary, but if required, you can override the __optimizations__ classmethod on the QueryType to do so. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks.","title":"Custom optimizations"},{"location":"queries/#schema-name","text":"By default, the name of the generated GraphQL ObjectType for a QueryType class is the name of the QueryType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], schema_name = \"Task\" ): name = Field ()","title":"Schema name"},{"location":"queries/#description","text":"You can provide a description for the QueryType by adding a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): \"\"\"Description.\"\"\" name = Field ()","title":"Description"},{"location":"queries/#interfaces","text":"You can add interfaces to the QueryType by providing them using the interfaces argument. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): name = Field () You can also add interfaces using decorator syntax. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from undine.relay import Node from .models import Task @Node class TaskType ( QueryType [ Task ]): name = Field () See the Interfaces section for more details on interfaces.","title":"Interfaces"},{"location":"queries/#directives","text":"You can add directives to the QueryType by providing them using the directives argument. The directive must be usable in the OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class TaskType ( QueryType [ Task ], directives = [ MyDirective ()]): name = Field () You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... @MyDirective () class TaskType ( QueryType [ Task ]): name = Field () See the Directives section for more details on directives.","title":"Directives"},{"location":"queries/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a QueryType from certain users by using the __is_visible__ method. Hiding the QueryType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint or Field using the QueryType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"queries/#graphql-extensions","text":"You can provide custom extensions for the QueryType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Field () QueryType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the GraphQL ObjectType extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"queries/#fields","text":"A Field is used to define a queryable value on a QueryType . Usually Fields correspond to fields on the Django Model for their respective QueryType . In GraphQL, a Field represents a GraphQLField on an ObjectType . A Field always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the Field .","title":"Fields"},{"location":"queries/#model-field-references","text":"For Fields corresponding to Django Model fields, the Field can be used without passing in a reference, as its attribute name in the QueryType class body can be used to identify the corresponding Model field. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () To be a bit more explicit, you could use a string referencing the Model field: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( \"name\" ) For better type safety, you can also use the Model field itself: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( Task . name ) Being explicit like this is only required if the name of the field in the GraphQL schema is different from the Model field name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( \"name\" )","title":"Model field references"},{"location":"queries/#expression-references","text":"Django ORM expressions can also be used as references. These create an annotation on the Model instances when fetched. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): upper_name = Field ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Field , QueryType from undine.utils.model_utils import SubqueryCount from .models import Task class TaskType ( QueryType [ Task ]): copies = Field ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"queries/#function-references","text":"Functions (or methods) can also be used to create Fields . This can be done by decorating a method with the Field class. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo ) -> str : return \"Hello World!\" The Field will use the decorated method as its GraphQL resolver. The method's return type will be used as the output type for the Field , so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the Model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Arguments added to the function signatures will be added as Field arguments in the GraphQL schema. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo , * , name : str ) -> str : return f \"Hello, { name } !\" If the method requires fields from the root instance, you should add custom optimization rules for the Field so that the fields are available when the resolver is called. See custom optimizations for how to add these, although it might be simpler to use a Calculation reference .","title":"Function references"},{"location":"queries/#calculation-references","text":"A Calculation reference is like a combination of function references and expression references . They can accept data from input arguments like a function reference, and return an expression that should be annotated to a queryset like an expression reference. A Calculation references can be created by subclassing the Calculation class and adding the required CalculationArguments to its class body. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import Value from undine import Calculation , CalculationArgument , DjangoExpression , Field , GQLInfo , QueryType from .models import Task class ExampleCalculation ( Calculation [ int ]): value = CalculationArgument ( int ) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : # Some impressive calculation here return Value ( self . value ) class TaskType ( QueryType [ Task ]): calc = Field ( ExampleCalculation ) Calculation objects always require the generic type argument to be set, which describes the return type of the calculation. This should be a python type matching the Django ORM expression that is returned in the __call__ method. CalculationArguments can be defined in the class body of the Calculation class. These define the input arguments for the calculation. When the calculation is executed, the CalculationArguments can be used to access the input data for that specific argument. The __call__ method should always be defined in the Calculation class. This should return a Django ORM expression that can be annotated to a queryset. You may access other fields using F -expressions and use request-specific data from the info argument. The Field will look like this in the GraphQL schema: 1 2 3 type TaskType { calc ( value : Int ! ) : Int ! } A Calculation reference is a good replacement for a function reference when the calculation is expensive enough that resolving it for each field would be slow. However, the calculation needs to be able to be executed in the database since __call__ needs to return a Django ORM expression to be annotated to a queryset. A Calculation reference is a good replacement for an expression reference when the expression requires input data from the request.","title":"Calculation references"},{"location":"queries/#relations","text":"Let's say there is a Task model with a ForeignKey to a Project model: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE ) You can then create QueryTypes for both models and add Fields for the related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Field , QueryType from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () The QueryTypes will be linked together in the GraphQL schema by their relations: 1 2 3 4 5 6 7 8 9 10 11 12 13 type ProjectType { pk : Int ! name : String ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! project : ProjectType ! } Undine will make sure that queries between the relations are optimized.","title":"Relations"},{"location":"queries/#permissions_1","text":"You can add a permission check for querying any data from an individual Field by decorating a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query task names.\" raise GraphQLPermissionError ( msg ) If Field permissions are defined for a related field, the related QueryType permissions are overridden by the Field permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Project , Task class ProjectType ( QueryType [ Project ]): @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo ) -> None : # Not called if 'ProjectType' is accessed from 'TaskType.project' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class TaskType ( QueryType [ Task ]): project = Field () @project . permissions def project_permissions ( self , info : GQLInfo , value : Project ) -> None : if not info . context . user . is_authenticated : raise GraphQLPermissionError Instead of raising an exception, you might want a failed permission check to result in a null value instead of an error. You can do this overriding the Field's resolver and manually checking the permissions there, returning None when permission is denied. Note that you'll need to manually set the Field as nullable if it would otherwise not be. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = True ) @name . resolve def name_resolver ( self , info : GQLInfo ) -> str | None : if not info . context . user . is_authenticated : return None return self . name","title":"Permissions"},{"location":"queries/#many","text":"By default, a Field is able to determine whether it returns a list of items based on its reference. For example, for a Model field, a ManyToManyField will return a list of items. If you want to configure this manually, you can do so by adding the many argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( many = False )","title":"Many"},{"location":"queries/#nullable","text":"By default, a Field is able to determine whether it's nullable or not based on its reference. For example, for a Model field, nullability is determined from its null attribute. If you want to configure this manually, you can do so by adding the nullable argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = False )","title":"Nullable"},{"location":"queries/#complexity","text":"The complexity value of a Field is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. By default, a Field is able to determine its complexity based on its reference. For example, a related Model field has a complexity of 1, and a regular Model field has a complexity of 0. If you want to configure this manually, you can do so by adding the complexity argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( complexity = 1 )","title":"Complexity"},{"location":"queries/#field-name","text":"A field_name can be provided to explicitly set the Django Model field that the Field corresponds to. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( field_name = \"name\" ) This can be useful when the Field has a different name and type in the GraphQL schema than in the Model.","title":"Field name"},{"location":"queries/#schema-name_1","text":"By default, the name of the ObjectType field generated from a Field is the same as the name of the Field on the QueryType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the ObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( schema_name = \"title\" ) This can be useful when the desired name of the ObjectType field is a Python keyword and cannot be used as the Field attribute name.","title":"Schema name"},{"location":"queries/#descriptions","text":"By default, a Field is able to determine its description based on its reference. For example, for a Model field , the description is taken from its help_text . If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\"","title":"Descriptions"},{"location":"queries/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Field as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"queries/#custom-resolvers","text":"Usually using a custom Field resolver is not necessary, and should be avoided if possible. This is because use of Model fields in resolvers without additional optimizations can result in a lot of database queries. You can override the resolver for a Field by adding a method to the class body of the QueryType and decorating it with the @<field_name>.resolve decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve def resolve_name ( self , info : GQLInfo ) -> str : return self . name . upper () About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation.","title":"Custom resolvers"},{"location":"queries/#custom-optimizations_1","text":"The optimizer is covered more thoroughly in the Optimizer section. Usually touching the Field optimizations is not necessary, but if required, you can do so by adding a method to the class body of the QueryType and decorating it with the @<field_name>.optimize decorator. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks.","title":"Custom optimizations"},{"location":"queries/#directives_1","text":"You can add directives to the Field by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field ( directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field () @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"queries/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Field from certain users by decorating a method with the <field_name>.visible decorator. Hiding a Field means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Field didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but the instance of the Field that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"queries/#graphql-extensions_1","text":"You can provide custom extensions for the Field by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( extensions = { \"foo\" : \"bar\" }) Field extensions are made available in the GraphQL ObjectType field extensions after the schema is created. The QueryType itself is found in the GraphQL field extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"scalars/","text":"Scalars \ud83d\udd17 In this section, we'll cover how GraphQL scalars work in Undine. Scalars are GraphQL types that represent concrete data types like strings, numbers, and booleans. Built-in Scalars \ud83d\udd17 In addition to GraphQL's built-in scalars of Int , Float , String , Boolean , and ID , Undine provides its own scalars that are useful for representing common data types in Python. Any \ud83d\udd17 Represent any value accepted by GraphQL. Used for e.g. for UnionTypes . Base16 \ud83d\udd17 Represents a base16-encoded string as defined in RFC 4648 . Base32 \ud83d\udd17 Represents a base32-encoded string as defined in RFC 4648 . Base64 \ud83d\udd17 Represents a base64-encoded string as defined in RFC 4648 . Date \ud83d\udd17 Represents a date value as specified by ISO 8601. Maps to the Python datetime.date type. See RFC 3339 . DateTime \ud83d\udd17 Represents a date and time value as specified by ISO 8601. Maps to the Python datetime.datetime type. See RFC 3339 . Decimal \ud83d\udd17 Represents a number as a string for correctly rounded floating point arithmetic. Maps to the Python decimal.Decimal type. Duration \ud83d\udd17 Represents a duration of time in seconds. Maps to the Python datetime.timedelta type. Email \ud83d\udd17 Represents a valid email address. See RFC 5322 . File \ud83d\udd17 Represents any kind of file. See the file upload section. IP \ud83d\udd17 Represents a valid IPv4 or IPv6 address. See RFC 8200 . and RFC 791 . IPv4 \ud83d\udd17 Represents a valid IPv4 address. See RFC 791 . IPv6 \ud83d\udd17 Represents a valid IPv6 address. See RFC 8200 . Image \ud83d\udd17 Represents an image file. See the file upload section. JSON \ud83d\udd17 Represents a JSON serializable object. Maps to the Python dict type. See RFC 8259 . Null \ud83d\udd17 Represents represents an always null value. Maps to the Python None value. Time \ud83d\udd17 Represents a time value as specified by ISO 8601. Maps to the Python datetime.time type. See RFC 3339 . URL \ud83d\udd17 Represents a valid URL. See RFC 3986 . UUID \ud83d\udd17 Represents a universally unique identifier string. Maps to Python's uuid.UUID type. See RFC 9562 . Modifying existing scalars \ud83d\udd17 All scalars have two functions that define its operation: parse , which is used to parse incoming data to python types serialize , which is used to serialize python data to GraphQL accepted types For Undine's additional built-in scalars, these functions are single dispatch generic functions . This means that you can register different implementations for the functions which are used depending on the type of the input value. Think of them like a dynamic switch statement. This allows you to replace or extend the behavior of a scalar depending on your use case. For example, you might want to use the whenever library instead or in addition to python's built-in datetime . To do this, you can register a new implementation for the parse function of the DateTime scalar. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from whenever import Instant , PlainDateTime , ZonedDateTime from undine.scalars.datetime import datetime_scalar @datetime_scalar . parse . register def _ ( value : str ) -> ZonedDateTime : # Default \"str\" parse overridden to use 'whenever' return ZonedDateTime . parse_common_iso ( value ) @datetime_scalar . serialize . register def _ ( value : Instant | ZonedDateTime | PlainDateTime ) -> str : # Extend serialization with types from 'whenever'. # Same implementation for all types in the union return value . format_common_iso () Custom scalars \ud83d\udd17 You can also define your own scalars to represent types that cannot be represented by any of Undine's built-in scalars. Let's create a new scalar named Vector3 that represents a 3D vector using a tuple of three integers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from django.core.exceptions import ValidationError from undine.scalars import ScalarType Vector3 = tuple [ int , int , int ] # Create a new ScalarType for our custom scalar. # In `ScalarType[Vector3, str]`, the first type parameter is the type that # the scalar will parse to, and the second the type that it will serialize to. vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , ) # Create the GraphQLScalarType from graphql-core. # This is the actual scalar we can add to our schema. GraphQLVector3 = vector3_scalar . as_graphql_scalar () # Register the parse and serialize functions for our scalar. @vector3_scalar . parse . register def _ ( value : str ) -> Vector3 : try : x , y , z = value . split ( \",\" ) return int ( x . strip ()), int ( y . strip ()), int ( z . strip ()) except ValueError as error : msg = f \"Invalid vector format: { value } \" raise ValidationError ( msg ) from error @vector3_scalar . serialize . register def _ ( value : tuple ) -> str : if len ( value ) != 3 : msg = f \"Vector must have 3 components, got { len ( value ) } \" raise ValidationError ( msg ) if not isinstance ( value [ 0 ], int ): msg = f \"Vector component X is not an integer, got { value [ 0 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 1 ], int ): msg = f \"Vector component Y is not an integer, got { value [ 1 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 2 ], int ): msg = f \"Vector component Z is not an integer, got { value [ 2 ] } \" raise ValidationError ( msg ) return f \" { value [ 0 ] } , { value [ 1 ] } , { value [ 2 ] } \" If Vector3 corresponds to a Django Model field, you could also let Undine know about it by registering it for its many built-in converters. This way a Model field can be converted automatically to your scalar for Fields , Inputs , Filters , and Orders . More on this in the \"Hacking Undine\" section.","title":"Scalars"},{"location":"scalars/#scalars","text":"In this section, we'll cover how GraphQL scalars work in Undine. Scalars are GraphQL types that represent concrete data types like strings, numbers, and booleans.","title":"Scalars"},{"location":"scalars/#built-in-scalars","text":"In addition to GraphQL's built-in scalars of Int , Float , String , Boolean , and ID , Undine provides its own scalars that are useful for representing common data types in Python.","title":"Built-in Scalars"},{"location":"scalars/#any","text":"Represent any value accepted by GraphQL. Used for e.g. for UnionTypes .","title":"Any"},{"location":"scalars/#base16","text":"Represents a base16-encoded string as defined in RFC 4648 .","title":"Base16"},{"location":"scalars/#base32","text":"Represents a base32-encoded string as defined in RFC 4648 .","title":"Base32"},{"location":"scalars/#base64","text":"Represents a base64-encoded string as defined in RFC 4648 .","title":"Base64"},{"location":"scalars/#date","text":"Represents a date value as specified by ISO 8601. Maps to the Python datetime.date type. See RFC 3339 .","title":"Date"},{"location":"scalars/#datetime","text":"Represents a date and time value as specified by ISO 8601. Maps to the Python datetime.datetime type. See RFC 3339 .","title":"DateTime"},{"location":"scalars/#decimal","text":"Represents a number as a string for correctly rounded floating point arithmetic. Maps to the Python decimal.Decimal type.","title":"Decimal"},{"location":"scalars/#duration","text":"Represents a duration of time in seconds. Maps to the Python datetime.timedelta type.","title":"Duration"},{"location":"scalars/#email","text":"Represents a valid email address. See RFC 5322 .","title":"Email"},{"location":"scalars/#file","text":"Represents any kind of file. See the file upload section.","title":"File"},{"location":"scalars/#ip","text":"Represents a valid IPv4 or IPv6 address. See RFC 8200 . and RFC 791 .","title":"IP"},{"location":"scalars/#ipv4","text":"Represents a valid IPv4 address. See RFC 791 .","title":"IPv4"},{"location":"scalars/#ipv6","text":"Represents a valid IPv6 address. See RFC 8200 .","title":"IPv6"},{"location":"scalars/#image","text":"Represents an image file. See the file upload section.","title":"Image"},{"location":"scalars/#json","text":"Represents a JSON serializable object. Maps to the Python dict type. See RFC 8259 .","title":"JSON"},{"location":"scalars/#null","text":"Represents represents an always null value. Maps to the Python None value.","title":"Null"},{"location":"scalars/#time","text":"Represents a time value as specified by ISO 8601. Maps to the Python datetime.time type. See RFC 3339 .","title":"Time"},{"location":"scalars/#url","text":"Represents a valid URL. See RFC 3986 .","title":"URL"},{"location":"scalars/#uuid","text":"Represents a universally unique identifier string. Maps to Python's uuid.UUID type. See RFC 9562 .","title":"UUID"},{"location":"scalars/#modifying-existing-scalars","text":"All scalars have two functions that define its operation: parse , which is used to parse incoming data to python types serialize , which is used to serialize python data to GraphQL accepted types For Undine's additional built-in scalars, these functions are single dispatch generic functions . This means that you can register different implementations for the functions which are used depending on the type of the input value. Think of them like a dynamic switch statement. This allows you to replace or extend the behavior of a scalar depending on your use case. For example, you might want to use the whenever library instead or in addition to python's built-in datetime . To do this, you can register a new implementation for the parse function of the DateTime scalar. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from whenever import Instant , PlainDateTime , ZonedDateTime from undine.scalars.datetime import datetime_scalar @datetime_scalar . parse . register def _ ( value : str ) -> ZonedDateTime : # Default \"str\" parse overridden to use 'whenever' return ZonedDateTime . parse_common_iso ( value ) @datetime_scalar . serialize . register def _ ( value : Instant | ZonedDateTime | PlainDateTime ) -> str : # Extend serialization with types from 'whenever'. # Same implementation for all types in the union return value . format_common_iso ()","title":"Modifying existing scalars"},{"location":"scalars/#custom-scalars","text":"You can also define your own scalars to represent types that cannot be represented by any of Undine's built-in scalars. Let's create a new scalar named Vector3 that represents a 3D vector using a tuple of three integers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from django.core.exceptions import ValidationError from undine.scalars import ScalarType Vector3 = tuple [ int , int , int ] # Create a new ScalarType for our custom scalar. # In `ScalarType[Vector3, str]`, the first type parameter is the type that # the scalar will parse to, and the second the type that it will serialize to. vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , ) # Create the GraphQLScalarType from graphql-core. # This is the actual scalar we can add to our schema. GraphQLVector3 = vector3_scalar . as_graphql_scalar () # Register the parse and serialize functions for our scalar. @vector3_scalar . parse . register def _ ( value : str ) -> Vector3 : try : x , y , z = value . split ( \",\" ) return int ( x . strip ()), int ( y . strip ()), int ( z . strip ()) except ValueError as error : msg = f \"Invalid vector format: { value } \" raise ValidationError ( msg ) from error @vector3_scalar . serialize . register def _ ( value : tuple ) -> str : if len ( value ) != 3 : msg = f \"Vector must have 3 components, got { len ( value ) } \" raise ValidationError ( msg ) if not isinstance ( value [ 0 ], int ): msg = f \"Vector component X is not an integer, got { value [ 0 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 1 ], int ): msg = f \"Vector component Y is not an integer, got { value [ 1 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 2 ], int ): msg = f \"Vector component Z is not an integer, got { value [ 2 ] } \" raise ValidationError ( msg ) return f \" { value [ 0 ] } , { value [ 1 ] } , { value [ 2 ] } \" If Vector3 corresponds to a Django Model field, you could also let Undine know about it by registering it for its many built-in converters. This way a Model field can be converted automatically to your scalar for Fields , Inputs , Filters , and Orders . More on this in the \"Hacking Undine\" section.","title":"Custom scalars"},{"location":"schema/","text":"Schema \ud83d\udd17 In this section, we'll cover how you can set up entrypoints to you GraphQL schema for executing operations in Undine. RootTypes \ud83d\udd17 A GraphQL schema defines a RootType for each kind of operation that it supports. In GraphQL terms, a RootType is just a regular ObjectType that just happens to be the root of the GraphQL Schema. Let's take a look at this example from the Tutorial . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" schema = create_schema ( query = Query ) Here you've created the Query RootType . In Undine, the Query RootType is required to exist for a schema to be created. Each RootType must also have at least one Entrypoint in its class body. As the name implies, the Query RootType is for querying data. For mutating data, you'd create a Mutation RootType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pathlib import Path from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" class Mutation ( RootType ): @Entrypoint def testing ( self ) -> int : return Path ( \"foo.txt\" ) . write_text ( \"Hello, World!\" , encoding = \"utf-8\" ) schema = create_schema ( query = Query , mutation = Mutation ) The Mutation RootType is optional, but if created, it must also include at least one Entrypoint , just like the Query RootType . For Subscription RootTypes , see the Subscriptions section. Schema name \ud83d\udd17 By default, the name of the generated GraphQL ObjectType from a RootType class is the name of the RootType class. If you need to change the name separately, you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , schema_name = \"MyQuery\" ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" Description \ud83d\udd17 To provide a description for the RootType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Entrypoint , RootType class Query ( RootType ): \"\"\"Operations for querying.\"\"\" @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" Directives \ud83d\udd17 You can add directives to the RootType by providing them using the directives argument. The directive must be usable in the OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class Query ( RootType , directives = [ MyDirective ()]): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" You can also add them using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... @MyDirective () class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" See the Directives section for more details on directives. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the RootType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the RootType . 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , extensions = { \"foo\" : \"bar\" }): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" RootType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The RootType itself is found in the GraphQL ObjectType extensions under a key defined by the ROOT_TYPE_EXTENSIONS_KEY setting. Entrypoints \ud83d\udd17 Entrypoints can be thought of as the \"API endpoints inside the GraphQL schema\" from which you can execute operations like queries or mutations. In GraphQL terms, they are the fields on the ObjectType created from a RootType An Entrypoint always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the operation. Function references \ud83d\udd17 Using a function/method as a reference is the most basic way of creating an Entrypoint . Function references can be used for both query and mutation Entrypoints . See the example from the Tutorial . 1 2 3 4 5 6 7 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint def testing ( self , info : GQLInfo ) -> str : return \"Hello World!\" With a function reference, the Entrypoint will use the decorated function as its GraphQL resolver. The function's return type will be used as the Entrypoint's output type, so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. You can add arguments to the Entrypoint by adding them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" This will add a non-null name string argument to the Entrypoint . Note that non-null arguments are required by GraphQL, so if you wanted to make the argument optional, you'd need to make it nullable (in which case it will be None by default) or add a default value ourselves. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str | None = None ) -> str : return f \"Hello, { name or 'World' } !\" You can add a description to the Entrypoint by adding a docstring to the method. If the method has arguments, you can add descriptions to those arguments by using reStructuredText docstrings format . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" What about other docstring formats? Other types of docstrings can be used by parsed by providing a custom parser to the DOCSTRING_PARSER setting that conforms to the DocstringParserProtocol from undine.typing . QueryType references \ud83d\udd17 A QueryType represents a GraphQL ObjectType for querying data from a Django Model. You can read more on QueryTypes in the Queries section. This section will only cover using them in Entrypoints . To create an Entrypoint for querying a single Model instance by its primary key, simply use the QueryType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) This would create the following field in the Query RootType : 1 2 3 type Query { task ( pk : Int ! ) : TaskType } To crete an Entrypoint for listing all instances of the Model, add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) This would create the following field in the Query RootType : 1 2 3 type Query { tasks : [ TaskType !]! } With a list Entrypoint , if a FilterSet or an OrderSet has been added to your QueryType , they will show up as arguments on the Entrypoint . 1 2 3 4 5 6 type Query { tasks ( filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): [ TaskType !]! } MutationType references \ud83d\udd17 A MutationType represents a possible mutation operation based on a Django Model. You can read more on MutationTypes in the Mutations section. This section will only cover using them in Entrypoints . To create an Entrypoint for mutating a single Model instance (a create mutation in this example), simply use the MutationType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } To create an Entrypoint for mutating multiple Model instances in bulk, add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { bulkCreateTask ( input : [ TaskCreateMutation !]!): [ TaskType !]! } Note that the total amount of objects that can be mutated in a bulk mutation is limited by the MUTATION_INSTANCE_LIMIT setting. Nullable \ud83d\udd17 By default, all Entrypoints are non-null (except for function references , which determine nullability from the function's signature). However, you can make an Entrypoint nullable explicitly by using the nullable argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , nullable = True ) Limit \ud83d\udd17 The limit argument is used by Entrypoints based on either QueryTypes , UnionTypes , or InterfaceTypes that return a list of items (i.e. many=True ) to limit the number of objects that are fetched. By default, this is set by the LIST_ENTRYPOINT_LIMIT setting. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , limit = 100 ) Permissions \ud83d\udd17 To add permission checks to your Entrypoint, use the @<entrypoint_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : # Not called if 'TaskType' is accessed from 'Query.task' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) @task . permissions def task_permissions ( self , info : GQLInfo , instance : Task ) -> None : if info . context . user . is_authenticated : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Note that permissions for Entrypoints based on QueryTypes or MutationTypes are checked using that QueryType's or MutationType's permissions if no permission checks have been defined on the Entrypoint . Custom resolver \ud83d\udd17 You can override the resolver for an Entrypoint by decorating a method using the @<entrypoint_name>.resolve decorator. This can be used, e.g., to add special-case Entrypoints for QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.optimizer import optimize_sync from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task_by_name = Entrypoint ( TaskType , nullable = True ) @task_by_name . resolve def resolve_task_by_name ( self , info : GQLInfo , name : str ) -> Task | None : return optimize_sync ( Task . objects . all (), info , name = name ) About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Note that when using this decorator, you'll override the resolver and arguments based on the reference used in the Entrypoint . Arguments will be taken from the additional arguments passed to the resolver, e.g., \"name\" in the example above. When overriding the resolver for Entrypoints based on QueryTypes , the QueryType's FilterSet and OrderSet will not be available on the Entrypoint Overriding the resolver for Entrypoints using MutationTypes is not recommended, as it bypasses the whole mutation process and many MutationType functions will not work. If the resolver returns a Django Model that resolves using QueryType , you should call the optimizer in the resolver using optimize_sync or optimize_async , like in the above example, so that queries are optimized. Schema name \ud83d\udd17 By default, the name of the ObjectType field generated from an Entrypoint is the same as the name of the Entrypoint on the RootType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the ObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , schema_name = \"singleTask\" ) This can be useful when the desired name of the ObjectType field is a Python keyword and cannot be used as the Entrypoint attribute name. Description \ud83d\udd17 By default, an Entrypoint is able to determine its description based on its reference. For example, for a QueryType , the description is taken from the class docstring. If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , description = \"Fetch a single Task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) \"\"\"Fetch a single Task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Entrypoint as deprecated. This is for documentation purposes only and does not affect the use of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , deprecation_reason = \"Use something else.\" ) Complexity \ud83d\udd17 The complexity value of an Entrypoint is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. Usually, complexity is set by QueryType Fields , but you can also set complexity on the Entrypoint itself. This can be useful for declaring complexity of Entrypoints not based on QueryTypes . Note that when the Entrypoint is based on a QueryType , this complexity adds to any complexity calculated from the QueryType's Fields . Directives \ud83d\udd17 You can add directives to the Entrypoint by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) @ MyDirective () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Entrypoint from certain users by decorating a method with the <entrypoint_name>.visible decorator. Hiding an Entrypoint means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType from undine.typing import DjangoRequestProtocol class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" @testing . visible def testing_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but the instance of the Entrypoint that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Entrypoint by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , extensions = { \"foo\" : \"bar\" }) Entrypoint extensions are made available in the GraphQL ObjectType field extensions after the schema is created. The Entrypoint itself is found in the GraphQL field extensions under a key defined by the ENTRYPOINT_EXTENSIONS_KEY setting. Schema export \ud83d\udd17 Undine includes a management command to export your GraphQL schema. It prints the schema to STDOUT , which can be redirected to a file like so: 1 python manage.py print_schema > schema.graphql","title":"Schema"},{"location":"schema/#schema","text":"In this section, we'll cover how you can set up entrypoints to you GraphQL schema for executing operations in Undine.","title":"Schema"},{"location":"schema/#roottypes","text":"A GraphQL schema defines a RootType for each kind of operation that it supports. In GraphQL terms, a RootType is just a regular ObjectType that just happens to be the root of the GraphQL Schema. Let's take a look at this example from the Tutorial . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" schema = create_schema ( query = Query ) Here you've created the Query RootType . In Undine, the Query RootType is required to exist for a schema to be created. Each RootType must also have at least one Entrypoint in its class body. As the name implies, the Query RootType is for querying data. For mutating data, you'd create a Mutation RootType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pathlib import Path from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" class Mutation ( RootType ): @Entrypoint def testing ( self ) -> int : return Path ( \"foo.txt\" ) . write_text ( \"Hello, World!\" , encoding = \"utf-8\" ) schema = create_schema ( query = Query , mutation = Mutation ) The Mutation RootType is optional, but if created, it must also include at least one Entrypoint , just like the Query RootType . For Subscription RootTypes , see the Subscriptions section.","title":"RootTypes"},{"location":"schema/#schema-name","text":"By default, the name of the generated GraphQL ObjectType from a RootType class is the name of the RootType class. If you need to change the name separately, you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , schema_name = \"MyQuery\" ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\"","title":"Schema name"},{"location":"schema/#description","text":"To provide a description for the RootType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Entrypoint , RootType class Query ( RootType ): \"\"\"Operations for querying.\"\"\" @Entrypoint def testing ( self ) -> str : return \"Hello, World!\"","title":"Description"},{"location":"schema/#directives","text":"You can add directives to the RootType by providing them using the directives argument. The directive must be usable in the OBJECT location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class Query ( RootType , directives = [ MyDirective ()]): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" You can also add them using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... @MyDirective () class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" See the Directives section for more details on directives.","title":"Directives"},{"location":"schema/#graphql-extensions","text":"You can provide custom extensions for the RootType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the RootType . 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , extensions = { \"foo\" : \"bar\" }): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" RootType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The RootType itself is found in the GraphQL ObjectType extensions under a key defined by the ROOT_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"schema/#entrypoints","text":"Entrypoints can be thought of as the \"API endpoints inside the GraphQL schema\" from which you can execute operations like queries or mutations. In GraphQL terms, they are the fields on the ObjectType created from a RootType An Entrypoint always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the operation.","title":"Entrypoints"},{"location":"schema/#function-references","text":"Using a function/method as a reference is the most basic way of creating an Entrypoint . Function references can be used for both query and mutation Entrypoints . See the example from the Tutorial . 1 2 3 4 5 6 7 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint def testing ( self , info : GQLInfo ) -> str : return \"Hello World!\" With a function reference, the Entrypoint will use the decorated function as its GraphQL resolver. The function's return type will be used as the Entrypoint's output type, so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. You can add arguments to the Entrypoint by adding them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" This will add a non-null name string argument to the Entrypoint . Note that non-null arguments are required by GraphQL, so if you wanted to make the argument optional, you'd need to make it nullable (in which case it will be None by default) or add a default value ourselves. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str | None = None ) -> str : return f \"Hello, { name or 'World' } !\" You can add a description to the Entrypoint by adding a docstring to the method. If the method has arguments, you can add descriptions to those arguments by using reStructuredText docstrings format . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" What about other docstring formats? Other types of docstrings can be used by parsed by providing a custom parser to the DOCSTRING_PARSER setting that conforms to the DocstringParserProtocol from undine.typing .","title":"Function references"},{"location":"schema/#querytype-references","text":"A QueryType represents a GraphQL ObjectType for querying data from a Django Model. You can read more on QueryTypes in the Queries section. This section will only cover using them in Entrypoints . To create an Entrypoint for querying a single Model instance by its primary key, simply use the QueryType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) This would create the following field in the Query RootType : 1 2 3 type Query { task ( pk : Int ! ) : TaskType } To crete an Entrypoint for listing all instances of the Model, add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) This would create the following field in the Query RootType : 1 2 3 type Query { tasks : [ TaskType !]! } With a list Entrypoint , if a FilterSet or an OrderSet has been added to your QueryType , they will show up as arguments on the Entrypoint . 1 2 3 4 5 6 type Query { tasks ( filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): [ TaskType !]! }","title":"QueryType references"},{"location":"schema/#mutationtype-references","text":"A MutationType represents a possible mutation operation based on a Django Model. You can read more on MutationTypes in the Mutations section. This section will only cover using them in Entrypoints . To create an Entrypoint for mutating a single Model instance (a create mutation in this example), simply use the MutationType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } To create an Entrypoint for mutating multiple Model instances in bulk, add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { bulkCreateTask ( input : [ TaskCreateMutation !]!): [ TaskType !]! } Note that the total amount of objects that can be mutated in a bulk mutation is limited by the MUTATION_INSTANCE_LIMIT setting.","title":"MutationType references"},{"location":"schema/#nullable","text":"By default, all Entrypoints are non-null (except for function references , which determine nullability from the function's signature). However, you can make an Entrypoint nullable explicitly by using the nullable argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , nullable = True )","title":"Nullable"},{"location":"schema/#limit","text":"The limit argument is used by Entrypoints based on either QueryTypes , UnionTypes , or InterfaceTypes that return a list of items (i.e. many=True ) to limit the number of objects that are fetched. By default, this is set by the LIST_ENTRYPOINT_LIMIT setting. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , limit = 100 )","title":"Limit"},{"location":"schema/#permissions","text":"To add permission checks to your Entrypoint, use the @<entrypoint_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : # Not called if 'TaskType' is accessed from 'Query.task' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) @task . permissions def task_permissions ( self , info : GQLInfo , instance : Task ) -> None : if info . context . user . is_authenticated : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Note that permissions for Entrypoints based on QueryTypes or MutationTypes are checked using that QueryType's or MutationType's permissions if no permission checks have been defined on the Entrypoint .","title":"Permissions"},{"location":"schema/#custom-resolver","text":"You can override the resolver for an Entrypoint by decorating a method using the @<entrypoint_name>.resolve decorator. This can be used, e.g., to add special-case Entrypoints for QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.optimizer import optimize_sync from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task_by_name = Entrypoint ( TaskType , nullable = True ) @task_by_name . resolve def resolve_task_by_name ( self , info : GQLInfo , name : str ) -> Task | None : return optimize_sync ( Task . objects . all (), info , name = name ) About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Note that when using this decorator, you'll override the resolver and arguments based on the reference used in the Entrypoint . Arguments will be taken from the additional arguments passed to the resolver, e.g., \"name\" in the example above. When overriding the resolver for Entrypoints based on QueryTypes , the QueryType's FilterSet and OrderSet will not be available on the Entrypoint Overriding the resolver for Entrypoints using MutationTypes is not recommended, as it bypasses the whole mutation process and many MutationType functions will not work. If the resolver returns a Django Model that resolves using QueryType , you should call the optimizer in the resolver using optimize_sync or optimize_async , like in the above example, so that queries are optimized.","title":"Custom resolver"},{"location":"schema/#schema-name_1","text":"By default, the name of the ObjectType field generated from an Entrypoint is the same as the name of the Entrypoint on the RootType class (converted to camelCase if CAMEL_CASE_SCHEMA_FIELDS is enabled). If you want to change the name of the ObjectType field separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , schema_name = \"singleTask\" ) This can be useful when the desired name of the ObjectType field is a Python keyword and cannot be used as the Entrypoint attribute name.","title":"Schema name"},{"location":"schema/#description_1","text":"By default, an Entrypoint is able to determine its description based on its reference. For example, for a QueryType , the description is taken from the class docstring. If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , description = \"Fetch a single Task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) \"\"\"Fetch a single Task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead.","title":"Description"},{"location":"schema/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Entrypoint as deprecated. This is for documentation purposes only and does not affect the use of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"schema/#complexity","text":"The complexity value of an Entrypoint is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. Usually, complexity is set by QueryType Fields , but you can also set complexity on the Entrypoint itself. This can be useful for declaring complexity of Entrypoints not based on QueryTypes . Note that when the Entrypoint is based on a QueryType , this complexity adds to any complexity calculated from the QueryType's Fields .","title":"Complexity"},{"location":"schema/#directives_1","text":"You can add directives to the Entrypoint by providing them using the directives argument. The directive must be usable in the FIELD_DEFINITION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , directives = [ MyDirective ()]) You can also add them using the @ operator (which kind of looks like GraphQL syntax): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) @ MyDirective () See the Directives section for more details on directives.","title":"Directives"},{"location":"schema/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Entrypoint from certain users by decorating a method with the <entrypoint_name>.visible decorator. Hiding an Entrypoint means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the Entrypoint didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType from undine.typing import DjangoRequestProtocol class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" @testing . visible def testing_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but the instance of the Entrypoint that is being used. Since visibility checks occur in the validation phase of the GraphQL request, GraphQL resolver info is not yet available. However, you can access the Django request object using the request argument. From this, you can, e.g., access the request user for permission checks. When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"schema/#graphql-extensions_1","text":"You can provide custom extensions for the Entrypoint by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , extensions = { \"foo\" : \"bar\" }) Entrypoint extensions are made available in the GraphQL ObjectType field extensions after the schema is created. The Entrypoint itself is found in the GraphQL field extensions under a key defined by the ENTRYPOINT_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"schema/#schema-export","text":"Undine includes a management command to export your GraphQL schema. It prints the schema to STDOUT , which can be redirected to a file like so: 1 python manage.py print_schema > schema.graphql","title":"Schema export"},{"location":"settings/","text":"Settings \ud83d\udd17 In this section, we'll cover the settings that can be used to customize Undine. Settings should be set in a dictionary named UNDINE in your settings file, unless otherwise specified. The settings can also be found in the settings file . 1 2 3 UNDINE = { # Settings go here } ADDITIONAL_VALIDATION_RULES Type: list[type[ASTValidationRule]] | Default: [] Additional validation rules to use for validating GraphQL documents (i.e. \"requests\"). Values should be given as the dotted paths to the validation rules used. ALLOW_DID_YOU_MEAN_SUGGESTIONS Type: bool | Default: False Whether to allow the 'did you mean' suggestions on error messages. Disabled by default so that information on the schema structure cannot be gained from error messages when trying to find schema entrypoints through trial and error (a form of security through obscurity). This should be left disabled when using EXPERIMENTAL_VISIBILITY_CHECKS . ALLOW_INTROSPECTION_QUERIES Type bool | Default: False Whether schema introspection queries are allowed or not. Disabled by default so that information on the schema structure cannot be gained through introspection (a form of security through obscurity). Should set this to True if using GraphiQL . ALLOW_QUERIES_WITH_SSE Type: bool | Default: False Whether queries can be executed over Server-Sent Events. ALLOW_MUTATIONS_WITH_SSE Type: bool | Default: False Whether mutations can be executed over Server-Sent Events. ALLOW_QUERIES_WITH_WEBSOCKETS Type: bool | Default: False Whether queries can be executed over WebSockets. ALLOW_MUTATIONS_WITH_WEBSOCKETS Type: bool | Default: False Whether mutations can be executed over WebSockets. ASYNC Type bool | Default: False Whether to use async view for the GraphQL endpoint or not. See Undine's Async documentation for more information. AUTOGENERATION Type bool | Default: False Whether to automatically generate Fields for QueryTypes , Inputs for MutationTypes , Filters for FilterSets , and Orders for OrderSets . Can also be set on an individual QueryType , MutationType , FilterSet , and OrderSet classes. CALCULATION_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_calculation_argument\" The key used to store a CalculationArgument in the extensions of its GraphQLArgument . CAMEL_CASE_SCHEMA_FIELDS Type: bool | Default: True Should field names be converted from 'snake_case' to 'camelCase' for the GraphQL schema? Conversion is not applied if schema_name is set manually in on the Entrypoint , Field , Input , etc. CONNECTION_EXTENSIONS_KEY Type: str | Default: \"undine_connection\" The key used to store a Connection in the extensions of its GraphQLObjectType . DIRECTIVE_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_directive_argument\" The key used to store a DirectiveArgument in the extensions of its GraphQLArgument . DIRECTIVE_EXTENSIONS_KEY Type str | Default: \"undine_directive\" The key used to store a Directive in the extensions of its GraphQLDirective . DISABLE_ONLY_FIELDS_OPTIMIZATION Type bool | Default: False Disable optimizing fetched fields with queryset.only() . DOCSTRING_PARSER Type type[DocstringParserProtocol] | Default: \"undine.parsers.parse_docstring.RSTDocstringParser\" The docstring parser to use to parse function docstrings to schema descriptions. Should be given as the dotted path to the docstring parser class. EMPTY_VALUES Type Container[Any] | Default: (None, \"\", [], {}) By default, if a Filter receives any of these values, that filter will be ignored. Can be changed on per- Filter basis using the empty_values argument. ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS Type bool | Default: False Whether to parse class attribute docstrings or not. Disabled by default to improve performance of the schema creation. ENTRYPOINT_EXTENSIONS_KEY Type str | Default: \"undine_entrypoint\" The key used to store an Entrypoint in the extensions of its GraphQLField . EXECUTION_CONTEXT_CLASS Type type[UndineExecutionContext] | Default: \"undine.execution.UndineExecutionContext\" GraphQL execution context class used by the schema. Should be given as the dotted path to the execution context class. EXPERIMENTAL_VISIBILITY_CHECKS Type: bool | Default: False Whether to enable experimental visibility checks. When enabled, parts of the schema can be hidden from certain users according to specified visibility checks. When a field is not visible to a user, it will not be included in introspection queries and it cannot be used in operations. Note that visibility does not affect \"did you mean\" suggestions, so it's advised to disable these using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting when using this feature. FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_field\" The key used to store a Field in the extensions of its GraphQLField . FILE_UPLOAD_ENABLED Type: bool | Default: False Whether file uploads are enabled. Should enable CSRF protection on the GraphiQL endpoint if enabled. See file uploads for more information. FILTER_EXTENSIONS_KEY Type: str | Default: \"undine_filter\" The key used to store a Filter in the extensions of its GraphQLInputField . FILTERSET_EXTENSIONS_KEY Type: str | Default: \"undine_filterset\" The key used to store a FilterSet in the extensions of its GraphQLInputObjectType . GRAPHIQL_ENABLED Type: bool | Default: False Whether to enable GraphiQL . Should also set ALLOW_INTROSPECTION_QUERIES to True , so that GraphiQL can introspect the GraphQL schema. GRAPHIQL_SSE_ENABLED Type: bool | Default: False Whether GraphiQL uses SSE for subscriptions instead of the built-in WebSocket client. GRAPHIQL_SSE_SINGLE_CONNECTION Type: bool | Default: False Controls whether the SSE subscription client uses single connection mode. Only relevant when GRAPHIQL_SSE_ENABLED is enabled. GRAPHQL_PATH Type: str | Default: \"graphql/\" The URL path where the GraphQL endpoint is located if it's included using path(\"\", include(\"undine.http.urls\")) . GRAPHQL_VIEW_NAME Type: str | Default: \"graphql\" The name given to the GraphQL view in Django's URL resolvers if it's included using path(\"\", include(\"undine.http.urls\")) . INCLUDE_ERROR_TRACEBACK Type: bool | Default: False When a GraphQL request returns an error response, and the error is based on a non-GraphQL exception, if this setting is enabled, the error traceback will be included in the response. Useful for debugging. INPUT_EXTENSIONS_KEY Type: str | Default: \"undine_input\" The key used to store an Input in the extensions of its GraphQLInputField . INTERFACE_FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_interface_field\" The key used to store an InterfaceField in the extensions of its GraphQLField . INTERFACE_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_interface\" The key used to store a InterfaceType in the extensions of its GraphQLInterfaceType . LIFECYCLE_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to use during the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. LIST_ENTRYPOINT_LIMIT Type int | None | Default: None Maximum number of objects that can be returned from a list Entrypoint when not using pagination. If None, all items are fetched. MAX_ALLOWED_ALIASES Type: int | Default: 15 The maximum number of aliases allowed in a single operation. MAX_ALLOWED_DIRECTIVES Type: int | Default: 50 The maximum number of directives allowed in a single operation. MAX_ERRORS Type: int | Default: 100 The maximum number of validation errors allowed in a GraphQL request before it's rejected, even if validation is still not complete. MAX_FILTERS_PER_TYPE Type: int | Default: 20 The maximum number of filters allowed to be used for filtering a single QueryType . MAX_ORDERS_PER_TYPE Type: int | Default: 10 The maximum number of orderings allowed to be used for ordering a single QueryType . MAX_QUERY_COMPLEXITY Type: int | Default: 10 Maximum query complexity that is allowed to be queried in a single operation. See the field complexity documentation for more information. MAX_TOKENS Type int | Default: None Maximum number of GraphQL document tokens the GraphQL parser will parse before it rejects a request. By default, this is set to None which means no limit. MODELTRANSLATION_INCLUDE_TRANSLATABLE Type: bool | Default: False Whether to add translatable fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MODELTRANSLATION_INCLUDE_TRANSLATIONS Type: bool | Default: True Whether to add translation fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MUTATION_FULL_CLEAN Type: bool | Default: True Whether to run model.full_clean() when creating or updating Model using MutationTypes . Turning this off can reduce the number of database queries during mutations, but may introduce issues that would be solved by running full Model validation. MUTATION_INSTANCE_LIMIT Type: int | Default: 100 The maximum number of objects that can be mutated in a single bulk mutation. MUTATION_INPUT_DATA_KEY Type: str | Default: \"input\" The key that the input argument based on a MutationType is added to when said MutationType is used in Entrypoints . MUTATION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_mutation_type\" The key used to store a MutationType in the extensions of its GraphQLInputObjectType . NO_ERROR_LOCATION Type: bool | Default: False Whether to remove error location information to GraphQL errors. OFFSET_PAGINATION_EXTENSIONS_KEY Type: str | Default: \"undine_offset_pagination\" The key used to store an OffsetPagination in the extensions of its GraphQLObjectType . OPTIMIZER_CLASS Type: type[QueryOptimizer] | Default: \"undine.optimizer.optimizer.QueryOptimizer\" The optimizer class to use for optimizing queries. Value should be given as the dotted path to the optimizer class. ORDER_EXTENSIONS_KEY Type: str | Default: \"undine_order\" The key used to store an Order in the extensions of its GraphQLEnumValue . ORDERSET_EXTENSIONS_KEY Type: str | Default: \"undine_orderset\" The key used to store a OrderSet in the extensions of its GraphQLEnumType . PAGINATION_INDEX_KEY Type: str | Default: \"_undine_pagination_index\" The key to which a nested pagination indexes are annotated to. PAGINATION_PAGE_SIZE Type: int | Default: 100 The maximum number of items to return from a page when paginating. PAGINATION_START_INDEX_KEY Type: str | Default: \"_undine_pagination_start\" The key to which a nested pagination start indexes are annotated to. PAGINATION_STOP_INDEX_KEY Type: str | Default: \"_undine_pagination_stop\" The key to which a nested pagination stop indexes are annotated to. PAGINATION_TOTAL_COUNT_KEY Type: str | Default: \"_undine_pagination_total_count\" The key to which a nested pagination total counts are annotated to. PERSISTED_DOCUMENTS_ONLY Type: bool | Default: False Whether to only allow persisted documents to be executed in the GraphQL API. PERSISTED_DOCUMENTS_PATH Type: str | Default: \"persisted-documents/\" The path where the persisted documents registration endpoint is located by default. PERSISTED_DOCUMENTS_PERMISSION_CALLBACK Type: PersistedDocumentsPermissionsCallback | Default: undine.persisted_documents.utils.default_permission_callback The function to use for permission checks for registration of persisted documents. PERSISTED_DOCUMENTS_VIEW_NAME Type: str | Default: \"persisted_documents\" The name of given to the persisted documents registration view in the URLconf. PG_TEXT_SEARCH_PREFIX Type: str | Default: \"_undine_ts_vector\" A prefix to use for the filter aliases of postgres full text search Filters . PREFETCH_HACK_CACHE_KEY Type: str | Default: \"_undine_prefetch_hack_cache\" The key to use for storing the prefetch hack cache in the queryset hints. QUERY_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_query_type\" The key used to store a QueryType in the extensions of its GraphQLObjectType . QUERY_TYPE_FILTER_INPUT_KEY Type: str | Default: \"filter\" The name of the input argument that is created for a FilterSet when a QueryType using that FilterSet is used in a list Entrypoint or many-related Field . QUERY_TYPE_ORDER_INPUT_KEY Type: str | Default: \"orderBy\" The name of the input argument that is created for an OrderSet when a QueryType using that OrderSet is used in a list Entrypoint or many-related Field . RESOLVER_ROOT_PARAM_NAME Type: str | Default: \"root\" The name of the root/parent parameter in Field / Entrypoint resolvers. ROOT_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_root_type\" The key used to store a RootType in the extensions of its GraphQLObjectType . ROOT_VALUE Type: Any | Default: None The root value for the GraphQL execution. Can be accessed by Entrypoint resolvers from the root argument. SCALAR_EXTENSIONS_KEY Type: str | Default: \"undine_scalar\" The key used to store a Undine ScalarType in the extensions of its GraphQLScalarType . SCHEMA Type: GraphQLSchema | Default: \"undine.settings.example_schema\" The file and variable where the GraphQL Schema for Undine is located. Value should be given as the dotted path, usually created using undine.schema.create_schema . SCHEMA_DIRECTIVES_EXTENSIONS_KEY Type: str | Default: \"undine_schema_directives\" The key used to store the schema definition directives in the extensions of its GraphQLSchema . SDL_PRINTER Type: type[SDLPrinter] | Default: \"undine.utils.graphql.sdl_printer.SDLPrinter\" The SDL printer to use. Value should be given as the dotted path to the SDL printer class. SSE_KEEP_ALIVE_INTERVAL Type: int | Default: 12 Interval in seconds for SSE keep-alive pings sent on the event stream. These pings prevent reverse proxies and load balancers from closing idle connections. Set to 0 to disable. SSE_OPERATION_STREAM_OPEN_TIMEOUT Type: int | Default: 30 Timeout in seconds for an operation to wait for the event stream to open (Single Connection mode). SSE_STREAM_SESSION_PREFIX Type: str | Default: \"graphql-over-sse-stream\" Key prefix used to store the GraphQL over SSE stream state in the user's session (Single Connection mode). SSE_TOKEN_HEADER_NAME Type: str | Default: \"X-GraphQL-Event-Stream-Token\" The name of the HTTP header to use for the GraphQL over SSE event stream token (Single Connection mode). SSE_TOKEN_QUERY_PARAM_NAME Type: str | Default: \"token\" The name of the query string parameter to use for the GraphQL over SSE event stream token (Single Connection mode). TESTING_CLIENT_FULL_STACKTRACE Type: bool | Default: False Whether to include the full stacktrace in testing client instead of just the relevant frames when checking where SQL queries are made. TESTING_CLIENT_NO_ASYNC_TIMEOUT Type: bool | Default: False Whether to disable the websocket timeouts in testing client. Can be useful in debugging. TOTAL_COUNT_PARAM_NAME Type: str | Default: \"totalCount\" The name of the parameter in a connection ObjectType for holding the count for the total number of items that can be queried from the connection. UNDINE_PERSISTED_DOCUMENTS_MODEL Type: type[Model] | Default: \"undine.persisted_documents.models.PersistedDocument\" NOTE : This setting should be set in the top level of the settings file, not in the UNDINE dictionary! The model to use for the PersistedDocument model. Works similarly to AUTH_USER_MODEL , so must be set before running migrations for the persisted documents app. UNION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_union_type\" The key used to store a Undine UnionType in the extensions of its GraphQLUnion . USE_SSE_DISTINCT_CONNECTIONS_FOR_HTTP_1 Type: bool | Default: False Whether Server-Sent Events should use distinct connections mode even with a HTTP/1.1 connection. Note that when using HTTP/1.1, the maximum number of open connections is limited to 6 per domain and browser. That means you will likely hit the limit in a real production environment with multiple requests and browser tabs. WEBSOCKET_CONNECTION_INIT_HOOK Type: WebSocketConnectionInitHook | Default: \"undine.utils.graphql.websocket.connection_init_hook\" The function to use for custom ConnectionInit logic. Value should be given as the dotted path to the function. WEBSOCKET_CONNECTION_INIT_TIMEOUT_SECONDS Type: int | Default: 3 The number of seconds to wait for the ConnectionInit message after opening a WebSocket before closing it. WEBSOCKET_PATH Type: str | Default: \"graphql/\" The path where the GraphQL over WebSocket endpoint is located if using undine.integrations.channels.get_websocket_enabled_app . WEBSOCKET_PING_HOOK Type: WebSocketConnectionPingHook | Default: \"undine.utils.graphql.websocket.ping_hook\" The function for specifying custom Ping message logic. Value should be given as the dotted path to the function. WEBSOCKET_PONG_HOOK Type: WebSocketConnectionPongHook | Default: \"undine.utils.graphql.websocket.pong_hook\" The function to for specifying custom Pong message logic. Value should be given as the dotted path to the function.","title":"Settings"},{"location":"settings/#settings","text":"In this section, we'll cover the settings that can be used to customize Undine. Settings should be set in a dictionary named UNDINE in your settings file, unless otherwise specified. The settings can also be found in the settings file . 1 2 3 UNDINE = { # Settings go here } ADDITIONAL_VALIDATION_RULES Type: list[type[ASTValidationRule]] | Default: [] Additional validation rules to use for validating GraphQL documents (i.e. \"requests\"). Values should be given as the dotted paths to the validation rules used. ALLOW_DID_YOU_MEAN_SUGGESTIONS Type: bool | Default: False Whether to allow the 'did you mean' suggestions on error messages. Disabled by default so that information on the schema structure cannot be gained from error messages when trying to find schema entrypoints through trial and error (a form of security through obscurity). This should be left disabled when using EXPERIMENTAL_VISIBILITY_CHECKS . ALLOW_INTROSPECTION_QUERIES Type bool | Default: False Whether schema introspection queries are allowed or not. Disabled by default so that information on the schema structure cannot be gained through introspection (a form of security through obscurity). Should set this to True if using GraphiQL . ALLOW_QUERIES_WITH_SSE Type: bool | Default: False Whether queries can be executed over Server-Sent Events. ALLOW_MUTATIONS_WITH_SSE Type: bool | Default: False Whether mutations can be executed over Server-Sent Events. ALLOW_QUERIES_WITH_WEBSOCKETS Type: bool | Default: False Whether queries can be executed over WebSockets. ALLOW_MUTATIONS_WITH_WEBSOCKETS Type: bool | Default: False Whether mutations can be executed over WebSockets. ASYNC Type bool | Default: False Whether to use async view for the GraphQL endpoint or not. See Undine's Async documentation for more information. AUTOGENERATION Type bool | Default: False Whether to automatically generate Fields for QueryTypes , Inputs for MutationTypes , Filters for FilterSets , and Orders for OrderSets . Can also be set on an individual QueryType , MutationType , FilterSet , and OrderSet classes. CALCULATION_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_calculation_argument\" The key used to store a CalculationArgument in the extensions of its GraphQLArgument . CAMEL_CASE_SCHEMA_FIELDS Type: bool | Default: True Should field names be converted from 'snake_case' to 'camelCase' for the GraphQL schema? Conversion is not applied if schema_name is set manually in on the Entrypoint , Field , Input , etc. CONNECTION_EXTENSIONS_KEY Type: str | Default: \"undine_connection\" The key used to store a Connection in the extensions of its GraphQLObjectType . DIRECTIVE_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_directive_argument\" The key used to store a DirectiveArgument in the extensions of its GraphQLArgument . DIRECTIVE_EXTENSIONS_KEY Type str | Default: \"undine_directive\" The key used to store a Directive in the extensions of its GraphQLDirective . DISABLE_ONLY_FIELDS_OPTIMIZATION Type bool | Default: False Disable optimizing fetched fields with queryset.only() . DOCSTRING_PARSER Type type[DocstringParserProtocol] | Default: \"undine.parsers.parse_docstring.RSTDocstringParser\" The docstring parser to use to parse function docstrings to schema descriptions. Should be given as the dotted path to the docstring parser class. EMPTY_VALUES Type Container[Any] | Default: (None, \"\", [], {}) By default, if a Filter receives any of these values, that filter will be ignored. Can be changed on per- Filter basis using the empty_values argument. ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS Type bool | Default: False Whether to parse class attribute docstrings or not. Disabled by default to improve performance of the schema creation. ENTRYPOINT_EXTENSIONS_KEY Type str | Default: \"undine_entrypoint\" The key used to store an Entrypoint in the extensions of its GraphQLField . EXECUTION_CONTEXT_CLASS Type type[UndineExecutionContext] | Default: \"undine.execution.UndineExecutionContext\" GraphQL execution context class used by the schema. Should be given as the dotted path to the execution context class. EXPERIMENTAL_VISIBILITY_CHECKS Type: bool | Default: False Whether to enable experimental visibility checks. When enabled, parts of the schema can be hidden from certain users according to specified visibility checks. When a field is not visible to a user, it will not be included in introspection queries and it cannot be used in operations. Note that visibility does not affect \"did you mean\" suggestions, so it's advised to disable these using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting when using this feature. FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_field\" The key used to store a Field in the extensions of its GraphQLField . FILE_UPLOAD_ENABLED Type: bool | Default: False Whether file uploads are enabled. Should enable CSRF protection on the GraphiQL endpoint if enabled. See file uploads for more information. FILTER_EXTENSIONS_KEY Type: str | Default: \"undine_filter\" The key used to store a Filter in the extensions of its GraphQLInputField . FILTERSET_EXTENSIONS_KEY Type: str | Default: \"undine_filterset\" The key used to store a FilterSet in the extensions of its GraphQLInputObjectType . GRAPHIQL_ENABLED Type: bool | Default: False Whether to enable GraphiQL . Should also set ALLOW_INTROSPECTION_QUERIES to True , so that GraphiQL can introspect the GraphQL schema. GRAPHIQL_SSE_ENABLED Type: bool | Default: False Whether GraphiQL uses SSE for subscriptions instead of the built-in WebSocket client. GRAPHIQL_SSE_SINGLE_CONNECTION Type: bool | Default: False Controls whether the SSE subscription client uses single connection mode. Only relevant when GRAPHIQL_SSE_ENABLED is enabled. GRAPHQL_PATH Type: str | Default: \"graphql/\" The URL path where the GraphQL endpoint is located if it's included using path(\"\", include(\"undine.http.urls\")) . GRAPHQL_VIEW_NAME Type: str | Default: \"graphql\" The name given to the GraphQL view in Django's URL resolvers if it's included using path(\"\", include(\"undine.http.urls\")) . INCLUDE_ERROR_TRACEBACK Type: bool | Default: False When a GraphQL request returns an error response, and the error is based on a non-GraphQL exception, if this setting is enabled, the error traceback will be included in the response. Useful for debugging. INPUT_EXTENSIONS_KEY Type: str | Default: \"undine_input\" The key used to store an Input in the extensions of its GraphQLInputField . INTERFACE_FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_interface_field\" The key used to store an InterfaceField in the extensions of its GraphQLField . INTERFACE_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_interface\" The key used to store a InterfaceType in the extensions of its GraphQLInterfaceType . LIFECYCLE_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to use during the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. LIST_ENTRYPOINT_LIMIT Type int | None | Default: None Maximum number of objects that can be returned from a list Entrypoint when not using pagination. If None, all items are fetched. MAX_ALLOWED_ALIASES Type: int | Default: 15 The maximum number of aliases allowed in a single operation. MAX_ALLOWED_DIRECTIVES Type: int | Default: 50 The maximum number of directives allowed in a single operation. MAX_ERRORS Type: int | Default: 100 The maximum number of validation errors allowed in a GraphQL request before it's rejected, even if validation is still not complete. MAX_FILTERS_PER_TYPE Type: int | Default: 20 The maximum number of filters allowed to be used for filtering a single QueryType . MAX_ORDERS_PER_TYPE Type: int | Default: 10 The maximum number of orderings allowed to be used for ordering a single QueryType . MAX_QUERY_COMPLEXITY Type: int | Default: 10 Maximum query complexity that is allowed to be queried in a single operation. See the field complexity documentation for more information. MAX_TOKENS Type int | Default: None Maximum number of GraphQL document tokens the GraphQL parser will parse before it rejects a request. By default, this is set to None which means no limit. MODELTRANSLATION_INCLUDE_TRANSLATABLE Type: bool | Default: False Whether to add translatable fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MODELTRANSLATION_INCLUDE_TRANSLATIONS Type: bool | Default: True Whether to add translation fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MUTATION_FULL_CLEAN Type: bool | Default: True Whether to run model.full_clean() when creating or updating Model using MutationTypes . Turning this off can reduce the number of database queries during mutations, but may introduce issues that would be solved by running full Model validation. MUTATION_INSTANCE_LIMIT Type: int | Default: 100 The maximum number of objects that can be mutated in a single bulk mutation. MUTATION_INPUT_DATA_KEY Type: str | Default: \"input\" The key that the input argument based on a MutationType is added to when said MutationType is used in Entrypoints . MUTATION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_mutation_type\" The key used to store a MutationType in the extensions of its GraphQLInputObjectType . NO_ERROR_LOCATION Type: bool | Default: False Whether to remove error location information to GraphQL errors. OFFSET_PAGINATION_EXTENSIONS_KEY Type: str | Default: \"undine_offset_pagination\" The key used to store an OffsetPagination in the extensions of its GraphQLObjectType . OPTIMIZER_CLASS Type: type[QueryOptimizer] | Default: \"undine.optimizer.optimizer.QueryOptimizer\" The optimizer class to use for optimizing queries. Value should be given as the dotted path to the optimizer class. ORDER_EXTENSIONS_KEY Type: str | Default: \"undine_order\" The key used to store an Order in the extensions of its GraphQLEnumValue . ORDERSET_EXTENSIONS_KEY Type: str | Default: \"undine_orderset\" The key used to store a OrderSet in the extensions of its GraphQLEnumType . PAGINATION_INDEX_KEY Type: str | Default: \"_undine_pagination_index\" The key to which a nested pagination indexes are annotated to. PAGINATION_PAGE_SIZE Type: int | Default: 100 The maximum number of items to return from a page when paginating. PAGINATION_START_INDEX_KEY Type: str | Default: \"_undine_pagination_start\" The key to which a nested pagination start indexes are annotated to. PAGINATION_STOP_INDEX_KEY Type: str | Default: \"_undine_pagination_stop\" The key to which a nested pagination stop indexes are annotated to. PAGINATION_TOTAL_COUNT_KEY Type: str | Default: \"_undine_pagination_total_count\" The key to which a nested pagination total counts are annotated to. PERSISTED_DOCUMENTS_ONLY Type: bool | Default: False Whether to only allow persisted documents to be executed in the GraphQL API. PERSISTED_DOCUMENTS_PATH Type: str | Default: \"persisted-documents/\" The path where the persisted documents registration endpoint is located by default. PERSISTED_DOCUMENTS_PERMISSION_CALLBACK Type: PersistedDocumentsPermissionsCallback | Default: undine.persisted_documents.utils.default_permission_callback The function to use for permission checks for registration of persisted documents. PERSISTED_DOCUMENTS_VIEW_NAME Type: str | Default: \"persisted_documents\" The name of given to the persisted documents registration view in the URLconf. PG_TEXT_SEARCH_PREFIX Type: str | Default: \"_undine_ts_vector\" A prefix to use for the filter aliases of postgres full text search Filters . PREFETCH_HACK_CACHE_KEY Type: str | Default: \"_undine_prefetch_hack_cache\" The key to use for storing the prefetch hack cache in the queryset hints. QUERY_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_query_type\" The key used to store a QueryType in the extensions of its GraphQLObjectType . QUERY_TYPE_FILTER_INPUT_KEY Type: str | Default: \"filter\" The name of the input argument that is created for a FilterSet when a QueryType using that FilterSet is used in a list Entrypoint or many-related Field . QUERY_TYPE_ORDER_INPUT_KEY Type: str | Default: \"orderBy\" The name of the input argument that is created for an OrderSet when a QueryType using that OrderSet is used in a list Entrypoint or many-related Field . RESOLVER_ROOT_PARAM_NAME Type: str | Default: \"root\" The name of the root/parent parameter in Field / Entrypoint resolvers. ROOT_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_root_type\" The key used to store a RootType in the extensions of its GraphQLObjectType . ROOT_VALUE Type: Any | Default: None The root value for the GraphQL execution. Can be accessed by Entrypoint resolvers from the root argument. SCALAR_EXTENSIONS_KEY Type: str | Default: \"undine_scalar\" The key used to store a Undine ScalarType in the extensions of its GraphQLScalarType . SCHEMA Type: GraphQLSchema | Default: \"undine.settings.example_schema\" The file and variable where the GraphQL Schema for Undine is located. Value should be given as the dotted path, usually created using undine.schema.create_schema . SCHEMA_DIRECTIVES_EXTENSIONS_KEY Type: str | Default: \"undine_schema_directives\" The key used to store the schema definition directives in the extensions of its GraphQLSchema . SDL_PRINTER Type: type[SDLPrinter] | Default: \"undine.utils.graphql.sdl_printer.SDLPrinter\" The SDL printer to use. Value should be given as the dotted path to the SDL printer class. SSE_KEEP_ALIVE_INTERVAL Type: int | Default: 12 Interval in seconds for SSE keep-alive pings sent on the event stream. These pings prevent reverse proxies and load balancers from closing idle connections. Set to 0 to disable. SSE_OPERATION_STREAM_OPEN_TIMEOUT Type: int | Default: 30 Timeout in seconds for an operation to wait for the event stream to open (Single Connection mode). SSE_STREAM_SESSION_PREFIX Type: str | Default: \"graphql-over-sse-stream\" Key prefix used to store the GraphQL over SSE stream state in the user's session (Single Connection mode). SSE_TOKEN_HEADER_NAME Type: str | Default: \"X-GraphQL-Event-Stream-Token\" The name of the HTTP header to use for the GraphQL over SSE event stream token (Single Connection mode). SSE_TOKEN_QUERY_PARAM_NAME Type: str | Default: \"token\" The name of the query string parameter to use for the GraphQL over SSE event stream token (Single Connection mode). TESTING_CLIENT_FULL_STACKTRACE Type: bool | Default: False Whether to include the full stacktrace in testing client instead of just the relevant frames when checking where SQL queries are made. TESTING_CLIENT_NO_ASYNC_TIMEOUT Type: bool | Default: False Whether to disable the websocket timeouts in testing client. Can be useful in debugging. TOTAL_COUNT_PARAM_NAME Type: str | Default: \"totalCount\" The name of the parameter in a connection ObjectType for holding the count for the total number of items that can be queried from the connection. UNDINE_PERSISTED_DOCUMENTS_MODEL Type: type[Model] | Default: \"undine.persisted_documents.models.PersistedDocument\" NOTE : This setting should be set in the top level of the settings file, not in the UNDINE dictionary! The model to use for the PersistedDocument model. Works similarly to AUTH_USER_MODEL , so must be set before running migrations for the persisted documents app. UNION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_union_type\" The key used to store a Undine UnionType in the extensions of its GraphQLUnion . USE_SSE_DISTINCT_CONNECTIONS_FOR_HTTP_1 Type: bool | Default: False Whether Server-Sent Events should use distinct connections mode even with a HTTP/1.1 connection. Note that when using HTTP/1.1, the maximum number of open connections is limited to 6 per domain and browser. That means you will likely hit the limit in a real production environment with multiple requests and browser tabs. WEBSOCKET_CONNECTION_INIT_HOOK Type: WebSocketConnectionInitHook | Default: \"undine.utils.graphql.websocket.connection_init_hook\" The function to use for custom ConnectionInit logic. Value should be given as the dotted path to the function. WEBSOCKET_CONNECTION_INIT_TIMEOUT_SECONDS Type: int | Default: 3 The number of seconds to wait for the ConnectionInit message after opening a WebSocket before closing it. WEBSOCKET_PATH Type: str | Default: \"graphql/\" The path where the GraphQL over WebSocket endpoint is located if using undine.integrations.channels.get_websocket_enabled_app . WEBSOCKET_PING_HOOK Type: WebSocketConnectionPingHook | Default: \"undine.utils.graphql.websocket.ping_hook\" The function for specifying custom Ping message logic. Value should be given as the dotted path to the function. WEBSOCKET_PONG_HOOK Type: WebSocketConnectionPongHook | Default: \"undine.utils.graphql.websocket.pong_hook\" The function to for specifying custom Pong message logic. Value should be given as the dotted path to the function.","title":"Settings"},{"location":"subscriptions/","text":"Subscriptions \ud83d\udd17 In this section, we'll cover how you can add subscriptions to your schema. Subscriptions are a way to get real-time updates from your server through your GraphQL Schema. Setup \ud83d\udd17 To use subscriptions, you'll need to turn on Undine's async support , as subscription resolvers are always async. Then, you have two options for a transport protocol: WebSockets or Server-Sent Events . WebSockets \ud83d\udd17 WebSockets use a persistent TCP connection between the client and server. They have broad client library support in the GraphQL ecosystem, making them a good choice when your client tooling expects WebSocket-based subscriptions. To use WebSockets, you'll need use Undine's channels integration . See the GraphQL over WebSocket protocol for details on how the protocol works. Server-Sent Events \ud83d\udd17 Server-Sent Events (SSE) use regular HTTP, which means they work through standard load balancers, proxies, and firewalls without special configuration. Since GraphQL subscriptions are inherently server-to-client, SSE is a natural fit and can be simpler to deploy than WebSockets. SSE can operate in two modes: Distinct Connections mode and Single Connection mode . Distinct Connections mode \ud83d\udd17 In Distinct Connections mode, each subscription opens its own SSE connection. This is the simpler mode and requires no extra setup beyond async support . However, when using HTTP/1.1, browsers limit SSE connections to 6 per browser and domain, so you should use a web server capable of HTTP/2 in production. You can use USE_SSE_DISTINCT_CONNECTIONS_FOR_HTTP_1 to allow Distinct Connections mode over HTTP/1.1, if you know this isn't going to be an issue for your use case. Single Connection mode \ud83d\udd17 In Single Connection mode, all operations are multiplexed over a single SSE connection, which avoids the HTTP/1.1 connection limit. This mode requires Undine's channels integration . Unlike the reference implementation , which keeps state in-memory within a single process, Undine stores stream and operation state in Django sessions to guarantee a single connection in multi-worker deployments. This changes the implementation slightly compared to the reference implementation: Due to the possibility of session state becoming stale in case the client loses its stream connection, Undine's implementation allows creating a new stream even if one is already open. In this case, the existing stream is closed and replaced with a new one. The reference implementation always returns 409 Conflict if a stream is already open. Using sessions also means that Undine's implementation requires authentication, while the reference implementation does not enforce this. Single Connection mode uses Django's cache framework and channel layers for state coordination. This requires both the cache backend and channel layer to work in multi-worker deployments. The cache backend should also support atomic cache.add . For example, using redis cache and channels-redis satisfies both requirements: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 CACHES = { \"default\" : { \"BACKEND\" : \"django.core.cache.backends.redis.RedisCache\" , \"LOCATION\" : \"redis://127.0.0.1:6379/0\" , }, } SESSION_ENGINE = \"django.contrib.sessions.backends.cache\" CHANNEL_LAYERS = { \"default\" : { \"BACKEND\" : \"channels_redis.core.RedisChannelLayer\" , \"CONFIG\" : { \"hosts\" : [( \"127.0.0.1\" , 6379 )], }, }, } AsyncGenerators \ud83d\udd17 The simplest way of creating subscriptions is by using an AsyncGenerator function. Let's take a look at a simple example of a subscription that counts down from 10 to 0. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown : Int ! } Using this subscription, you'll receive the following response 10 times on 1 second intervals, while the value of the countdown field is decreases from 10 to 1. 1 2 3 4 5 { \"data\" : { \"countdown\" : 10 } } The subscription's output type will be determined based on the first generic type parameter on the AsyncGenerator return type (in this case int ), so typing it is required. To add arguments for the subscription, you can add them to the function signature. Typing these arguments is also required to determine their input type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo , start : int = 10 ) -> AsyncGenerator [ int , None ]: for i in range ( start , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown ( start : Int ! = 10 ) : Int ! } If an exception is raised in the function, the subscription will be closed and an error message will be sent to the client. You should raise exceptions subclassing GraphQLError for better error messages, or use the GraphQLErrorGroup to raise multiple errors at once. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" raise GraphQLError ( msg ) await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) You can also yield a GraphQLError from the function, which will send an error while keeping the subscription open. Furthermore, adding the error to the return type does not change the return type of the subscription. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int | GraphQLError , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" yield GraphQLError ( msg ) continue await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) AsyncIterables \ud83d\udd17 You can also use an AsyncIterable instead of creating an AsyncGenerator function. Note that the AsyncIterable needs to be returned from the Entrypoint function, not used as the Entrypoint reference itself. Otherwise, they work similarly to AsyncGenerators . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import asyncio from collections.abc import AsyncGenerator , AsyncIterable , AsyncIterator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Countdown : def __aiter__ ( self ) -> AsyncIterator [ int ]: return self . gen () async def gen ( self ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncIterable [ int ]: return Countdown () schema = create_schema ( query = Query , subscription = Subscription ) Signal subscriptions \ud83d\udd17 Undine also supports creating subscriptions for Django signals using SignalSubscriptions . For example, if you wanted to listen to new Tasks being created, you could add a ModelCreateSubscription for the Task Model like this. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , QueryType , RootType , create_schema from undine.subscriptions import ModelCreateSubscription from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) class Subscription ( RootType ): created_tasks = Entrypoint ( ModelCreateSubscription ( TaskType )) schema = create_schema ( query = Query , subscription = Subscription ) Similar subscriptions exists for Model updates ( ModelUpdateSubscription ), deletes ( ModelDeleteSubscription ), and overall saves ( ModelSaveSubscription ). These subscriptions return data through QueryTypes so queries to them are optimized just like any other query. For delete subscriptions, note that the Model instance may have been deleted by the time the subscription is executed. You should not rely on the instance existing in the database or its relations being connected like you would with a normal query. However, a copy of the instance is made just before deletion so that you can query its details, but not its relations since those have not been prefetched. For other signals, you can create custom subscriptions by subclassing undine.subscriptions.SignalSubscription and adding the appropriate converters in order to use it in your schema. See the \"Hacking Undine\" section for more information on how to do this. Permissions \ud83d\udd17 As subscriptions use Entrypoints , you can use their permission checks to set per-value permissions for the subscription. Raising an exception from a permission check will close the subscription and send an error message to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema from undine.exceptions import GraphQLPermissionError class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i @countdown . permissions def countdown_permissions ( self , info : GQLInfo , value : int ) -> None : if value > 10 and not info . context . user . is_superuser : msg = \"Countdown value is too high\" raise GraphQLPermissionError ( msg ) schema = create_schema ( query = Query , subscription = Subscription ) When using GraphQL over WebSocket, you can also configure permission checks for establishing a websocket connection using the WEBSOCKET_CONNECTION_INIT_HOOK setting. 1 2 3 4 5 6 7 8 9 10 from typing import Any from undine.exceptions import GraphQLPermissionError from undine.utils.graphql.websocket import WebSocketRequest def connection_init_hook ( request : WebSocketRequest ) -> dict [ str , Any ] | None : if not request . user . is_superuser : msg = \"Only superusers can establish a connection\" raise GraphQLPermissionError ( msg )","title":"Subscriptions"},{"location":"subscriptions/#subscriptions","text":"In this section, we'll cover how you can add subscriptions to your schema. Subscriptions are a way to get real-time updates from your server through your GraphQL Schema.","title":"Subscriptions"},{"location":"subscriptions/#setup","text":"To use subscriptions, you'll need to turn on Undine's async support , as subscription resolvers are always async. Then, you have two options for a transport protocol: WebSockets or Server-Sent Events .","title":"Setup"},{"location":"subscriptions/#websockets","text":"WebSockets use a persistent TCP connection between the client and server. They have broad client library support in the GraphQL ecosystem, making them a good choice when your client tooling expects WebSocket-based subscriptions. To use WebSockets, you'll need use Undine's channels integration . See the GraphQL over WebSocket protocol for details on how the protocol works.","title":"WebSockets"},{"location":"subscriptions/#server-sent-events","text":"Server-Sent Events (SSE) use regular HTTP, which means they work through standard load balancers, proxies, and firewalls without special configuration. Since GraphQL subscriptions are inherently server-to-client, SSE is a natural fit and can be simpler to deploy than WebSockets. SSE can operate in two modes: Distinct Connections mode and Single Connection mode .","title":"Server-Sent Events"},{"location":"subscriptions/#distinct-connections-mode","text":"In Distinct Connections mode, each subscription opens its own SSE connection. This is the simpler mode and requires no extra setup beyond async support . However, when using HTTP/1.1, browsers limit SSE connections to 6 per browser and domain, so you should use a web server capable of HTTP/2 in production. You can use USE_SSE_DISTINCT_CONNECTIONS_FOR_HTTP_1 to allow Distinct Connections mode over HTTP/1.1, if you know this isn't going to be an issue for your use case.","title":"Distinct Connections mode"},{"location":"subscriptions/#single-connection-mode","text":"In Single Connection mode, all operations are multiplexed over a single SSE connection, which avoids the HTTP/1.1 connection limit. This mode requires Undine's channels integration . Unlike the reference implementation , which keeps state in-memory within a single process, Undine stores stream and operation state in Django sessions to guarantee a single connection in multi-worker deployments. This changes the implementation slightly compared to the reference implementation: Due to the possibility of session state becoming stale in case the client loses its stream connection, Undine's implementation allows creating a new stream even if one is already open. In this case, the existing stream is closed and replaced with a new one. The reference implementation always returns 409 Conflict if a stream is already open. Using sessions also means that Undine's implementation requires authentication, while the reference implementation does not enforce this. Single Connection mode uses Django's cache framework and channel layers for state coordination. This requires both the cache backend and channel layer to work in multi-worker deployments. The cache backend should also support atomic cache.add . For example, using redis cache and channels-redis satisfies both requirements: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 CACHES = { \"default\" : { \"BACKEND\" : \"django.core.cache.backends.redis.RedisCache\" , \"LOCATION\" : \"redis://127.0.0.1:6379/0\" , }, } SESSION_ENGINE = \"django.contrib.sessions.backends.cache\" CHANNEL_LAYERS = { \"default\" : { \"BACKEND\" : \"channels_redis.core.RedisChannelLayer\" , \"CONFIG\" : { \"hosts\" : [( \"127.0.0.1\" , 6379 )], }, }, }","title":"Single Connection mode"},{"location":"subscriptions/#asyncgenerators","text":"The simplest way of creating subscriptions is by using an AsyncGenerator function. Let's take a look at a simple example of a subscription that counts down from 10 to 0. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown : Int ! } Using this subscription, you'll receive the following response 10 times on 1 second intervals, while the value of the countdown field is decreases from 10 to 1. 1 2 3 4 5 { \"data\" : { \"countdown\" : 10 } } The subscription's output type will be determined based on the first generic type parameter on the AsyncGenerator return type (in this case int ), so typing it is required. To add arguments for the subscription, you can add them to the function signature. Typing these arguments is also required to determine their input type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo , start : int = 10 ) -> AsyncGenerator [ int , None ]: for i in range ( start , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown ( start : Int ! = 10 ) : Int ! } If an exception is raised in the function, the subscription will be closed and an error message will be sent to the client. You should raise exceptions subclassing GraphQLError for better error messages, or use the GraphQLErrorGroup to raise multiple errors at once. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" raise GraphQLError ( msg ) await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) You can also yield a GraphQLError from the function, which will send an error while keeping the subscription open. Furthermore, adding the error to the return type does not change the return type of the subscription. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int | GraphQLError , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" yield GraphQLError ( msg ) continue await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription )","title":"AsyncGenerators"},{"location":"subscriptions/#asynciterables","text":"You can also use an AsyncIterable instead of creating an AsyncGenerator function. Note that the AsyncIterable needs to be returned from the Entrypoint function, not used as the Entrypoint reference itself. Otherwise, they work similarly to AsyncGenerators . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import asyncio from collections.abc import AsyncGenerator , AsyncIterable , AsyncIterator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Countdown : def __aiter__ ( self ) -> AsyncIterator [ int ]: return self . gen () async def gen ( self ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncIterable [ int ]: return Countdown () schema = create_schema ( query = Query , subscription = Subscription )","title":"AsyncIterables"},{"location":"subscriptions/#signal-subscriptions","text":"Undine also supports creating subscriptions for Django signals using SignalSubscriptions . For example, if you wanted to listen to new Tasks being created, you could add a ModelCreateSubscription for the Task Model like this. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , QueryType , RootType , create_schema from undine.subscriptions import ModelCreateSubscription from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) class Subscription ( RootType ): created_tasks = Entrypoint ( ModelCreateSubscription ( TaskType )) schema = create_schema ( query = Query , subscription = Subscription ) Similar subscriptions exists for Model updates ( ModelUpdateSubscription ), deletes ( ModelDeleteSubscription ), and overall saves ( ModelSaveSubscription ). These subscriptions return data through QueryTypes so queries to them are optimized just like any other query. For delete subscriptions, note that the Model instance may have been deleted by the time the subscription is executed. You should not rely on the instance existing in the database or its relations being connected like you would with a normal query. However, a copy of the instance is made just before deletion so that you can query its details, but not its relations since those have not been prefetched. For other signals, you can create custom subscriptions by subclassing undine.subscriptions.SignalSubscription and adding the appropriate converters in order to use it in your schema. See the \"Hacking Undine\" section for more information on how to do this.","title":"Signal subscriptions"},{"location":"subscriptions/#permissions","text":"As subscriptions use Entrypoints , you can use their permission checks to set per-value permissions for the subscription. Raising an exception from a permission check will close the subscription and send an error message to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema from undine.exceptions import GraphQLPermissionError class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i @countdown . permissions def countdown_permissions ( self , info : GQLInfo , value : int ) -> None : if value > 10 and not info . context . user . is_superuser : msg = \"Countdown value is too high\" raise GraphQLPermissionError ( msg ) schema = create_schema ( query = Query , subscription = Subscription ) When using GraphQL over WebSocket, you can also configure permission checks for establishing a websocket connection using the WEBSOCKET_CONNECTION_INIT_HOOK setting. 1 2 3 4 5 6 7 8 9 10 from typing import Any from undine.exceptions import GraphQLPermissionError from undine.utils.graphql.websocket import WebSocketRequest def connection_init_hook ( request : WebSocketRequest ) -> dict [ str , Any ] | None : if not request . user . is_superuser : msg = \"Only superusers can establish a connection\" raise GraphQLPermissionError ( msg )","title":"Permissions"},{"location":"tutorial/","text":"Tutorial \ud83d\udd17 Before starting the tutorial, read the Getting Started section. This tutorial will guide you through creating a simple GraphQL API using Undine. You'll learn the fundamental aspects of creating a GraphQL schema: queries, mutations, filtering, ordering, permissions, and validation. This should give you familiarity with how Undine works so that you can explore the rest of the documentation for more details. The example application will be a project management system, where users can create tasks with multiple steps and add them to projects. Very exciting! The Django project will have a single app called service where you'll create your models and schema. See the full directory structure below: 1 2 3 4 5 6 7 8 9 10 11 12 13 system/ \u251c\u2500 config/ \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 settings.py \u2502 \u251c\u2500 urls.py \u2502 \u251c\u2500 wsgi.py \u251c\u2500 service/ \u2502 \u251c\u2500 migrations/ \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 apps.py \u2502 \u251c\u2500 models.py \u251c\u2500 manage.py A starting template is available in docs/snippets/tutorial/template . Part 1: Setup \ud83d\udd17 First, install Undine using the installation instructions . Undine comes with an example schema that you can try out before creating your own. To access it, add the following to your project's urls.py file: 1 2 3 4 5 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), ] Next, configure Undine to enable GraphiQL , a tool for exploring GraphQL schemas in the browser. Undine is configured using the UNDINE setting in your Django project's settings.py file, so add the following to it: 1 2 3 4 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , } Now start the Django server and navigate to /graphql/ to see the GraphiQL UI. Make the following request: 1 2 3 query { testing } You should see this response: 1 2 3 4 5 { \"data\" : { \"testing\" : \"Hello World\" } } Part 2: Creating the Schema \ud83d\udd17 Next, let's replace the example schema with your own. Create a file called schema.py in your service app directory and add the following to it: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello World\" schema = create_schema ( query = Query ) This creates the same schema as Undine's example schema. To make it your own, simply modify the return value of the testing method with your own custom message. In Undine, Entrypoints are used in the class bodies of RootTypes to define the operations that can be executed from your GraphQL schema. Now you need to tell Undine to use your custom schema instead of the example one. Add the SCHEMA setting to Undine's configuration and set it to point to the schema variable you created in your schema.py file. 1 2 3 4 5 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , \"SCHEMA\" : \"service.schema.schema\" , } How do I determine the value for SCHEMA ? The value for SCHEMA is a \"dotted import path\" \u2014 a string that can be imported with Django's import_string utility. In other words, \"service.schema.schema\" points to a file service/schema.py with a variable schema . Restart the Django server and make the same request as before. You should see your own message instead of the example one. Part 3: Adding Queries \ud83d\udd17 Now that you have your own schema, let's start exposing Django Models through it. In your models.py file, add the following Model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Create and run migrations for this Model. To add the Task Model to the schema, let's add two Entrypoints : one for fetching a single Task , and another for fetching all Tasks . Replace the current schema.py file with the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) A QueryType is a class that represents a GraphQL ObjectType for a Django Model in the GraphQL schema. By adding Fields to its class body, you can expose the Model's fields in the GraphQL schema. To create Entrypoints for this QueryType , you simply use the QueryType as an argument to the Entrypoint class instead of decorating a method like you did before. This creates an Entrypoint for fetching a single Task by its primary key. For fetching all Tasks , pass many=True to indicate a list endpoint. Now it's time to try out your new schema. But wait, first you need some data to query! In your terminal, run python manage.py shell to start Django's shell and create a few rows for the Task Model. 1 2 3 4 >>> from service.models import Task >>> Task . objects . create ( name = \"Task 1\" , done = False ) >>> Task . objects . create ( name = \"Task 2\" , done = True ) >>> Task . objects . create ( name = \"Task 3\" , done = False ) Now reboot the Django server and make the following request: 1 2 3 4 5 6 7 query { tasks { pk name done } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } ] } } Next, let's add a couple more Models to your project. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . SET_NULL , null = True , blank = True , related_name = \"tasks\" ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE , related_name = \"steps\" ) Create and run migrations for these Models, then create some data for them: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> from service.models import Project , Step , Task >>> project_1 = Project . objects . create ( name = \"Project 1\" ) >>> project_2 = Project . objects . create ( name = \"Project 2\" ) >>> task_1 = Task . objects . get ( name = \"Task 1\" ) >>> task_2 = Task . objects . get ( name = \"Task 2\" ) >>> task_3 = Task . objects . get ( name = \"Task 3\" ) >>> task_1 . project = project_1 >>> task_1 . save () >>> task_2 . project = project_2 >>> task_2 . save () >>> step_1 = Step . objects . create ( name = \"Step 1\" , done = false , task = task_1 ) >>> step_2 = Step . objects . create ( name = \"Step 2\" , done = true , task = task_1 ) >>> step_3 = Step . objects . create ( name = \"Step 3\" , done = false , task = task_2 ) >>> step_4 = Step . objects . create ( name = \"Step 4\" , done = true , task = task_3 ) >>> step_5 = Step . objects . create ( name = \"Step 5\" , done = true , task = task_3 ) Then, add these Models to your schema by creating a QueryType for each of them. Your can also link the QueryTypes to each other by adding Fields for the Model related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () steps = Field () class StepType ( QueryType [ Step ]): pk = Field () name = Field () done = Field () task = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) Reboot the Django server once more and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name done project { pk name } steps { pk name done } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false , \"project\" : { \"pk\" : 1 , \"name\" : \"Project 1\" }, \"steps\" : [ { \"pk\" : 1 , \"name\" : \"Step 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Step 2\" , \"done\" : true } ] }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true , \"project\" : { \"pk\" : 2 , \"name\" : \"Project 2\" }, \"steps\" : [ { \"pk\" : 3 , \"name\" : \"Step 3\" , \"done\" : false } ] }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false , \"project\" : null , \"steps\" : [ { \"pk\" : 4 , \"name\" : \"Step 4\" , \"done\" : true }, { \"pk\" : 5 , \"name\" : \"Step 5\" , \"done\" : true } ] } ] } } Now that you're are using relations, Undine will automatically optimize the database queries for those relations. Part 4: Adding Mutations \ud83d\udd17 Next, let's add a mutation to your schema for creating Tasks . Add the following to the schema.py file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Undine will know that the MutationType TaskCreateMutation is a create mutation because the class has the word \"create\" in its name. Similarly, having \"update\" in the name will make an update mutation, and \"delete\" will make a delete mutation. Create, update and delete mutations are executed differently (see the Mutations section for more details). You could also use the kind argument in the MutationType class definition to be more explicit. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () done = Input () The TaskCreateMutation MutationType will use the TaskType QueryType as the output type since they share the same Model. In fact, all MutationTypes require a QueryType for the same Model to be created, even if it's not otherwise usable from the GraphQL schema. Let's try out the new mutation. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" }) { name } } You should see this response: 1 2 3 4 5 6 7 { \"data\" : { \"createTask\" : { \"name\" : \"New task\" } } } You can also mutate related objects by using other MutationTypes as Inputs . Modify the TaskCreateMutation by adding a Project Input. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Here TaskProjectInput is a special \"related\" kind of MutationType . These MutationTypes allow you to freely modify the related objects during the mutation. For example, using the above configuration, you could create a Task and a Project in a single mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { name project { name } } } Or you could link an existing Project to a new Task . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { name project { name } } } Or link an existing Project while renaming it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Renamed project\" } } ) { name project { name } } } Undine also supports bulk mutations by using the many argument on the Entrypoint . Let's add a bulk mutation for creating Tasks using the TaskCreateMutation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation ) Bulk mutations work just like regular mutations. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mutation { bulkCreateTasks ( input : [ { name : \"New Task\" project : { name : \"New Project\" } } { name : \"Other Task\" project : { name : \"Other Project\" } } ] ) { name project { name } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"data\" : { \"bulkCreateTasks\" : [ { \"name\" : \"New Task\" , \"project\" : { \"name\" : \"New Project\" } }, { \"name\" : \"Other Task\" , \"project\" : { \"name\" : \"Other Project\" } } ] } } Part 5: Adding Permissions \ud83d\udd17 In Undine, you can add permission checks to QueryTypes or MutationTypes as well as individual Fields or Inputs . First, let's add a permission check for querying Tasks . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Now all users need to be logged in to access Tasks through TaskType . Boot up the Django server and make the following request: 1 2 3 4 5 query { tasks { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Need to be logged in to access Tasks.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"tasks\" ], \"extensions\" : { \"status_code\" : 403 , \"error_code\" : \"PERMISSION_DENIED\" } } ] } The permission check will be called for each Task instance returned by the QueryType . For Field permissions, decorate a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access the name of the Task.\" raise GraphQLPermissionError ( msg ) Now users need to be logged in to be able to query Task names. Mutation permissions using MutationTypes work similarly to query permissions using QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : msg = \"Must be a staff user to be able add tasks.\" raise GraphQLPermissionError ( msg ) Now users need to be staff members to be able to create new Tasks using TaskCreateMutation . You can also restrict the usage of specific Inputs by decorating a method with @<input_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): done = Input () @done . permissions def done_permissions ( self , info : GQLInfo , value : bool ) -> None : if not info . context . user . is_superuser : msg = \"Must be a superuser to be able add done tasks.\" raise GraphQLPermissionError ( msg ) Now only superusers can add Tasks that are already done, since in this case the default value of Task.done is False , and Input permissions are only checked for non-default values. Part 6: Adding Validation \ud83d\udd17 Mutations using MutationTypes can also be validated on both the MutationType and individual Input level. To add validation for a MutationType , add the __validate__ classmethod to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data [ \"done\" ]: msg = \"Cannot create a done task.\" raise GraphQLValidationError ( msg ) Now users cannot create Tasks that are already marked as done. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" , done : true }) { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Cannot create a done task.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"createTask\" ], \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" } } ] } To add validation for an Input , decorate a method with @<input_name>.validate . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters.\" raise GraphQLValidationError ( msg ) Now users cannot create Tasks with names that are less than 3 characters long. Part 7: Adding Filtering \ud83d\udd17 Results from QueryTypes can be filtered using Filters defined in a FilterSet . Create a FilterSet for the Task Model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_contains = Filter ( lookup = \"icontains\" ) done = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): pk = Field () name = Field () done = Field () created_at = Field () Now all Entrypoints created from this QueryType will have a filter argument that contains the filtering options defined by the FilterSet . Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameContains : \"a\" } ) { pk name } } Check the response. You should only see Tasks with names that contain the letter \"a\". Different Filters can also be combined to narrow down the results. 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( filter : { nameContains : \"a\" done : false } ) { pk name } } With this query, you should only see Tasks that contain the letter \"a\" and are not done. If you wanted to see either tasks containing the letter a or tasks that are not done, you could put the filters inside an OR block: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { OR : { nameContains : \"a\" done : false } } ) { pk name } } Similar logical blocks exist for AND , NOT and XOR , and they can be nested as deeply as needed. Part 8: Adding Ordering \ud83d\udd17 Results from QueryTypes can be ordered using Orders defined in an OrderSet . Create an OrderSet for the Task Model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): pk = Order () name = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): pk = Field () name = Field () done = Field () created_at = Field () Now all Entrypoints created from this QueryType will have an orderBy argument that contains the ordering options defined by the OrderSet . Adding an ordering enables you to order by that fields in both ascending and descending directions. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( orderBy : [ nameAsc pkDesc ] ) { pk name } } With this ordering, you should see the Tasks ordered primarily by name in ascending order, and secondarily by primary key in descending order. Next Steps \ud83d\udd17 In this tutorial, you've learned the basics of creating a GraphQL schema using Undine. It's likely your GraphQL schema has requirements outside of what has been covered here, so it's recommended to read the Queries , Mutations , Filtering , and Ordering sections next. The Pagination section is also helpful to learn how to paginate your QueryTypes using Relay Connections. For more in-depth information on how Undine optimizes queries to your GraphQL Schema, as well as how to provide custom optimizations for more complex use cases, see the Optimizer section.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"Before starting the tutorial, read the Getting Started section. This tutorial will guide you through creating a simple GraphQL API using Undine. You'll learn the fundamental aspects of creating a GraphQL schema: queries, mutations, filtering, ordering, permissions, and validation. This should give you familiarity with how Undine works so that you can explore the rest of the documentation for more details. The example application will be a project management system, where users can create tasks with multiple steps and add them to projects. Very exciting! The Django project will have a single app called service where you'll create your models and schema. See the full directory structure below: 1 2 3 4 5 6 7 8 9 10 11 12 13 system/ \u251c\u2500 config/ \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 settings.py \u2502 \u251c\u2500 urls.py \u2502 \u251c\u2500 wsgi.py \u251c\u2500 service/ \u2502 \u251c\u2500 migrations/ \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 apps.py \u2502 \u251c\u2500 models.py \u251c\u2500 manage.py A starting template is available in docs/snippets/tutorial/template .","title":"Tutorial"},{"location":"tutorial/#part-1-setup","text":"First, install Undine using the installation instructions . Undine comes with an example schema that you can try out before creating your own. To access it, add the following to your project's urls.py file: 1 2 3 4 5 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), ] Next, configure Undine to enable GraphiQL , a tool for exploring GraphQL schemas in the browser. Undine is configured using the UNDINE setting in your Django project's settings.py file, so add the following to it: 1 2 3 4 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , } Now start the Django server and navigate to /graphql/ to see the GraphiQL UI. Make the following request: 1 2 3 query { testing } You should see this response: 1 2 3 4 5 { \"data\" : { \"testing\" : \"Hello World\" } }","title":"Part 1: Setup"},{"location":"tutorial/#part-2-creating-the-schema","text":"Next, let's replace the example schema with your own. Create a file called schema.py in your service app directory and add the following to it: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello World\" schema = create_schema ( query = Query ) This creates the same schema as Undine's example schema. To make it your own, simply modify the return value of the testing method with your own custom message. In Undine, Entrypoints are used in the class bodies of RootTypes to define the operations that can be executed from your GraphQL schema. Now you need to tell Undine to use your custom schema instead of the example one. Add the SCHEMA setting to Undine's configuration and set it to point to the schema variable you created in your schema.py file. 1 2 3 4 5 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , \"SCHEMA\" : \"service.schema.schema\" , } How do I determine the value for SCHEMA ? The value for SCHEMA is a \"dotted import path\" \u2014 a string that can be imported with Django's import_string utility. In other words, \"service.schema.schema\" points to a file service/schema.py with a variable schema . Restart the Django server and make the same request as before. You should see your own message instead of the example one.","title":"Part 2: Creating the Schema"},{"location":"tutorial/#part-3-adding-queries","text":"Now that you have your own schema, let's start exposing Django Models through it. In your models.py file, add the following Model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Create and run migrations for this Model. To add the Task Model to the schema, let's add two Entrypoints : one for fetching a single Task , and another for fetching all Tasks . Replace the current schema.py file with the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) A QueryType is a class that represents a GraphQL ObjectType for a Django Model in the GraphQL schema. By adding Fields to its class body, you can expose the Model's fields in the GraphQL schema. To create Entrypoints for this QueryType , you simply use the QueryType as an argument to the Entrypoint class instead of decorating a method like you did before. This creates an Entrypoint for fetching a single Task by its primary key. For fetching all Tasks , pass many=True to indicate a list endpoint. Now it's time to try out your new schema. But wait, first you need some data to query! In your terminal, run python manage.py shell to start Django's shell and create a few rows for the Task Model. 1 2 3 4 >>> from service.models import Task >>> Task . objects . create ( name = \"Task 1\" , done = False ) >>> Task . objects . create ( name = \"Task 2\" , done = True ) >>> Task . objects . create ( name = \"Task 3\" , done = False ) Now reboot the Django server and make the following request: 1 2 3 4 5 6 7 query { tasks { pk name done } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } ] } } Next, let's add a couple more Models to your project. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . SET_NULL , null = True , blank = True , related_name = \"tasks\" ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE , related_name = \"steps\" ) Create and run migrations for these Models, then create some data for them: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> from service.models import Project , Step , Task >>> project_1 = Project . objects . create ( name = \"Project 1\" ) >>> project_2 = Project . objects . create ( name = \"Project 2\" ) >>> task_1 = Task . objects . get ( name = \"Task 1\" ) >>> task_2 = Task . objects . get ( name = \"Task 2\" ) >>> task_3 = Task . objects . get ( name = \"Task 3\" ) >>> task_1 . project = project_1 >>> task_1 . save () >>> task_2 . project = project_2 >>> task_2 . save () >>> step_1 = Step . objects . create ( name = \"Step 1\" , done = false , task = task_1 ) >>> step_2 = Step . objects . create ( name = \"Step 2\" , done = true , task = task_1 ) >>> step_3 = Step . objects . create ( name = \"Step 3\" , done = false , task = task_2 ) >>> step_4 = Step . objects . create ( name = \"Step 4\" , done = true , task = task_3 ) >>> step_5 = Step . objects . create ( name = \"Step 5\" , done = true , task = task_3 ) Then, add these Models to your schema by creating a QueryType for each of them. Your can also link the QueryTypes to each other by adding Fields for the Model related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () steps = Field () class StepType ( QueryType [ Step ]): pk = Field () name = Field () done = Field () task = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) Reboot the Django server once more and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name done project { pk name } steps { pk name done } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false , \"project\" : { \"pk\" : 1 , \"name\" : \"Project 1\" }, \"steps\" : [ { \"pk\" : 1 , \"name\" : \"Step 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Step 2\" , \"done\" : true } ] }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true , \"project\" : { \"pk\" : 2 , \"name\" : \"Project 2\" }, \"steps\" : [ { \"pk\" : 3 , \"name\" : \"Step 3\" , \"done\" : false } ] }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false , \"project\" : null , \"steps\" : [ { \"pk\" : 4 , \"name\" : \"Step 4\" , \"done\" : true }, { \"pk\" : 5 , \"name\" : \"Step 5\" , \"done\" : true } ] } ] } } Now that you're are using relations, Undine will automatically optimize the database queries for those relations.","title":"Part 3: Adding Queries"},{"location":"tutorial/#part-4-adding-mutations","text":"Next, let's add a mutation to your schema for creating Tasks . Add the following to the schema.py file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Undine will know that the MutationType TaskCreateMutation is a create mutation because the class has the word \"create\" in its name. Similarly, having \"update\" in the name will make an update mutation, and \"delete\" will make a delete mutation. Create, update and delete mutations are executed differently (see the Mutations section for more details). You could also use the kind argument in the MutationType class definition to be more explicit. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () done = Input () The TaskCreateMutation MutationType will use the TaskType QueryType as the output type since they share the same Model. In fact, all MutationTypes require a QueryType for the same Model to be created, even if it's not otherwise usable from the GraphQL schema. Let's try out the new mutation. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" }) { name } } You should see this response: 1 2 3 4 5 6 7 { \"data\" : { \"createTask\" : { \"name\" : \"New task\" } } } You can also mutate related objects by using other MutationTypes as Inputs . Modify the TaskCreateMutation by adding a Project Input. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Here TaskProjectInput is a special \"related\" kind of MutationType . These MutationTypes allow you to freely modify the related objects during the mutation. For example, using the above configuration, you could create a Task and a Project in a single mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { name project { name } } } Or you could link an existing Project to a new Task . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { name project { name } } } Or link an existing Project while renaming it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Renamed project\" } } ) { name project { name } } } Undine also supports bulk mutations by using the many argument on the Entrypoint . Let's add a bulk mutation for creating Tasks using the TaskCreateMutation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation ) Bulk mutations work just like regular mutations. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mutation { bulkCreateTasks ( input : [ { name : \"New Task\" project : { name : \"New Project\" } } { name : \"Other Task\" project : { name : \"Other Project\" } } ] ) { name project { name } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"data\" : { \"bulkCreateTasks\" : [ { \"name\" : \"New Task\" , \"project\" : { \"name\" : \"New Project\" } }, { \"name\" : \"Other Task\" , \"project\" : { \"name\" : \"Other Project\" } } ] } }","title":"Part 4: Adding Mutations"},{"location":"tutorial/#part-5-adding-permissions","text":"In Undine, you can add permission checks to QueryTypes or MutationTypes as well as individual Fields or Inputs . First, let's add a permission check for querying Tasks . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Now all users need to be logged in to access Tasks through TaskType . Boot up the Django server and make the following request: 1 2 3 4 5 query { tasks { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Need to be logged in to access Tasks.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"tasks\" ], \"extensions\" : { \"status_code\" : 403 , \"error_code\" : \"PERMISSION_DENIED\" } } ] } The permission check will be called for each Task instance returned by the QueryType . For Field permissions, decorate a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access the name of the Task.\" raise GraphQLPermissionError ( msg ) Now users need to be logged in to be able to query Task names. Mutation permissions using MutationTypes work similarly to query permissions using QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : msg = \"Must be a staff user to be able add tasks.\" raise GraphQLPermissionError ( msg ) Now users need to be staff members to be able to create new Tasks using TaskCreateMutation . You can also restrict the usage of specific Inputs by decorating a method with @<input_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): done = Input () @done . permissions def done_permissions ( self , info : GQLInfo , value : bool ) -> None : if not info . context . user . is_superuser : msg = \"Must be a superuser to be able add done tasks.\" raise GraphQLPermissionError ( msg ) Now only superusers can add Tasks that are already done, since in this case the default value of Task.done is False , and Input permissions are only checked for non-default values.","title":"Part 5: Adding Permissions"},{"location":"tutorial/#part-6-adding-validation","text":"Mutations using MutationTypes can also be validated on both the MutationType and individual Input level. To add validation for a MutationType , add the __validate__ classmethod to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data [ \"done\" ]: msg = \"Cannot create a done task.\" raise GraphQLValidationError ( msg ) Now users cannot create Tasks that are already marked as done. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" , done : true }) { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Cannot create a done task.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"createTask\" ], \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" } } ] } To add validation for an Input , decorate a method with @<input_name>.validate . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters.\" raise GraphQLValidationError ( msg ) Now users cannot create Tasks with names that are less than 3 characters long.","title":"Part 6: Adding Validation"},{"location":"tutorial/#part-7-adding-filtering","text":"Results from QueryTypes can be filtered using Filters defined in a FilterSet . Create a FilterSet for the Task Model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_contains = Filter ( lookup = \"icontains\" ) done = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): pk = Field () name = Field () done = Field () created_at = Field () Now all Entrypoints created from this QueryType will have a filter argument that contains the filtering options defined by the FilterSet . Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameContains : \"a\" } ) { pk name } } Check the response. You should only see Tasks with names that contain the letter \"a\". Different Filters can also be combined to narrow down the results. 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( filter : { nameContains : \"a\" done : false } ) { pk name } } With this query, you should only see Tasks that contain the letter \"a\" and are not done. If you wanted to see either tasks containing the letter a or tasks that are not done, you could put the filters inside an OR block: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { OR : { nameContains : \"a\" done : false } } ) { pk name } } Similar logical blocks exist for AND , NOT and XOR , and they can be nested as deeply as needed.","title":"Part 7: Adding Filtering"},{"location":"tutorial/#part-8-adding-ordering","text":"Results from QueryTypes can be ordered using Orders defined in an OrderSet . Create an OrderSet for the Task Model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): pk = Order () name = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): pk = Field () name = Field () done = Field () created_at = Field () Now all Entrypoints created from this QueryType will have an orderBy argument that contains the ordering options defined by the OrderSet . Adding an ordering enables you to order by that fields in both ascending and descending directions. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( orderBy : [ nameAsc pkDesc ] ) { pk name } } With this ordering, you should see the Tasks ordered primarily by name in ascending order, and secondarily by primary key in descending order.","title":"Part 8: Adding Ordering"},{"location":"tutorial/#next-steps","text":"In this tutorial, you've learned the basics of creating a GraphQL schema using Undine. It's likely your GraphQL schema has requirements outside of what has been covered here, so it's recommended to read the Queries , Mutations , Filtering , and Ordering sections next. The Pagination section is also helpful to learn how to paginate your QueryTypes using Relay Connections. For more in-depth information on how Undine optimizes queries to your GraphQL Schema, as well as how to provide custom optimizations for more complex use cases, see the Optimizer section.","title":"Next Steps"},{"location":"unions/","text":"Unions \ud83d\udd17 In this section, we'll cover how GraphQL Unions work in Undine. Unions are abstract GraphQL types that represent a group of ObjectTypes that need to be returned together, e.g. for a search result. UnionType \ud83d\udd17 In Undine, a GraphQL Union between two or more QueryTypes is implemented using a UnionType . The QueryTypes in the Union should be added as generic type parameters to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... Usage in Entrypoints \ud83d\udd17 An Entrypoint created using a UnionType as the reference will return all instances of all QueryTypes it contains. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 query { searchObjects { ... on TaskType { name } ... on ProjectType { name } __typename } } Filtering \ud83d\udd17 By default, an Entrypoint for a UnionType will return all instances of all QueryTypes it contains. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the UnionType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... @TaskFilterSet @TaskOrderSet class TaskType ( QueryType [ Task ]): ... class ProjectFilterSet ( FilterSet [ Project ]): ... class ProjectOrderSet ( OrderSet [ Project ]): ... @ProjectFilterSet @ProjectOrderSet class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { searchObjects ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterProject : ProjectFilterSet orderByProject : [ ProjectOrderSet !] ): [ Commentable !]! } This allows filtering and ordering the different types of models in the UnionType separately. To filter and order across different Models in the Union , you can implement a FilterSet or an OrderSet for the same Models as the QueryTypes in the UnionType and add it to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjectsFilterSet ( FilterSet [ Task , Project ]): ... class SearchObjectsOrderSet ( OrderSet [ Task , Project ]): ... @SearchObjectsFilterSet @SearchObjectsOrderSet class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 type Query { searchObjects ( filter : SearchObjectsFilterSet orderBy : [ SearchObjectsOrderSet !] ): [ Commentable !]! } Note that a FilterSet or OrderSet created for multiple Models like this should only contain Filters and Orders which will work on all Models in the UnionType . For example, a \"name\" Filter can be added to the FilterSet if all Models contain a \"name\" field of type CharField . Pagination \ud83d\udd17 UnionTypes can be paginated just like any QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Entrypoint , QueryType , RootType , UnionType from undine.relay import Connection from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( Connection ( SearchObjects )) See the Pagination section for more details on pagination. Schema name \ud83d\udd17 By default, the name of the generated GraphQL Union for a UnionType class is the name of the UnionType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], schema_name = \"Search\" ): ... Description \ud83d\udd17 A description for a UnionType can be provided as a docstring. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): \"\"\"Description\"\"\" Directives \ud83d\udd17 You can add directives to the UnionType by providing them using the directives argument. The directive must be usable in the UNION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class MyDirective ( Directive , locations = [ DirectiveLocation . UNION ]): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], directives = [ MyDirective ()]): ... You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class MyDirective ( Directive , locations = [ DirectiveLocation . UNION ]): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... @MyDirective () class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a UnionType from certain users by using the __is_visible__ method. Hiding the UnionType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the UnionType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import QueryType , UnionType from undine.typing import DjangoRequestProtocol from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them. GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the UnionType by providing an extensions argument with a dictionary containing them. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], extensions = { \"foo\" : \"bar\" }): ... UnionType extensions are made available in the GraphQL Union extensions after the schema is created. The UnionType itself is found in the GraphQL Union extensions under a key defined by the UNION_TYPE_EXTENSIONS_KEY setting.","title":"Unions"},{"location":"unions/#unions","text":"In this section, we'll cover how GraphQL Unions work in Undine. Unions are abstract GraphQL types that represent a group of ObjectTypes that need to be returned together, e.g. for a search result.","title":"Unions"},{"location":"unions/#uniontype","text":"In Undine, a GraphQL Union between two or more QueryTypes is implemented using a UnionType . The QueryTypes in the Union should be added as generic type parameters to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ...","title":"UnionType"},{"location":"unions/#usage-in-entrypoints","text":"An Entrypoint created using a UnionType as the reference will return all instances of all QueryTypes it contains. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 query { searchObjects { ... on TaskType { name } ... on ProjectType { name } __typename } }","title":"Usage in Entrypoints"},{"location":"unions/#filtering","text":"By default, an Entrypoint for a UnionType will return all instances of all QueryTypes it contains. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the UnionType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... @TaskFilterSet @TaskOrderSet class TaskType ( QueryType [ Task ]): ... class ProjectFilterSet ( FilterSet [ Project ]): ... class ProjectOrderSet ( OrderSet [ Project ]): ... @ProjectFilterSet @ProjectOrderSet class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { searchObjects ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterProject : ProjectFilterSet orderByProject : [ ProjectOrderSet !] ): [ Commentable !]! } This allows filtering and ordering the different types of models in the UnionType separately. To filter and order across different Models in the Union , you can implement a FilterSet or an OrderSet for the same Models as the QueryTypes in the UnionType and add it to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjectsFilterSet ( FilterSet [ Task , Project ]): ... class SearchObjectsOrderSet ( OrderSet [ Task , Project ]): ... @SearchObjectsFilterSet @SearchObjectsOrderSet class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 type Query { searchObjects ( filter : SearchObjectsFilterSet orderBy : [ SearchObjectsOrderSet !] ): [ Commentable !]! } Note that a FilterSet or OrderSet created for multiple Models like this should only contain Filters and Orders which will work on all Models in the UnionType . For example, a \"name\" Filter can be added to the FilterSet if all Models contain a \"name\" field of type CharField .","title":"Filtering"},{"location":"unions/#pagination","text":"UnionTypes can be paginated just like any QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Entrypoint , QueryType , RootType , UnionType from undine.relay import Connection from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( Connection ( SearchObjects )) See the Pagination section for more details on pagination.","title":"Pagination"},{"location":"unions/#schema-name","text":"By default, the name of the generated GraphQL Union for a UnionType class is the name of the UnionType class. If you want to change the name separately, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], schema_name = \"Search\" ): ...","title":"Schema name"},{"location":"unions/#description","text":"A description for a UnionType can be provided as a docstring. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): \"\"\"Description\"\"\"","title":"Description"},{"location":"unions/#directives","text":"You can add directives to the UnionType by providing them using the directives argument. The directive must be usable in the UNION location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class MyDirective ( Directive , locations = [ DirectiveLocation . UNION ]): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], directives = [ MyDirective ()]): ... You can also add directives using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation from undine import QueryType , UnionType from undine.directives import Directive from .models import Project , Task class MyDirective ( Directive , locations = [ DirectiveLocation . UNION ]): ... class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... @MyDirective () class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... See the Directives section for more details on directives.","title":"Directives"},{"location":"unions/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a UnionType from certain users by using the __is_visible__ method. Hiding the UnionType means that it will not be included in introspection queries, and trying to use it in operations will result in an error that looks exactly like the UnionType didn't exist in the first place. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import QueryType , UnionType from undine.typing import DjangoRequestProtocol from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser When using visibility checks, you should also disable \"did you mean\" suggestions using the ALLOW_DID_YOU_MEAN_SUGGESTIONS setting. Otherwise, a hidden field might show up in them.","title":"Visibility"},{"location":"unions/#graphql-extensions","text":"You can provide custom extensions for the UnionType by providing an extensions argument with a dictionary containing them. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], extensions = { \"foo\" : \"bar\" }): ... UnionType extensions are made available in the GraphQL Union extensions after the schema is created. The UnionType itself is found in the GraphQL Union extensions under a key defined by the UNION_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"validation-rules/","text":"Validation rules \ud83d\udd17 This is an advanced GraphQL core feature. For validating mutations, see the Mutations documentation. A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation according to the GraphQL AST. By default, graphql-core (which Undine uses under the hood) comes with a set of validation rules which make sure that a GraphQL operation is valid according to the GraphQL specification. Undine adds a few more validation rules of its own, and allows you to add your own as well. Additional Rules \ud83d\udd17 MaxAliasCountRule \ud83d\udd17 This validation rule checks that the number of aliases in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_ALIASES setting. This is used to prevent denial-of-service attacks and heap overflow from \"alias overloading\" which happens when a GraphQL operation is executed multiple times in a single request by aliasing it over and over again, leading to high execution time and thus high CPU and memory usage. MaxComplexityRule \ud83d\udd17 This validation rule checks that the complexity of a GraphQL operation does not exceed the maximum allowed, as set by the MAX_QUERY_COMPLEXITY setting. This is used to prevent denial-of-service attacks that could arise from slow execution of a GraphQL operation due to the complexity of generated database queries or API calls. See the complexity documentation for more information. MaxDirectiveCountRule \ud83d\udd17 This validation rule checks that the number of directives in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_DIRECTIVES setting. This is used to prevent denial-of-service attacks, heap overflow or server overloading from \"directive overloading\" that could arise from having to parse, validate, and process too many directives. OneOfInputObjectTypeRule \ud83d\udd17 This validation rule checks that a one-of input object is used correctly. Only added when graphql-core version is below v3.2.7 since oneOf input object support was added in that version. VisibilityRule \ud83d\udd17 When EXPERIMENTAL_VISIBILITY_CHECKS are enabled, this validation rule checks that users cannot use parts of the schema that are not visible to them, as defined by visibility checks. See how to enable visibility checks for the different objects in Undine: Entrypoint visibility QueryType visibility Field visibility MutationType visibility Input visibility FilterSet visibility Filter visibility OrderSet visibility Order visibility InterfaceType visibility InterfaceField visibility UnionType visibility Directive visibility DirectiveArgument visibility CalculationArgument visibility Custom validation rules \ud83d\udd17 To add your own validation rules, you'll need to create a class that inherits from graphql.validation.rules.ValidationRule . This class implements the visitor pattern to traverse the GraphQL AST. Different Nodes in the AST can be visited by defining either enter_<node_type> or leave_<node_type> methods, depending on whether you want to visit the node before or after its children. These methods have the following signature (example for NameNode ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 from __future__ import annotations from typing import TYPE_CHECKING from graphql import ValidationRule if TYPE_CHECKING : from graphql import NameNode , Node , VisitorAction class MyValidationRule ( ValidationRule ): def enter_name ( self , node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : \"\"\" Called when entering a given node, before visiting its children. :param node: The current node being visiting. :param key: The index or key to this node from the parent node or array. :param parent: the parent immediately above this node, which may be an array. :param path: The key path to get to this node from the root node. :param ancestors: All nodes and arrays visited before reaching parent of this node. These correspond to array indices in `path`. :return: Action to be taken on the node: - self.IDLE: no action - self.SKIP: skip visiting this node - self.BREAK: stop visiting altogether - self.REMOVE: delete this node - any other value: replace this node with the returned value \"\"\" return None def leave_name ( self , node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : \"\"\" Called when leaving a given node, after visiting its children. :param node: The current node being visiting. :param key: The index or key to this node from the parent node or array. :param parent: the parent immediately above this node, which may be an array. :param path: The key path to get to this node from the root node. :param ancestors: All nodes and arrays visited before reaching parent of this node. These correspond to array indices in `path`. :return: Action to be taken on the node: - self.IDLE: no action - self.BREAK: stop visiting altogether - self.REMOVE: delete this node - any other value: replace this node with the returned value \"\"\" return None When you have created your custom validation rule, you can register it using the ADDITIONAL_VALIDATION_RULES setting. For clarity, here is a list of Node types that can be visited during the GraphQL document validation phase: DocumentNode Hooks enter_document and leave_document | Node: graphql.language.ast.DocumentNode A DocumentNode is visited at the root of the GraphQL document AST. It can define multiple operations and fragments. OperationDefinitionNode Hooks enter_operation_definition and leave_operation_definition | Node: graphql.language.ast.OperationDefinitionNode An OperationDefinitionNode is visited for each operation in the GraphQL document. Note that a GraphQL document can contain multiple operations, although only one operation can be executed in a single request. VariableDefinitionNode Hooks enter_variable_definition and leave_variable_definition | Node: graphql.language.ast.VariableDefinitionNode A VariableDefinitionNode is visited for each variable definition in the GraphQL document. Variables are defined at the start of an operation using dollar signs ( $ ). NameNode Hooks enter_name and enter_name | Node: graphql.language.ast.NameNode A NameNode is visited for each named entity in the GraphQL document. This includes field names, argument names, and type names, etc. SelectionSetNode Hooks enter_selection_set and leave_selection_set | Node: graphql.language.ast.SelectionSetNode A SelectionSetNode is visited for each selection set in the GraphQL document. A selection set is a set of fields or fragments requested from a GraphQL type. FieldNode Hooks enter_field and leave_field | Node: graphql.language.ast.FieldNode A FieldNode is visited for each field in the GraphQL document. ArgumentNode Hooks enter_argument and leave_argument | Node: graphql.language.ast.ArgumentNode An ArgumentNode is visited for each field argument in the GraphQL document. FragmentSpreadNode Hooks enter_fragment_spread and leave_fragment_spread | Node: graphql.language.ast.FragmentSpreadNode A FragmentSpreadNode is visited for each fragment spread in the GraphQL document. InlineFragmentNode Hooks enter_inline_fragment and leave_inline_fragment | Node: graphql.language.ast.InlineFragmentNode A InlineFragmentNode is visited for each inline fragment in the GraphQL document. FragmentDefinitionNode Hooks enter_fragment_definition and leave_fragment_definition | Node: graphql.language.ast.FragmentDefinitionNode A FragmentDefinitionNode is visited for each fragment definition in the GraphQL document. NamedTypeNode Hooks enter_named_type and leave_named_type | Node: graphql.language.ast.NamedTypeNode A NamedTypeNode is visited for each named type referenced in the GraphQL document. Named types are referenced when using inline fragments or defining fragments. Example: 1 2 3 4 5 6 7 8 9 10 11 12 query { node ( id : \"123\" ) { ... on User { # NamedTypeNode \"User\" ... Data } } } fragment Data on User { # NamedTypeNode \"User\" id name } ListTypeNode Hooks enter_list_type and leave_list_type | Node: graphql.language.ast.ListTypeNode A ListTypeNode is visited for each list type in the GraphQL document. NonNullTypeNode Hooks enter_non_null_type and leave_non_null_type | Node: graphql.language.ast.NonNullTypeNode A NonNullTypeNode is visited for each non-null type in the GraphQL document. DirectiveNode Hooks enter_directive and leave_directive | Node: graphql.language.ast.DirectiveNode A DirectiveNode is visited for each directive used in the GraphQL document. VariableNode Hooks enter_variable and leave_variable | Node: graphql.language.ast.VariableNode A VariableNode is visited for each variable used in the GraphQL document. IntValueNode Hooks enter_int_value and leave_int_value | Node: graphql.language.ast.IntValueNode A IntValueNode is visited for each integer value in the GraphQL document. Values can be used in arguments or variables. FloatValueNode Hooks enter_float_value and leave_float_value | Node: graphql.language.ast.FloatValueNode A FloatValueNode is visited for each float value in the GraphQL document. Values can be used in arguments or variables. StringValueNode Hooks enter_string_value and leave_string_value | Node: graphql.language.ast.StringValueNode A StringValueNode is visited for each string value in the GraphQL document. Values can be used in arguments or variables. BooleanValueNode Hooks enter_boolean_value and leave_boolean_value | Node: graphql.language.ast.BooleanValueNode A BooleanValueNode is visited for each boolean value in the GraphQL document. Values can be used in arguments or variables. NullValueNode Hooks enter_null_value and leave_null_value | Node: graphql.language.ast.NullValueNode A NullValueNode is visited for each null value in the GraphQL document. Values can be used in arguments or variables. EnumValueNode Hooks enter_enum_value and leave_enum_value | Node: graphql.language.ast.EnumValueNode A EnumValueNode is visited for each enum value in the GraphQL document. Values can be used in arguments or variables. ListValueNode Hooks enter_list_value and leave_list_value | Node: graphql.language.ast.ListValueNode A ListValueNode is visited for each list value in the GraphQL document. Values can be used in arguments or variables. ObjectValueNode Hooks enter_object_value and leave_object_value | Node: graphql.language.ast.ObjectValueNode A ObjectValueNode is visited for each object value in the GraphQL document. Values can be used in arguments or variables. ObjectFieldNode Hooks enter_object_field and leave_object_field | Node: graphql.language.ast.ObjectFieldNode A ObjectFieldNode is visited for each object field in the GraphQL document. Values can be used in arguments or variables. There are other node types which can be visited if validation rules are run against the GraphQL schema, but these are not covered in this documentation. A ValidationRule instance has access to the ValidationContext instance, through which you can access to useful contextual information relative to the visited node. For example, you can access the current GraphQL type for the node using self.context.get_type() .","title":"Validation Rules"},{"location":"validation-rules/#validation-rules","text":"This is an advanced GraphQL core feature. For validating mutations, see the Mutations documentation. A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation according to the GraphQL AST. By default, graphql-core (which Undine uses under the hood) comes with a set of validation rules which make sure that a GraphQL operation is valid according to the GraphQL specification. Undine adds a few more validation rules of its own, and allows you to add your own as well.","title":"Validation rules"},{"location":"validation-rules/#additional-rules","text":"","title":"Additional Rules"},{"location":"validation-rules/#maxaliascountrule","text":"This validation rule checks that the number of aliases in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_ALIASES setting. This is used to prevent denial-of-service attacks and heap overflow from \"alias overloading\" which happens when a GraphQL operation is executed multiple times in a single request by aliasing it over and over again, leading to high execution time and thus high CPU and memory usage.","title":"MaxAliasCountRule"},{"location":"validation-rules/#maxcomplexityrule","text":"This validation rule checks that the complexity of a GraphQL operation does not exceed the maximum allowed, as set by the MAX_QUERY_COMPLEXITY setting. This is used to prevent denial-of-service attacks that could arise from slow execution of a GraphQL operation due to the complexity of generated database queries or API calls. See the complexity documentation for more information.","title":"MaxComplexityRule"},{"location":"validation-rules/#maxdirectivecountrule","text":"This validation rule checks that the number of directives in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_DIRECTIVES setting. This is used to prevent denial-of-service attacks, heap overflow or server overloading from \"directive overloading\" that could arise from having to parse, validate, and process too many directives.","title":"MaxDirectiveCountRule"},{"location":"validation-rules/#oneofinputobjecttyperule","text":"This validation rule checks that a one-of input object is used correctly. Only added when graphql-core version is below v3.2.7 since oneOf input object support was added in that version.","title":"OneOfInputObjectTypeRule"},{"location":"validation-rules/#visibilityrule","text":"When EXPERIMENTAL_VISIBILITY_CHECKS are enabled, this validation rule checks that users cannot use parts of the schema that are not visible to them, as defined by visibility checks. See how to enable visibility checks for the different objects in Undine: Entrypoint visibility QueryType visibility Field visibility MutationType visibility Input visibility FilterSet visibility Filter visibility OrderSet visibility Order visibility InterfaceType visibility InterfaceField visibility UnionType visibility Directive visibility DirectiveArgument visibility CalculationArgument visibility","title":"VisibilityRule"},{"location":"validation-rules/#custom-validation-rules","text":"To add your own validation rules, you'll need to create a class that inherits from graphql.validation.rules.ValidationRule . This class implements the visitor pattern to traverse the GraphQL AST. Different Nodes in the AST can be visited by defining either enter_<node_type> or leave_<node_type> methods, depending on whether you want to visit the node before or after its children. These methods have the following signature (example for NameNode ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 from __future__ import annotations from typing import TYPE_CHECKING from graphql import ValidationRule if TYPE_CHECKING : from graphql import NameNode , Node , VisitorAction class MyValidationRule ( ValidationRule ): def enter_name ( self , node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : \"\"\" Called when entering a given node, before visiting its children. :param node: The current node being visiting. :param key: The index or key to this node from the parent node or array. :param parent: the parent immediately above this node, which may be an array. :param path: The key path to get to this node from the root node. :param ancestors: All nodes and arrays visited before reaching parent of this node. These correspond to array indices in `path`. :return: Action to be taken on the node: - self.IDLE: no action - self.SKIP: skip visiting this node - self.BREAK: stop visiting altogether - self.REMOVE: delete this node - any other value: replace this node with the returned value \"\"\" return None def leave_name ( self , node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : \"\"\" Called when leaving a given node, after visiting its children. :param node: The current node being visiting. :param key: The index or key to this node from the parent node or array. :param parent: the parent immediately above this node, which may be an array. :param path: The key path to get to this node from the root node. :param ancestors: All nodes and arrays visited before reaching parent of this node. These correspond to array indices in `path`. :return: Action to be taken on the node: - self.IDLE: no action - self.BREAK: stop visiting altogether - self.REMOVE: delete this node - any other value: replace this node with the returned value \"\"\" return None When you have created your custom validation rule, you can register it using the ADDITIONAL_VALIDATION_RULES setting. For clarity, here is a list of Node types that can be visited during the GraphQL document validation phase: DocumentNode Hooks enter_document and leave_document | Node: graphql.language.ast.DocumentNode A DocumentNode is visited at the root of the GraphQL document AST. It can define multiple operations and fragments. OperationDefinitionNode Hooks enter_operation_definition and leave_operation_definition | Node: graphql.language.ast.OperationDefinitionNode An OperationDefinitionNode is visited for each operation in the GraphQL document. Note that a GraphQL document can contain multiple operations, although only one operation can be executed in a single request. VariableDefinitionNode Hooks enter_variable_definition and leave_variable_definition | Node: graphql.language.ast.VariableDefinitionNode A VariableDefinitionNode is visited for each variable definition in the GraphQL document. Variables are defined at the start of an operation using dollar signs ( $ ). NameNode Hooks enter_name and enter_name | Node: graphql.language.ast.NameNode A NameNode is visited for each named entity in the GraphQL document. This includes field names, argument names, and type names, etc. SelectionSetNode Hooks enter_selection_set and leave_selection_set | Node: graphql.language.ast.SelectionSetNode A SelectionSetNode is visited for each selection set in the GraphQL document. A selection set is a set of fields or fragments requested from a GraphQL type. FieldNode Hooks enter_field and leave_field | Node: graphql.language.ast.FieldNode A FieldNode is visited for each field in the GraphQL document. ArgumentNode Hooks enter_argument and leave_argument | Node: graphql.language.ast.ArgumentNode An ArgumentNode is visited for each field argument in the GraphQL document. FragmentSpreadNode Hooks enter_fragment_spread and leave_fragment_spread | Node: graphql.language.ast.FragmentSpreadNode A FragmentSpreadNode is visited for each fragment spread in the GraphQL document. InlineFragmentNode Hooks enter_inline_fragment and leave_inline_fragment | Node: graphql.language.ast.InlineFragmentNode A InlineFragmentNode is visited for each inline fragment in the GraphQL document. FragmentDefinitionNode Hooks enter_fragment_definition and leave_fragment_definition | Node: graphql.language.ast.FragmentDefinitionNode A FragmentDefinitionNode is visited for each fragment definition in the GraphQL document. NamedTypeNode Hooks enter_named_type and leave_named_type | Node: graphql.language.ast.NamedTypeNode A NamedTypeNode is visited for each named type referenced in the GraphQL document. Named types are referenced when using inline fragments or defining fragments. Example: 1 2 3 4 5 6 7 8 9 10 11 12 query { node ( id : \"123\" ) { ... on User { # NamedTypeNode \"User\" ... Data } } } fragment Data on User { # NamedTypeNode \"User\" id name } ListTypeNode Hooks enter_list_type and leave_list_type | Node: graphql.language.ast.ListTypeNode A ListTypeNode is visited for each list type in the GraphQL document. NonNullTypeNode Hooks enter_non_null_type and leave_non_null_type | Node: graphql.language.ast.NonNullTypeNode A NonNullTypeNode is visited for each non-null type in the GraphQL document. DirectiveNode Hooks enter_directive and leave_directive | Node: graphql.language.ast.DirectiveNode A DirectiveNode is visited for each directive used in the GraphQL document. VariableNode Hooks enter_variable and leave_variable | Node: graphql.language.ast.VariableNode A VariableNode is visited for each variable used in the GraphQL document. IntValueNode Hooks enter_int_value and leave_int_value | Node: graphql.language.ast.IntValueNode A IntValueNode is visited for each integer value in the GraphQL document. Values can be used in arguments or variables. FloatValueNode Hooks enter_float_value and leave_float_value | Node: graphql.language.ast.FloatValueNode A FloatValueNode is visited for each float value in the GraphQL document. Values can be used in arguments or variables. StringValueNode Hooks enter_string_value and leave_string_value | Node: graphql.language.ast.StringValueNode A StringValueNode is visited for each string value in the GraphQL document. Values can be used in arguments or variables. BooleanValueNode Hooks enter_boolean_value and leave_boolean_value | Node: graphql.language.ast.BooleanValueNode A BooleanValueNode is visited for each boolean value in the GraphQL document. Values can be used in arguments or variables. NullValueNode Hooks enter_null_value and leave_null_value | Node: graphql.language.ast.NullValueNode A NullValueNode is visited for each null value in the GraphQL document. Values can be used in arguments or variables. EnumValueNode Hooks enter_enum_value and leave_enum_value | Node: graphql.language.ast.EnumValueNode A EnumValueNode is visited for each enum value in the GraphQL document. Values can be used in arguments or variables. ListValueNode Hooks enter_list_value and leave_list_value | Node: graphql.language.ast.ListValueNode A ListValueNode is visited for each list value in the GraphQL document. Values can be used in arguments or variables. ObjectValueNode Hooks enter_object_value and leave_object_value | Node: graphql.language.ast.ObjectValueNode A ObjectValueNode is visited for each object value in the GraphQL document. Values can be used in arguments or variables. ObjectFieldNode Hooks enter_object_field and leave_object_field | Node: graphql.language.ast.ObjectFieldNode A ObjectFieldNode is visited for each object field in the GraphQL document. Values can be used in arguments or variables. There are other node types which can be visited if validation rules are run against the GraphQL schema, but these are not covered in this documentation. A ValidationRule instance has access to the ValidationContext instance, through which you can access to useful contextual information relative to the visited node. For example, you can access the current GraphQL type for the node using self.context.get_type() .","title":"Custom validation rules"}]}