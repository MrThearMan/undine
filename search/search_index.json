{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Undine \ud83d\udd17 1 pip install undine Undine is a GraphQL library for Django. It's designed to be easy to use and extend while providing out-of-the-box solutions for many common issues GraphQL developers face. Feature highlights: Automatic generation of GraphQL types from Django models Automatic query optimization Logically composable filtering Ordering based on enums Single and bulk mutations, including relations Hidden and input-only mutation inputs Built-in permission and validation hooks Support for Relay Global object IDs and Connection pagination File uploads based on GraphQL multipart request specification Support for asynchronous execution Subscriptions with websockets Optional persisted documents support Lifecycle hooks for customizing the GraphQL request cycle Built-in testing tools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 from typing import Any from undine import Entrypoint , FilterSet , GQLInfo , MutationType , OrderSet , QueryType , RootType , create_schema from undine.exceptions import GraphQLPermissionError from undine.relay import Connection from .models import Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( Connection ( TaskType )) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation )","title":"Home"},{"location":"#undine","text":"1 pip install undine Undine is a GraphQL library for Django. It's designed to be easy to use and extend while providing out-of-the-box solutions for many common issues GraphQL developers face. Feature highlights: Automatic generation of GraphQL types from Django models Automatic query optimization Logically composable filtering Ordering based on enums Single and bulk mutations, including relations Hidden and input-only mutation inputs Built-in permission and validation hooks Support for Relay Global object IDs and Connection pagination File uploads based on GraphQL multipart request specification Support for asynchronous execution Subscriptions with websockets Optional persisted documents support Lifecycle hooks for customizing the GraphQL request cycle Built-in testing tools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 from typing import Any from undine import Entrypoint , FilterSet , GQLInfo , MutationType , OrderSet , QueryType , RootType , create_schema from undine.exceptions import GraphQLPermissionError from undine.relay import Connection from .models import Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( Connection ( TaskType )) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation )","title":"Undine"},{"location":"async/","text":"Async support \ud83d\udd17 In this section, we'll look at how you can make you schema support async operations. Note that asynchronous execution will require an ASGI capable web server . Setup \ud83d\udd17 To enable async support, you need to set the ASYNC setting to True . 1 2 3 UNDINE = { \"ASYNC\" : True , } With this, your GraphQL endpoint will change from a sync view to an async view. This allows you to write your Entrypoint resolvers as coroutines. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint async def example ( self , info : GQLInfo ) -> str : return \"foo\" @example . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : # Some permission check logic here return Various parts of the QueryTypes , MutationTypes , and their Fields and Inputs can also be made async. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve async def resolve_name ( self , info : GQLInfo ) -> str : return self . name @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class CustomTaskMutation ( MutationType [ Task ]): name = Input () @name . validate async def validate ( self , info : GQLInfo , value : str ) -> None : return @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return @classmethod async def __mutate__ ( cls , root : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Any : return @classmethod async def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> Any : return @classmethod async def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return Notes \ud83d\udd17 Using async resolvers without ASYNC enabled will raise an error when an operation resolves using that resolver. Existing resolvers e.g. for QueryTypes and MutationTypes will automatically adapt to work in an async context based on the ASYNC setting. Another small detail that is worth noting when ASYNC is enabled is that info.context.user is always fetched eagerly, even if it's not used in the operation. This allows using the request user in synchronous parts of the code, like in permission checks (which cannot be made async due to internal implementation details), without causing an error due to using the Django ORM directly in an async context. Asynchronous execution is also slightly slower than synchronous execution due to inherent overhead of the asyncio event loop. See Django's async documentation for changes that need to be made for Django to work in async context.","title":"Async Support"},{"location":"async/#async-support","text":"In this section, we'll look at how you can make you schema support async operations. Note that asynchronous execution will require an ASGI capable web server .","title":"Async support"},{"location":"async/#setup","text":"To enable async support, you need to set the ASYNC setting to True . 1 2 3 UNDINE = { \"ASYNC\" : True , } With this, your GraphQL endpoint will change from a sync view to an async view. This allows you to write your Entrypoint resolvers as coroutines. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint async def example ( self , info : GQLInfo ) -> str : return \"foo\" @example . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : # Some permission check logic here return Various parts of the QueryTypes , MutationTypes , and their Fields and Inputs can also be made async. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve async def resolve_name ( self , info : GQLInfo ) -> str : return self . name @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class CustomTaskMutation ( MutationType [ Task ]): name = Input () @name . validate async def validate ( self , info : GQLInfo , value : str ) -> None : return @name . permissions async def permissions ( self , info : GQLInfo , value : str ) -> None : return @classmethod async def __mutate__ ( cls , root : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Any : return @classmethod async def __bulk_mutate__ ( cls , instances : list [ Task ], info : GQLInfo , input_data : list [ dict [ str , Any ]]) -> Any : return @classmethod async def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return @classmethod async def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : return","title":"Setup"},{"location":"async/#notes","text":"Using async resolvers without ASYNC enabled will raise an error when an operation resolves using that resolver. Existing resolvers e.g. for QueryTypes and MutationTypes will automatically adapt to work in an async context based on the ASYNC setting. Another small detail that is worth noting when ASYNC is enabled is that info.context.user is always fetched eagerly, even if it's not used in the operation. This allows using the request user in synchronous parts of the code, like in permission checks (which cannot be made async due to internal implementation details), without causing an error due to using the Django ORM directly in an async context. Asynchronous execution is also slightly slower than synchronous execution due to inherent overhead of the asyncio event loop. See Django's async documentation for changes that need to be made for Django to work in async context.","title":"Notes"},{"location":"contributing/","text":"Contributing \ud83d\udd17 Thank you for your interest in contributing! To start, please read the library docs thoroughly. If you don't find what you are looking for, proceed with the steps below. I found a bug! \ud83d\udd17 Please file a bug report . If you are not using the latest version of the library, please upgrade and see if that fixes the issue. If not, please create a minimal example that demonstrates the bug and instructions on how to create that setup from a new virtual environment. Also include any error tracebacks (unabridged when possible). This will help a lot when diagnosing the bug. Do not use pictures to include the traceback. I have a feature request! \ud83d\udd17 You can suggest new features to be implemented via a feature request . You can ask me to implement it or work on it yourself but all features should be discussed and agreed upon first before any coding is done. I have a question! \ud83d\udd17 Please ask it in the discussions section instead of creating an issue. If your question warrants an issue, I'll ask you to create it. Questions about clarifying documentation are appreciated! Creating a pull request \ud83d\udd17 Once you have created a feature request , we have agreed on an implementation, and you wish to work on it, follow these steps to create a pull request. Fork the repository . Clone your fork and create a new branch from the main branch. Set up the environment . Make changes and write tests following these guidelines . Add documentation when applicable following these guidelines . Push the changes to your fork. Create a pull request targeting the main branch. Sit back while your pull request is reviewed . Note that a pull request should always be aimed at solving a single issue. If you want multiple issues solved, make separate pull requests for each. Corrections for spelling mistakes are the exception, since I make so many of those... Pull requests should be kept as small as possible while following the guidelines mentioned above. Smaller pull request are easier to review and test which helps them get merged. Code review process \ud83d\udd17 Pull requests will be reviewed automatically and manually. In the automated phase, GitHub Actions will run testing pipelines for all supported operating systems and python versions, and pre-commit CI will check linting rules. If you encounter any errors, try to fix them based on what the pipelines tell you. If coverage is lowered, add tests, noting the guidelines here . Don't be afraid to ask for advice if you're unsure what is wrong. Note for first-time contributors: Checks are not allowed to run automatically for first-time contributors, so you'll need me to approve them each time you push new code. In the manual phase, I will review the pull request by adding comments with suggestions for changes. If you agree with the suggestions, implement them and push the changes to you fork \u2014 the pull request will be updated automatically. You can either amend your previous commits or add more commits, either is fine. If you disagree with the suggestions, provide your reasons for disagreeing and we can discuss what to do. Once all automated checks have passed and I have accepted the pull request, your code will be merged to the main branch. Any related issues should be closed as completed. I'll usually make a new release after each new feature, but if not, you can also ask for one. Creating a new release \ud83d\udd17 Increment the version in pyproject.toml , loosely following semantic versioning rules. Push the change to the main branch with the commit message Bump version . Draft a new release on GitHub. Use v{version} (e.g. v1.2.3) for the tag name and Release {version} for the release title, using the same version that's in pyproject.toml . Note that the release will be made with the pyproject.toml version and not the tag name! Fill in the release description. Add any attachments when applicable. Publish the release. This will start the release pipeline in GitHub Actions . Check that the release pipeline was successful. If not, delete the tag from origin with git push --delete origin {tag_name} and fix the issue before trying again. Setting up the environment \ud83d\udd17 Install Poetry . Install Just . Run poetry install to create a virtual environment and install project dependencies. Run just hook to install the pre-commit hooks. Run just help to list all existing development commands and their descriptions. Testing \ud83d\udd17 Tests can be run with just tests and individual tests with just test <test_name> . This will run tests in you local environment . You can also test your code in multiple environments with nox . To do this, you must install python interpreters for all python version the library supports and then run just nox . Linting can be run on-demand with just lint or automatically before commits when installed with just hook . Guidelines for writing code \ud83d\udd17 All code should be tested with 100% coverage \ud83d\udd17 Do not write tests simply to archive 100% coverage. Instead, try to write tests for all the ways the feature could be used (use cases), including ways that should not work, and then test for coverage. If you find uncovered code, see if you can remove it, or maybe you simply missed a use case. You should always need more tests to cover all use cases than to achieve 100% coverage. Adding # pragma: no cover to a line of code will ignore it from coverage results, but this should be used very sparingly, as this can lead to undocumented behavior if you are not careful. An example of a line that might be ignored like this is an exception that is raised at the end of a match statement, where its cases cover all possible inputs (basically a statement that should never be reached). All code should be typed when possible \ud83d\udd17 Tests are an exception to this. Make sure the typing construct used is supported in all python versions the library supports. If not, you should reconsider if there is an older alternative, or if there is a backport that can be installed conditionally for the older versions. In these cases, the type should be added to the undine/typing.py file, so that the import logic between the backport and the standard library is contained in one place. Create all custom types in undine/typing.py and import them from there. This helps avoids circular imports and prevents creating duplicate types. Use of TypedDict is encouraged where dicts would be used. All \"public\" functions, methods, and classes should include a docstring \ud83d\udd17 \"Public\" here means that the piece of code is intended to be used by the library users directly, and not inside the library itself. Docstrings should be written in reStructuredText format . Code that is short and clearly self-documenting does not necessarily need a docstring. As an example, def sum(i: int, j: int) -> int: return i + j does not need a docstring. This applies more broadly to arguments, e.g., when a function might need a docstring, the arguments might not need explicit documentation. Keep the docstring to the point. Each line of documentation has a maintenance cost. Documentation is not an excuse to write code that is hard to understand. Docstrings can include code examples, but longer one should be written to docs . All code should be linted using the projects lint rules \ud83d\udd17 Easiest way to do this is to install the pre-commit hooks with just hook . This will make sure the pre-commit hooks will run automatically when you make a commit. You can also run hooks manually with just lint . Comments that ignore linting rules ( # type: ignore[...] , # fmt: off , # noqa: ... ) should be used very sparingly. They are often not necessary and can lead to undocumented behavior if you are not careful. Guidelines for writing documentation \ud83d\udd17 All documentation is written in docs/ using markdown, and built with mkdocs Write in idiomatic english, using simple language Keep examples simple and self-contained Give the reader time to understand the basics before going over edge cases and configurations Use markdown features, like fenced code blocks , blockquotes , horizontal rules , or links , to emphasize and format text If diagrams are needed, use mermaid.js inside fenced code blocks Break up lines around the 100 character mark Do not use emojis Double-check for spelling mistakes and grammar License \ud83d\udd17 By contributing, you agree that your contributions will be licensed under the MIT Licence .","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for your interest in contributing! To start, please read the library docs thoroughly. If you don't find what you are looking for, proceed with the steps below.","title":"Contributing"},{"location":"contributing/#i-found-a-bug","text":"Please file a bug report . If you are not using the latest version of the library, please upgrade and see if that fixes the issue. If not, please create a minimal example that demonstrates the bug and instructions on how to create that setup from a new virtual environment. Also include any error tracebacks (unabridged when possible). This will help a lot when diagnosing the bug. Do not use pictures to include the traceback.","title":"I found a bug!"},{"location":"contributing/#i-have-a-feature-request","text":"You can suggest new features to be implemented via a feature request . You can ask me to implement it or work on it yourself but all features should be discussed and agreed upon first before any coding is done.","title":"I have a feature request!"},{"location":"contributing/#i-have-a-question","text":"Please ask it in the discussions section instead of creating an issue. If your question warrants an issue, I'll ask you to create it. Questions about clarifying documentation are appreciated!","title":"I have a question!"},{"location":"contributing/#creating-a-pull-request","text":"Once you have created a feature request , we have agreed on an implementation, and you wish to work on it, follow these steps to create a pull request. Fork the repository . Clone your fork and create a new branch from the main branch. Set up the environment . Make changes and write tests following these guidelines . Add documentation when applicable following these guidelines . Push the changes to your fork. Create a pull request targeting the main branch. Sit back while your pull request is reviewed . Note that a pull request should always be aimed at solving a single issue. If you want multiple issues solved, make separate pull requests for each. Corrections for spelling mistakes are the exception, since I make so many of those... Pull requests should be kept as small as possible while following the guidelines mentioned above. Smaller pull request are easier to review and test which helps them get merged.","title":"Creating a pull request"},{"location":"contributing/#code-review-process","text":"Pull requests will be reviewed automatically and manually. In the automated phase, GitHub Actions will run testing pipelines for all supported operating systems and python versions, and pre-commit CI will check linting rules. If you encounter any errors, try to fix them based on what the pipelines tell you. If coverage is lowered, add tests, noting the guidelines here . Don't be afraid to ask for advice if you're unsure what is wrong. Note for first-time contributors: Checks are not allowed to run automatically for first-time contributors, so you'll need me to approve them each time you push new code. In the manual phase, I will review the pull request by adding comments with suggestions for changes. If you agree with the suggestions, implement them and push the changes to you fork \u2014 the pull request will be updated automatically. You can either amend your previous commits or add more commits, either is fine. If you disagree with the suggestions, provide your reasons for disagreeing and we can discuss what to do. Once all automated checks have passed and I have accepted the pull request, your code will be merged to the main branch. Any related issues should be closed as completed. I'll usually make a new release after each new feature, but if not, you can also ask for one.","title":"Code review process"},{"location":"contributing/#creating-a-new-release","text":"Increment the version in pyproject.toml , loosely following semantic versioning rules. Push the change to the main branch with the commit message Bump version . Draft a new release on GitHub. Use v{version} (e.g. v1.2.3) for the tag name and Release {version} for the release title, using the same version that's in pyproject.toml . Note that the release will be made with the pyproject.toml version and not the tag name! Fill in the release description. Add any attachments when applicable. Publish the release. This will start the release pipeline in GitHub Actions . Check that the release pipeline was successful. If not, delete the tag from origin with git push --delete origin {tag_name} and fix the issue before trying again.","title":"Creating a new release"},{"location":"contributing/#setting-up-the-environment","text":"Install Poetry . Install Just . Run poetry install to create a virtual environment and install project dependencies. Run just hook to install the pre-commit hooks. Run just help to list all existing development commands and their descriptions.","title":"Setting up the environment"},{"location":"contributing/#testing","text":"Tests can be run with just tests and individual tests with just test <test_name> . This will run tests in you local environment . You can also test your code in multiple environments with nox . To do this, you must install python interpreters for all python version the library supports and then run just nox . Linting can be run on-demand with just lint or automatically before commits when installed with just hook .","title":"Testing"},{"location":"contributing/#guidelines-for-writing-code","text":"","title":"Guidelines for writing code"},{"location":"contributing/#all-code-should-be-tested-with-100-coverage","text":"Do not write tests simply to archive 100% coverage. Instead, try to write tests for all the ways the feature could be used (use cases), including ways that should not work, and then test for coverage. If you find uncovered code, see if you can remove it, or maybe you simply missed a use case. You should always need more tests to cover all use cases than to achieve 100% coverage. Adding # pragma: no cover to a line of code will ignore it from coverage results, but this should be used very sparingly, as this can lead to undocumented behavior if you are not careful. An example of a line that might be ignored like this is an exception that is raised at the end of a match statement, where its cases cover all possible inputs (basically a statement that should never be reached).","title":"All code should be tested with 100% coverage"},{"location":"contributing/#all-code-should-be-typed-when-possible","text":"Tests are an exception to this. Make sure the typing construct used is supported in all python versions the library supports. If not, you should reconsider if there is an older alternative, or if there is a backport that can be installed conditionally for the older versions. In these cases, the type should be added to the undine/typing.py file, so that the import logic between the backport and the standard library is contained in one place. Create all custom types in undine/typing.py and import them from there. This helps avoids circular imports and prevents creating duplicate types. Use of TypedDict is encouraged where dicts would be used.","title":"All code should be typed when possible"},{"location":"contributing/#all-public-functions-methods-and-classes-should-include-a-docstring","text":"\"Public\" here means that the piece of code is intended to be used by the library users directly, and not inside the library itself. Docstrings should be written in reStructuredText format . Code that is short and clearly self-documenting does not necessarily need a docstring. As an example, def sum(i: int, j: int) -> int: return i + j does not need a docstring. This applies more broadly to arguments, e.g., when a function might need a docstring, the arguments might not need explicit documentation. Keep the docstring to the point. Each line of documentation has a maintenance cost. Documentation is not an excuse to write code that is hard to understand. Docstrings can include code examples, but longer one should be written to docs .","title":"All \"public\" functions, methods, and classes should include a docstring"},{"location":"contributing/#all-code-should-be-linted-using-the-projects-lint-rules","text":"Easiest way to do this is to install the pre-commit hooks with just hook . This will make sure the pre-commit hooks will run automatically when you make a commit. You can also run hooks manually with just lint . Comments that ignore linting rules ( # type: ignore[...] , # fmt: off , # noqa: ... ) should be used very sparingly. They are often not necessary and can lead to undocumented behavior if you are not careful.","title":"All code should be linted using the projects lint rules"},{"location":"contributing/#guidelines-for-writing-documentation","text":"All documentation is written in docs/ using markdown, and built with mkdocs Write in idiomatic english, using simple language Keep examples simple and self-contained Give the reader time to understand the basics before going over edge cases and configurations Use markdown features, like fenced code blocks , blockquotes , horizontal rules , or links , to emphasize and format text If diagrams are needed, use mermaid.js inside fenced code blocks Break up lines around the 100 character mark Do not use emojis Double-check for spelling mistakes and grammar","title":"Guidelines for writing documentation"},{"location":"contributing/#license","text":"By contributing, you agree that your contributions will be licensed under the MIT Licence .","title":"License"},{"location":"directives/","text":"Directives \ud83d\udd17 In this section, we'll cover the GraphQL directives in Undine. Directives are a way to add metadata to your GraphQL schema, which can be accessed during query execution or by clients consuming your schema. Directive \ud83d\udd17 In Undine, a GraphQL directive is implemented by subclassing the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... Note that a Directive by itself does not do anything. It is only used as a way to define additional metadata, which the GraphQL server can use at runtime. If the directive implies some behavior, you'll need to add it, e.g., using a ValidationRule . Note that declared Directives are automatically added to the schema, even if they are not used. A Directive always requires the locations it will be used in to be set using the locations argument. The locations can be divided into two categories: executable locations and type system locations . Executable locations \ud83d\udd17 Executable locations identify places in a GraphQL document (i.e. \"request\") where a directive can be used. See the example below on what these locations are. QUERY \ud83d\udd17 1 2 3 4 5 6 7 query ( $pk : Int !) @ new { task ( pk : $pk ) { pk name done } } MUTATION \ud83d\udd17 1 2 3 4 5 mutation ( $input : CreateTaskMutation !) @ new { createTask ( input : $input ) { pk } } SUBSCRIPTION \ud83d\udd17 1 2 3 4 5 6 subscription @ new { comments { username message } } FIELD \ud83d\udd17 1 2 3 4 5 6 7 query { task ( pk : 1 ) { pk @new name done } } FRAGMENT_DEFINITION \ud83d\udd17 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment } } fragment taskFragment on TaskType @new { pk name done } FRAGMENT_SPREAD \ud83d\udd17 1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment @new } } fragment taskFragment on TaskType { pk name done } INLINE_FRAGMENT \ud83d\udd17 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType @new { name } } } VARIABLE_DEFINITION \ud83d\udd17 1 2 3 4 5 6 7 query ( $pk : Int ! @new ) { task ( pk : $pk ) { pk name done } } Type system locations \ud83d\udd17 Type system locations identify places in a GraphQL schema (i.e. \"API\") where a directive can be used. Since Undine is used to define the schema, each type system location corresponds to an Undine object that accepts that type of directive. SCHEMA \ud83d\udd17 The SCHEMA location corresponds to the schema definition itself. Directives can be added here by using the schema_definition_directives argument in the create_schema function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , RootType , create_schema from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . SCHEMA ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Query ( RootType ): @Entrypoint def example ( self , value : str ) -> str : return value schema = create_schema ( query = Query , schema_definition_directives = [ VersionDirective ( value = \"v1.0.0\" )], ) In schema definition 1 2 3 4 5 6 directive @version(value: String!) on SCHEMA schema @version(value: \"v1.0.0\") { query : Query mutation : Mutation } SCALAR \ud83d\udd17 The SCALAR location corresponds to the scalars defined in the schema. In Undine, ScalarType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument from undine.scalars import ScalarType class VersionDirective ( Directive , locations = [ DirectiveLocation . SCALAR ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) Vector3 = tuple [ int , int , int ] vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , directives = [ VersionDirective ( value = \"v1.0.0\" )], ) In schema definition 1 2 3 directive @version(value: String!) on SCALAR scalar Vector3 @version(value: \"1.0.0\") OBJECT \ud83d\udd17 The OBJECT location corresponds to the ObjectTypes defined in the schema. In Undine, QueryTypes and RootTypes accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , QueryType , RootType from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . OBJECT ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... class Query ( RootType , directives = [ VersionDirective ( value = \"v2.0.0\" )]): tasks = Entrypoint ( TaskType , many = True ) In schema definition 1 2 3 4 5 6 7 8 9 10 11 directive @version(value: String!) on OBJECT type TaskType @version(value: \"v1.0.0\") { name : String ! done : Boolean ! createdAt : DateTime ! } type Query @version(value: \"v1.0.0\") { tasks : [ TaskType !]! } FIELD_DEFINITION \ud83d\udd17 The FIELD_DEFINITION location corresponds to the fields defined in the schema. In Undine, Fields , InterfaceFields and Entrypoints accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , Field , InterfaceField , InterfaceType , QueryType , RootType from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ AddedInDirective ( version = \"v1.0.0\" )]) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): created_at = Field ( directives = [ AddedInDirective ( version = \"v1.0.0\" )]) class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 directive @addedIn(version: String!) on FIELD_DEFINITION interface Named { name : String ! @addedIn ( version : \"v1.0.0\" ) } type TaskType implements Named { name : String ! done : Boolean ! createdAt : DateTime ! @addedIn ( version : \"v1.0.0\" ) } type Query { tasks : [ TaskType !]! @addedIn ( version : \"v1.0.0\" ) } ARGUMENT_DEFINITION \ud83d\udd17 The ARGUMENT_DEFINITION location corresponds to the field arguments defined in the schema. In Undine, CalculationArguments and DirectiveArguments accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from django.db.models import Value from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Calculation , CalculationArgument , DjangoExpression , GQLInfo from undine.directives import Directive , DirectiveArgument # Actual directive can be defined in multiple locations, but omit those for brevity. class AddedInDirective ( Directive , locations = [ DirectiveLocation . ARGUMENT_DEFINITION ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ AddedInDirective ( version = \"v1.0.0\" )], ) class Calc ( Calculation [ int ]): value = CalculationArgument ( int , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : return Value ( self . value ) In schema definition 1 2 3 4 5 6 7 8 9 10 11 directive @addedIn(version: String!) on ARGUMENT_DEFINITION directive @new ( version: String! @addedIn(version: \"v1.0.0\") ) on FIELD_DEFINITION type TaskType { calc ( value : Int ! @ addedIn ( version : \"v1.0.0\" ) ): Int ! } INTERFACE \ud83d\udd17 The INTERFACE location corresponds to the interfaces defined in the schema. In Undine, InterfaceType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Named ( InterfaceType , directives = [ VersionDirective ( value = \"v1.0.0\" )]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) In schema definition 1 2 3 4 5 directive @version(value: String!) on INTERFACE interface Named @version(value: \"v1.0.0\") { name : String ! } UNION \ud83d\udd17 The UNION location corresponds to the unions defined in the schema. In Undine, UnionType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import QueryType , UnionType from undine.directives import Directive , DirectiveArgument from .models import Project , Task class VersionDirective ( Directive , locations = [ DirectiveLocation . UNION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObject ( UnionType [ TaskType , ProjectType ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 directive @version(value: String!) on UNION union SearchObject @version(value: \"v1.0.0\") = TaskType | ProjectType ENUM \ud83d\udd17 The ENUM location corresponds to the enums defined in the schema. In Undine, OrderSet accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import OrderSet from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . ENUM ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskOrderSet ( OrderSet [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 4 5 6 directive @version(value: String!) on ENUM enum TaskOrderSet @version(value: \"v1.0.0\") { nameAsc nameDesc } ENUM_VALUE \ud83d\udd17 The ENUM_VALUE location corresponds to the enum values defined in the schema. In Undine, Order accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Order , OrderSet from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 directive @addedIn(version: String!) on ENUM_VALUE enum TaskOrderSet { nameAsc @addedIn ( version : \"v1.0.0\" ) nameDesc @addedIn ( version : \"v1.0.0\" ) } INPUT_OBJECT \ud83d\udd17 The INPUT_OBJECT location corresponds to the input objects defined in the schema. In Undine, MutationType and FilterSet accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import FilterSet , MutationType from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... class CreateTaskMutation ( MutationType [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 4 5 6 7 8 9 directive @version(value: String!) on INPUT_OBJECT input TaskFilterSet @version(value: \"v1.0.0\") { name : String } input TaskCreateMutation @version(value: \"v1.0.0\") { name : String } INPUT_FIELD_DEFINITION \ud83d\udd17 The INPUT_FIELD_DEFINITION location corresponds to the input field definitions defined in the schema. In Undine, Input and Filter accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Filter , FilterSet , Input , MutationType from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ], schema_name = \"addedIn\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ AddedInDirective ( value = \"v1.0.0\" )]) class CreateTaskMutation ( MutationType [ Task ]): name = Input ( directives = [ AddedInDirective ( value = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 7 8 9 directive @addedIn(version: String!) on INPUT_FIELD_DEFINITION input TaskFilterSet { name : String @addedIn ( version : \"v1.0.0\" ) } input TaskCreateMutation { name : String @addedIn ( version : \"v1.0.0\" ) } Is repeatable \ud83d\udd17 A directive can be declared as repeatable using the is_repeatable argument. This means that the directive can be used multiple times in the same location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , RootType from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" , is_repeatable = True , ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Query ( RootType ): @Entrypoint ( directives = [ VersionDirective ( value = \"v1.0.0\" ), VersionDirective ( value = \"v2.0.0\" )]) def example ( self ) -> str : return \"Example\" In schema definition 1 2 3 4 5 directive @version(value: String!) repeatable on FIELD_DEFINITION type Query { example : String ! @version ( value : \"v1.0.0\" ) @version ( value : \"v2.0.0\" ) } Schema name \ud83d\udd17 By default, the name of the generated Directive is the same as the name of the Directive class. You can change this by setting the schema_name argument to the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ... Extensions \ud83d\udd17 You can provide custom extensions for the Directive by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Directive . 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ... Directive extensions are made available in the GraphQL Directive extensions after the schema is created. The Directive itself is found in the extensions under a key defined by the DIRECTIVE_EXTENSIONS_KEY setting. DirectiveArgument \ud83d\udd17 A Directive can optionally have a number of DirectiveArguments defined in the class body. These define the arguments that can or must be used with the directive. A DirectiveArgument always requires input type of the argument, which needs to be a GraphQL input type. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) Schema name \ud83d\udd17 By default, the name of the argument is the same as the name of the attribute to which the DirectiveArgument was defined to in the Directive class. You can change this by setting the schema_name argument to the DirectiveArgument class. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), schema_name = \"version\" ) Description \ud83d\udd17 A description for a DirectiveArgument can be provided in on of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), description = \"Version value.\" ) 2) As class attribute docstring, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) \"\"\"Version value.\"\"\" Default value \ud83d\udd17 A default_value can be provided to set the default value for the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), default_value = \"1.0.0\" ) Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the DirectiveArgument as deprecated. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use something else.\" ) Extensions \ud83d\udd17 You can provide custom extensions for the DirectiveArgument by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) DirectiveArgument extensions are made available in the GraphQL Argument extensions after the schema is created. The DirectiveArgument itself is found in the extensions under a key defined by the DIRECTIVE_ARGUMENT_EXTENSIONS_KEY setting.","title":"Directives"},{"location":"directives/#directives","text":"In this section, we'll cover the GraphQL directives in Undine. Directives are a way to add metadata to your GraphQL schema, which can be accessed during query execution or by clients consuming your schema.","title":"Directives"},{"location":"directives/#directive","text":"In Undine, a GraphQL directive is implemented by subclassing the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... Note that a Directive by itself does not do anything. It is only used as a way to define additional metadata, which the GraphQL server can use at runtime. If the directive implies some behavior, you'll need to add it, e.g., using a ValidationRule . Note that declared Directives are automatically added to the schema, even if they are not used. A Directive always requires the locations it will be used in to be set using the locations argument. The locations can be divided into two categories: executable locations and type system locations .","title":"Directive"},{"location":"directives/#executable-locations","text":"Executable locations identify places in a GraphQL document (i.e. \"request\") where a directive can be used. See the example below on what these locations are.","title":"Executable locations"},{"location":"directives/#query","text":"1 2 3 4 5 6 7 query ( $pk : Int !) @ new { task ( pk : $pk ) { pk name done } }","title":"QUERY"},{"location":"directives/#mutation","text":"1 2 3 4 5 mutation ( $input : CreateTaskMutation !) @ new { createTask ( input : $input ) { pk } }","title":"MUTATION"},{"location":"directives/#subscription","text":"1 2 3 4 5 6 subscription @ new { comments { username message } }","title":"SUBSCRIPTION"},{"location":"directives/#field","text":"1 2 3 4 5 6 7 query { task ( pk : 1 ) { pk @new name done } }","title":"FIELD"},{"location":"directives/#fragment_definition","text":"1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment } } fragment taskFragment on TaskType @new { pk name done }","title":"FRAGMENT_DEFINITION"},{"location":"directives/#fragment_spread","text":"1 2 3 4 5 6 7 8 9 10 11 query { task ( pk : 1 ) { ... taskFragment @new } } fragment taskFragment on TaskType { pk name done }","title":"FRAGMENT_SPREAD"},{"location":"directives/#inline_fragment","text":"1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType @new { name } } }","title":"INLINE_FRAGMENT"},{"location":"directives/#variable_definition","text":"1 2 3 4 5 6 7 query ( $pk : Int ! @new ) { task ( pk : $pk ) { pk name done } }","title":"VARIABLE_DEFINITION"},{"location":"directives/#type-system-locations","text":"Type system locations identify places in a GraphQL schema (i.e. \"API\") where a directive can be used. Since Undine is used to define the schema, each type system location corresponds to an Undine object that accepts that type of directive.","title":"Type system locations"},{"location":"directives/#schema","text":"The SCHEMA location corresponds to the schema definition itself. Directives can be added here by using the schema_definition_directives argument in the create_schema function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , RootType , create_schema from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . SCHEMA ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Query ( RootType ): @Entrypoint def example ( self , value : str ) -> str : return value schema = create_schema ( query = Query , schema_definition_directives = [ VersionDirective ( value = \"v1.0.0\" )], ) In schema definition 1 2 3 4 5 6 directive @version(value: String!) on SCHEMA schema @version(value: \"v1.0.0\") { query : Query mutation : Mutation }","title":"SCHEMA"},{"location":"directives/#scalar","text":"The SCALAR location corresponds to the scalars defined in the schema. In Undine, ScalarType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument from undine.scalars import ScalarType class VersionDirective ( Directive , locations = [ DirectiveLocation . SCALAR ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) Vector3 = tuple [ int , int , int ] vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , directives = [ VersionDirective ( value = \"v1.0.0\" )], ) In schema definition 1 2 3 directive @version(value: String!) on SCALAR scalar Vector3 @version(value: \"1.0.0\")","title":"SCALAR"},{"location":"directives/#object","text":"The OBJECT location corresponds to the ObjectTypes defined in the schema. In Undine, QueryTypes and RootTypes accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , QueryType , RootType from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . OBJECT ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... class Query ( RootType , directives = [ VersionDirective ( value = \"v2.0.0\" )]): tasks = Entrypoint ( TaskType , many = True ) In schema definition 1 2 3 4 5 6 7 8 9 10 11 directive @version(value: String!) on OBJECT type TaskType @version(value: \"v1.0.0\") { name : String ! done : Boolean ! createdAt : DateTime ! } type Query @version(value: \"v1.0.0\") { tasks : [ TaskType !]! }","title":"OBJECT"},{"location":"directives/#field_definition","text":"The FIELD_DEFINITION location corresponds to the fields defined in the schema. In Undine, Fields , InterfaceFields and Entrypoints accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , Field , InterfaceField , InterfaceType , QueryType , RootType from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), directives = [ AddedInDirective ( version = \"v1.0.0\" )]) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): created_at = Field ( directives = [ AddedInDirective ( version = \"v1.0.0\" )]) class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 directive @addedIn(version: String!) on FIELD_DEFINITION interface Named { name : String ! @addedIn ( version : \"v1.0.0\" ) } type TaskType implements Named { name : String ! done : Boolean ! createdAt : DateTime ! @addedIn ( version : \"v1.0.0\" ) } type Query { tasks : [ TaskType !]! @addedIn ( version : \"v1.0.0\" ) }","title":"FIELD_DEFINITION"},{"location":"directives/#argument_definition","text":"The ARGUMENT_DEFINITION location corresponds to the field arguments defined in the schema. In Undine, CalculationArguments and DirectiveArguments accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from django.db.models import Value from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Calculation , CalculationArgument , DjangoExpression , GQLInfo from undine.directives import Directive , DirectiveArgument # Actual directive can be defined in multiple locations, but omit those for brevity. class AddedInDirective ( Directive , locations = [ DirectiveLocation . ARGUMENT_DEFINITION ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"new\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), directives = [ AddedInDirective ( version = \"v1.0.0\" )], ) class Calc ( Calculation [ int ]): value = CalculationArgument ( int , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : return Value ( self . value ) In schema definition 1 2 3 4 5 6 7 8 9 10 11 directive @addedIn(version: String!) on ARGUMENT_DEFINITION directive @new ( version: String! @addedIn(version: \"v1.0.0\") ) on FIELD_DEFINITION type TaskType { calc ( value : Int ! @ addedIn ( version : \"v1.0.0\" ) ): Int ! }","title":"ARGUMENT_DEFINITION"},{"location":"directives/#interface","text":"The INTERFACE location corresponds to the interfaces defined in the schema. In Undine, InterfaceType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . INTERFACE ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Named ( InterfaceType , directives = [ VersionDirective ( value = \"v1.0.0\" )]): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) In schema definition 1 2 3 4 5 directive @version(value: String!) on INTERFACE interface Named @version(value: \"v1.0.0\") { name : String ! }","title":"INTERFACE"},{"location":"directives/#union","text":"The UNION location corresponds to the unions defined in the schema. In Undine, UnionType accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import QueryType , UnionType from undine.directives import Directive , DirectiveArgument from .models import Project , Task class VersionDirective ( Directive , locations = [ DirectiveLocation . UNION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObject ( UnionType [ TaskType , ProjectType ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 directive @version(value: String!) on UNION union SearchObject @version(value: \"v1.0.0\") = TaskType | ProjectType","title":"UNION"},{"location":"directives/#enum","text":"The ENUM location corresponds to the enums defined in the schema. In Undine, OrderSet accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import OrderSet from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . ENUM ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskOrderSet ( OrderSet [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 4 5 6 directive @version(value: String!) on ENUM enum TaskOrderSet @version(value: \"v1.0.0\") { nameAsc nameDesc }","title":"ENUM"},{"location":"directives/#enum_value","text":"The ENUM_VALUE location corresponds to the enum values defined in the schema. In Undine, Order accepts Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Order , OrderSet from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ], schema_name = \"addedIn\" ): version = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" , directives = [ AddedInDirective ( version = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 directive @addedIn(version: String!) on ENUM_VALUE enum TaskOrderSet { nameAsc @addedIn ( version : \"v1.0.0\" ) nameDesc @addedIn ( version : \"v1.0.0\" ) }","title":"ENUM_VALUE"},{"location":"directives/#input_object","text":"The INPUT_OBJECT location corresponds to the input objects defined in the schema. In Undine, MutationType and FilterSet accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import FilterSet , MutationType from undine.directives import Directive , DirectiveArgument from .models import Task class VersionDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... class CreateTaskMutation ( MutationType [ Task ], directives = [ VersionDirective ( value = \"v1.0.0\" )]): ... In schema definition 1 2 3 4 5 6 7 8 9 directive @version(value: String!) on INPUT_OBJECT input TaskFilterSet @version(value: \"v1.0.0\") { name : String } input TaskCreateMutation @version(value: \"v1.0.0\") { name : String }","title":"INPUT_OBJECT"},{"location":"directives/#input_field_definition","text":"The INPUT_FIELD_DEFINITION location corresponds to the input field definitions defined in the schema. In Undine, Input and Filter accept Directives declared for this location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Filter , FilterSet , Input , MutationType from undine.directives import Directive , DirectiveArgument from .models import Task class AddedInDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ], schema_name = \"addedIn\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ AddedInDirective ( value = \"v1.0.0\" )]) class CreateTaskMutation ( MutationType [ Task ]): name = Input ( directives = [ AddedInDirective ( value = \"v1.0.0\" )]) In schema definition 1 2 3 4 5 6 7 8 9 directive @addedIn(version: String!) on INPUT_FIELD_DEFINITION input TaskFilterSet { name : String @addedIn ( version : \"v1.0.0\" ) } input TaskCreateMutation { name : String @addedIn ( version : \"v1.0.0\" ) }","title":"INPUT_FIELD_DEFINITION"},{"location":"directives/#is-repeatable","text":"A directive can be declared as repeatable using the is_repeatable argument. This means that the directive can be used multiple times in the same location. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine import Entrypoint , RootType from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" , is_repeatable = True , ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) class Query ( RootType ): @Entrypoint ( directives = [ VersionDirective ( value = \"v1.0.0\" ), VersionDirective ( value = \"v2.0.0\" )]) def example ( self ) -> str : return \"Example\" In schema definition 1 2 3 4 5 directive @version(value: String!) repeatable on FIELD_DEFINITION type Query { example : String ! @version ( value : \"v1.0.0\" ) @version ( value : \"v2.0.0\" ) }","title":"Is repeatable"},{"location":"directives/#schema-name","text":"By default, the name of the generated Directive is the same as the name of the Directive class. You can change this by setting the schema_name argument to the Directive class. 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ...","title":"Schema name"},{"location":"directives/#extensions","text":"You can provide custom extensions for the Directive by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Directive . 1 2 3 4 5 6 from graphql import DirectiveLocation from undine.directives import Directive class NewDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], extensions = { \"foo\" : \"bar\" }): ... Directive extensions are made available in the GraphQL Directive extensions after the schema is created. The Directive itself is found in the extensions under a key defined by the DIRECTIVE_EXTENSIONS_KEY setting.","title":"Extensions"},{"location":"directives/#directiveargument","text":"A Directive can optionally have a number of DirectiveArguments defined in the class body. These define the arguments that can or must be used with the directive. A DirectiveArgument always requires input type of the argument, which needs to be a GraphQL input type. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ))","title":"DirectiveArgument"},{"location":"directives/#schema-name_1","text":"By default, the name of the argument is the same as the name of the attribute to which the DirectiveArgument was defined to in the Directive class. You can change this by setting the schema_name argument to the DirectiveArgument class. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), schema_name = \"version\" )","title":"Schema name"},{"location":"directives/#description","text":"A description for a DirectiveArgument can be provided in on of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), description = \"Version value.\" ) 2) As class attribute docstring, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString )) \"\"\"Version value.\"\"\"","title":"Description"},{"location":"directives/#default-value","text":"A default_value can be provided to set the default value for the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), default_value = \"1.0.0\" )","title":"Default value"},{"location":"directives/#deprecation-reason","text":"A deprecation_reason can be provided to mark the DirectiveArgument as deprecated. 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"directives/#extensions_1","text":"You can provide custom extensions for the DirectiveArgument by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the DirectiveArgument . 1 2 3 4 5 6 7 from graphql import DirectiveLocation , GraphQLNonNull , GraphQLString from undine.directives import Directive , DirectiveArgument class VersionDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ], schema_name = \"version\" ): value = DirectiveArgument ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) DirectiveArgument extensions are made available in the GraphQL Argument extensions after the schema is created. The DirectiveArgument itself is found in the extensions under a key defined by the DIRECTIVE_ARGUMENT_EXTENSIONS_KEY setting.","title":"Extensions"},{"location":"faq/","text":"FAQ \ud83d\udd17 Here are some common questions you might have when it comes to using Undine or why it's designed the way it is. If you don't find an answer here, please ask a question on the discussion page . Why are all the methods dunder method on, e.g., the QueryType class? \ud83d\udd17 This is to avoid name collisions with possible names of Fields that can be added to the class body of a QueryType class. In GraphQL, all names starting with two underscores are reserved by GraphQL, e.g. __typename , so by this logic, all dunder methods cannot collide with any fields you might want.","title":"FAQ"},{"location":"faq/#faq","text":"Here are some common questions you might have when it comes to using Undine or why it's designed the way it is. If you don't find an answer here, please ask a question on the discussion page .","title":"FAQ"},{"location":"faq/#why-are-all-the-methods-dunder-method-on-eg-the-querytype-class","text":"This is to avoid name collisions with possible names of Fields that can be added to the class body of a QueryType class. In GraphQL, all names starting with two underscores are reserved by GraphQL, e.g. __typename , so by this logic, all dunder methods cannot collide with any fields you might want.","title":"Why are all the methods dunder method on, e.g., the QueryType class?"},{"location":"file-upload/","text":"File Upload \ud83d\udd17 In this section, we'll cover the everything necessary for adding support for file uploads to your GraphQL schema using the GraphQL multipart request specification specification. Setup \ud83d\udd17 Undine supports file uploads, but they disabled by default due to security reasons. Specifically, since file uploads are sent using a multipart/form-data request, they may be sent without a CORS preflight request if the browser determines the requests meets the criteria for a \"simple request\" . Therefore, you should make sure CSRF protection is enabled on the GraphQL endpoint. This can be done by making sure that the GraphQL view has the @csrf_protect decorator, or that the CsrfViewMiddleware exists in your MIDDLEWARE setting (and the view is not using @csrf_exempt ). 1 2 3 4 5 MIDDLEWARE = [ # ... \"django.middleware.csrf.CsrfViewMiddleware\" , # ... ] Then you can enable file uploads by adding the following to your settings: 1 2 3 UNDINE = { \"FILE_UPLOAD_ENABLED\" : True , } Uploading files \ud83d\udd17 Undine has two Scalars for uploading files: File for uploading general files, and Image for uploading images. They correspond to Django's FileField and ImageField respectively. The Image scalar performs additional validations on the uploaded image, such as checking if the uploaded file is an image file. Like Django's ImageField , using the Image scalar requires the Pillow library to be installed. You can install it together with Undine using pip install undine[image] . Now, let's suppose we have the following model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) image = models . ImageField () If we create a basic setup for creating a Task : 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class TaskCreateMutation ( MutationType [ Task ]): ... class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) Our GraphQL schema will have the following input object type: 1 2 3 4 input TaskCreateMutation { name : String ! image : Image ! } Now the client can send a request that conforms to the GraphQL multipart request specification , and Undine's GraphQL view will parse the request and slot the files into the correct locations in the input data. Example request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 POST /graphql/ HTTP/1.1 Content-Type: multipart/form-data; boundary=--BoUnDaRyStRiNg Content-Length: 490 --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"operations\" {\"query\": \"mutation($input: TaskCreateMutation!) { createTask(input: $input) { pk } }\", \"variables\": {\"input\": {\"name\": \"Task\", \"image\": null}}} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"map\" {\"0\": [\"variables.input.image\"]} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"0\"; filename=\"image.png\" \\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x02\\x00\\x00\\x00\\x90wS\\xde\\x00\\x00\\x00\\x0cIDATx\\x01c```\\x00\\x00\\x00\\x04\\x00\\x01\\xe4\\x94\\x84\\x06\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82 --BoUnDaRyStRiNg-- See the Implementations section in the GraphQL multipart request specification for client side libraries that support file uploads.","title":"File Upload"},{"location":"file-upload/#file-upload","text":"In this section, we'll cover the everything necessary for adding support for file uploads to your GraphQL schema using the GraphQL multipart request specification specification.","title":"File Upload"},{"location":"file-upload/#setup","text":"Undine supports file uploads, but they disabled by default due to security reasons. Specifically, since file uploads are sent using a multipart/form-data request, they may be sent without a CORS preflight request if the browser determines the requests meets the criteria for a \"simple request\" . Therefore, you should make sure CSRF protection is enabled on the GraphQL endpoint. This can be done by making sure that the GraphQL view has the @csrf_protect decorator, or that the CsrfViewMiddleware exists in your MIDDLEWARE setting (and the view is not using @csrf_exempt ). 1 2 3 4 5 MIDDLEWARE = [ # ... \"django.middleware.csrf.CsrfViewMiddleware\" , # ... ] Then you can enable file uploads by adding the following to your settings: 1 2 3 UNDINE = { \"FILE_UPLOAD_ENABLED\" : True , }","title":"Setup"},{"location":"file-upload/#uploading-files","text":"Undine has two Scalars for uploading files: File for uploading general files, and Image for uploading images. They correspond to Django's FileField and ImageField respectively. The Image scalar performs additional validations on the uploaded image, such as checking if the uploaded file is an image file. Like Django's ImageField , using the Image scalar requires the Pillow library to be installed. You can install it together with Undine using pip install undine[image] . Now, let's suppose we have the following model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) image = models . ImageField () If we create a basic setup for creating a Task : 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Entrypoint , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class TaskCreateMutation ( MutationType [ Task ]): ... class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) Our GraphQL schema will have the following input object type: 1 2 3 4 input TaskCreateMutation { name : String ! image : Image ! } Now the client can send a request that conforms to the GraphQL multipart request specification , and Undine's GraphQL view will parse the request and slot the files into the correct locations in the input data. Example request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 POST /graphql/ HTTP/1.1 Content-Type: multipart/form-data; boundary=--BoUnDaRyStRiNg Content-Length: 490 --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"operations\" {\"query\": \"mutation($input: TaskCreateMutation!) { createTask(input: $input) { pk } }\", \"variables\": {\"input\": {\"name\": \"Task\", \"image\": null}}} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"map\" {\"0\": [\"variables.input.image\"]} --BoUnDaRyStRiNg Content-Disposition: form-data; name=\"0\"; filename=\"image.png\" \\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x02\\x00\\x00\\x00\\x90wS\\xde\\x00\\x00\\x00\\x0cIDATx\\x01c```\\x00\\x00\\x00\\x04\\x00\\x01\\xe4\\x94\\x84\\x06\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82 --BoUnDaRyStRiNg-- See the Implementations section in the GraphQL multipart request specification for client side libraries that support file uploads.","title":"Uploading files"},{"location":"filtering/","text":"Filtering \ud83d\udd17 In this section, we'll cover the everything necessary for filtering results returned by your QueryTypes . FilterSet \ud83d\udd17 A FilterSet is a collection of Filter objects that can be applied to a QueryType . In GraphQL, they represent an InputObjectType , which when added to a QueryType creates an input argument for filtering the results of a QueryType . A basic FilterSet is created by subclassing FilterSet and adding its Django Model as a generic type parameter. Then, the FilterSet can be added to a QueryType using the filterset argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): name = Field () You can also add the FilterSet using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @TaskFilterSet class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 A FilterSet can automatically introspect its Django model and convert the model's fields to Filters on the FilterSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) An auto-generated FilterSet will have all of the Task model's fields and those fields' lookups translated into input arguments. Here is the generated InputObjectType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 input TaskFilterSet { createdAt : DateTime createdAtDate : Date createdAtDateGt : Date createdAtDateGte : Date createdAtDateIn : [ Date !] createdAtDateLt : Date createdAtDateLte : Date createdAtDateRange : [ Date !] createdAtDay : Int createdAtDayContains : Int createdAtDayEndsWith : Int createdAtDayGt : Int createdAtDayGte : Int createdAtDayIn : [ Int !] createdAtDayLt : Int createdAtDayLte : Int createdAtDayRange : [ Int !] createdAtDayStartsWith : Int createdAtGt : DateTime createdAtGte : DateTime createdAtHour : Int createdAtHourContains : Int createdAtHourEndsWith : Int createdAtHourGt : Int createdAtHourGte : Int createdAtHourIn : [ Int !] createdAtHourLt : Int createdAtHourLte : Int createdAtHourRange : [ Int !] createdAtHourStartsWith : Int createdAtIn : [ DateTime !] createdAtIsoWeekDay : Int createdAtIsoWeekDayContains : Int createdAtIsoWeekDayEndsWith : Int createdAtIsoWeekDayGt : Int createdAtIsoWeekDayGte : Int createdAtIsoWeekDayIn : [ Int !] createdAtIsoWeekDayLt : Int createdAtIsoWeekDayLte : Int createdAtIsoWeekDayRange : [ Int !] createdAtIsoWeekDayStartsWith : Int createdAtIsoYear : Int createdAtIsoYearContains : Int createdAtIsoYearEndsWith : Int createdAtIsoYearGt : Int createdAtIsoYearGte : Int createdAtIsoYearIn : [ Int !] createdAtIsoYearLt : Int createdAtIsoYearLte : Int createdAtIsoYearRange : [ Int !] createdAtIsoYearStartsWith : Int createdAtLt : DateTime createdAtLte : DateTime createdAtMinute : Int createdAtMinuteContains : Int createdAtMinuteEndsWith : Int createdAtMinuteGt : Int createdAtMinuteGte : Int createdAtMinuteIn : [ Int !] createdAtMinuteLt : Int createdAtMinuteLte : Int createdAtMinuteRange : [ Int !] createdAtMinuteStartsWith : Int createdAtMonth : Int createdAtMonthContains : Int createdAtMonthEndsWith : Int createdAtMonthGt : Int createdAtMonthGte : Int createdAtMonthIn : [ Int !] createdAtMonthLt : Int createdAtMonthLte : Int createdAtMonthRange : [ Int !] createdAtMonthStartsWith : Int createdAtQuarter : Int createdAtQuarterContains : Int createdAtQuarterEndsWith : Int createdAtQuarterGt : Int createdAtQuarterGte : Int createdAtQuarterIn : [ Int !] createdAtQuarterLt : Int createdAtQuarterLte : Int createdAtQuarterRange : [ Int !] createdAtQuarterStartsWith : Int createdAtRange : [ DateTime !] createdAtSecond : Int createdAtSecondContains : Int createdAtSecondEndsWith : Int createdAtSecondGt : Int createdAtSecondGte : Int createdAtSecondIn : [ Int !] createdAtSecondLt : Int createdAtSecondLte : Int createdAtSecondRange : [ Int !] createdAtSecondStartsWith : Int createdAtTime : Time createdAtTimeContains : Time createdAtTimeEndsWith : Time createdAtTimeGt : Time createdAtTimeGte : Time createdAtTimeIn : [ Time !] createdAtTimeLt : Time createdAtTimeLte : Time createdAtTimeRange : [ Time !] createdAtTimeStartsWith : Time createdAtWeek : Int createdAtWeekContains : Int createdAtWeekDay : Int createdAtWeekDayContains : Int createdAtWeekDayEndsWith : Int createdAtWeekDayGt : Int createdAtWeekDayGte : Int createdAtWeekDayIn : [ Int !] createdAtWeekDayLt : Int createdAtWeekDayLte : Int createdAtWeekDayRange : [ Int !] createdAtWeekDayStartsWith : Int createdAtWeekEndsWith : Int createdAtWeekGt : Int createdAtWeekGte : Int createdAtWeekIn : [ Int !] createdAtWeekLt : Int createdAtWeekLte : Int createdAtWeekRange : [ Int !] createdAtWeekStartsWith : Int createdAtYear : Int createdAtYearContains : Int createdAtYearEndsWith : Int createdAtYearGt : Int createdAtYearGte : Int createdAtYearIn : [ Int !] createdAtYearLt : Int createdAtYearLte : Int createdAtYearRange : [ Int !] createdAtYearStartsWith : Int done : Boolean name : String nameContains : String nameContainsExact : String nameEndsWith : String nameEndsWithExact : String nameExact : String nameIn : [ String !] nameStartsWith : String nameStartsWithExact : String pk : Int pkContains : Int pkEndsWith : Int pkGt : Int pkGte : Int pkIn : [ Int !] pkLt : Int pkLte : Int pkRange : [ Int !] pkStartsWith : Int project : Int projectGt : Int projectGte : Int projectIn : [ Int !] projectIsNull : Boolean projectLt : Int projectLte : Int NOT : TaskFilterSet AND : TaskFilterSet OR : TaskFilterSet XOR : TaskFilterSet } About Filter names Usually the names of the Filters generated by auto-generation correspond to the lookup in Django, but for text-based fields, names are changed slightly to lean towards using case-insensitive lookups first: Filter name uses __iexact and nameExact uses __exact . Similarly, nameStartsWith uses __istartswith while nameStartsWithExact uses __startswith , etc. To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the FilterSet class definition. With this, you can leave the FilterSet class body empty. 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True , exclude = [ \"created_at\" ]): ... You can also exclude specific model lookups, e.g. created_at__gte . Logical operators \ud83d\udd17 A FilterSet always provides the logical operators NOT , AND , OR , XOR , allowing users to freely create more complex conditions from defined filters. Let's assume you've added an auto-generated TaskFilterSet to a QueryType named TaskType . Normally, when multiple filter's are used, we'll get results where all results match all filters. 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameStartsWith : \"a\" done : true } ) { name } } However, by adding the filter to an OR block, we can get results where any of the conditions match: 1 2 3 4 5 6 7 8 9 10 11 12 query { tasks ( filter : { OR : { nameStartsWith : \"a\" done : true } } ) { name } } Note that only the results inside the conditional block will use that logical combinator. For example, in the following example, only tasks that contains an \"e\" AND EITHER start with \"a\" OR are done will be returned: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { nameContains : \"e\" OR : { nameStartsWith : \"a\" done : true } } ) { name } } Filter queryset \ud83d\udd17 Together with its Filters , a FilterSet also provides a __filter_queryset__ classmethod. This method can be used to add filtering that should always be applied when fetching objects through QueryTypes using this FilterSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_staff : return queryset . none () return queryset As QueryTypes also have a __filter_queryset__ classmethod, its important to note the order in which these are applied by the Optimizer . Schema name \ud83d\udd17 By default, the name of the generated InputObjectType is the same as the name of the FilterSet class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], schema_name = \"TaskFilterInput\" ): name = Filter () Description \ud83d\udd17 You can provide a description using the description argument. 1 2 3 4 5 6 7 8 9 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): \"\"\"Description.\"\"\" name = Filter () Directives \ud83d\udd17 You can add directives to the FilterSet by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ MyDirective ()]): name = Filter () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a FilterSet from certain users by adding the visible argument to the FilterSet . Hiding a filterset means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the FilterSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the FilterSet . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Filter () FilterSet extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The FilterSet itself is found in the extensions under a key defined by the FILTERSET_EXTENSIONS_KEY setting. Filter \ud83d\udd17 A Filter is a class that is used to define a possible filter input for a FilterSet . Usually Filters correspond to fields on the Django model for their respective FilterSet . In GraphQL, it represents an GraphQLInputField in an InputObjectType . A Filter always requires a reference from which it will create the proper GraphQL resolver, input type for the Filter . Model field references \ud83d\udd17 For Filters corresponding to Django model fields, the Filter can be used without passing in a reference, as its attribute name in the FilterSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): title = Filter ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as the references. These create an alias in the queryset when the Filter is used. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_upper = Filter ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Filter , FilterSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): copies = Filter ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Function references \ud83d\udd17 Functions (or methods) can also be used to create Filters . This can be done by decorating a method with the Filter class. 1 2 3 4 5 6 7 8 9 10 11 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : return Q ( name__iexact = value ) The Filter method should return a Q expression. The type of the value argument is used as the input type for the Filter , so typing it is required. About method signature The decorated method is treated as a static method by the Filter . The self argument is not an instance of the FilterSet , but the instance of the Filter that is being used. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument is the value provided for the filter. It should always be named \"value\", and is required to be a keyword only argument. Lookup \ud83d\udd17 By default, when defining a Filter on a FilterSet , the \"exact\" lookup expression is used. This can be changed by providing the lookup argument to the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( lookup = \"icontains\" ) Many \ud83d\udd17 The many argument changes the behavior of the Filter such that it takes a list of values instead of a single value. Then, each of the values are combined as defined by the match argument to form a single filter condition. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" ) This would create the following filter input: 1 2 3 input TaskFilterSet { name : [ String !] } So if a query is filtered using this filter with the value [\"foo\", \"bar\"] , the filter condition would be Q(name__icontains=\"foo\") | Q(name__icontains=\"bar\") . Match \ud83d\udd17 The match changes the behavior of the many argument to combine the provided values with a different operation. The default is any , which means that the filter condition will include an item if it matches any of the provided values. The match argument can be set to all if all of the values should match, or one_of if only one of the values should match. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" , match = \"all\" ) Distinct \ud83d\udd17 If using some Filter would require a call to queryset.distinct() (e.g. lookups spanning \"to-many\" relations), you can use the distinct argument to tell the FilterSet for the Filter to do that if the Filter is used in a query. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( distinct = True ) Required \ud83d\udd17 By default, all Filter are not required (nullable in GraphQL terms). If you want to make a Filter required, you can do so by setting the required argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( required = True ) Aliases \ud83d\udd17 Sometimes a Filter may require additional expressions to be added as aliases to the queryset when the Filter is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import F , OuterRef , Q from undine import DjangoExpression , Filter , FilterSet , GQLInfo from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): has_more_copies = Filter ( Q ( copies__gt = F ( \"non_copies\" ))) @has_more_copies . aliases def has_more_copies_aliases ( self , info : GQLInfo , * , value : bool ) -> dict [ str , DjangoExpression ]: return { \"copies\" : SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))), \"non_copies\" : SubqueryCount ( Task . objects . exclude ( name = OuterRef ( \"name\" ))), } Empty values \ud83d\udd17 By default, Filters will ignore some values which are considered \"empty\" in the context of filtering. These values are set globally by the EMPTY_VALUES setting. Usually this is what you want, as it allows you to set default values in our GraphQL variables. If you wish to change what's considered an empty value for an individual Filter , you can do so by setting the empty_values argument to a list of values. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): # Allow filtering with the empty string or None title = Filter ( empty_values = []) Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django model field name that the Filter corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): field_name = Filter ( field_name = \"name\" ) Schema name \ud83d\udd17 A schema_name can be provided to override the name of the Filter in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Filter attribute name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( schema_name = \"title\" ) Description \ud83d\udd17 By default, a Filter is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( description = \"Get only tasks with the given name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () \"\"\"Get only tasks with the given name.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : \"\"\"Get only tasks with the given name.\"\"\" return Q ( name__iexact = value ) Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Filter as deprecated. This is for documentation purposes only, and does not affect the use of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( deprecation_reason = \"Use something else.\" ) Empty filter result \ud83d\udd17 A special EmptyFilterResult exception can be raised from a Filter to indicate that the usage of the Filter should result in an empty queryset, e.g. because of the value given or for permission reasons. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet , GQLInfo from undine.exceptions import EmptyFilterResult from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> bool : if value == \"secret\" : raise EmptyFilterResult return True Raising this exceptions skips the rest of the Filter logic and results in an empty queryset. Permissions \ud83d\udd17 You can add permissions check to individual Filters by using a custom function and adding the permission check inline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import GraphQLPermissionError from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : msg = \"Only authenticated users can filter by task names.\" raise GraphQLPermissionError ( msg ) return Q ( name__icontains = value ) You can also raise the EmptyFilterResult exception if the usage of the filter should result in an empty queryset instead of an error. Directives \ud83d\udd17 You can add directives to the Filter by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ MyDirective ()]) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Filter from certain users by adding the visible argument to the Filter . Hiding a filter means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Filter by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( extensions = { \"foo\" : \"bar\" }) Filter extensions are made available in the GraphQL InputField extensions after the schema is created. The Filter itself is found in the extensions under a key defined by the FILTER_EXTENSIONS_KEY setting.","title":"Filtering"},{"location":"filtering/#filtering","text":"In this section, we'll cover the everything necessary for filtering results returned by your QueryTypes .","title":"Filtering"},{"location":"filtering/#filterset","text":"A FilterSet is a collection of Filter objects that can be applied to a QueryType . In GraphQL, they represent an InputObjectType , which when added to a QueryType creates an input argument for filtering the results of a QueryType . A basic FilterSet is created by subclassing FilterSet and adding its Django Model as a generic type parameter. Then, the FilterSet can be added to a QueryType using the filterset argument. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): name = Field () You can also add the FilterSet using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @TaskFilterSet class TaskType ( QueryType [ Task ]): name = Field ()","title":"FilterSet"},{"location":"filtering/#auto-generation","text":"A FilterSet can automatically introspect its Django model and convert the model's fields to Filters on the FilterSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) An auto-generated FilterSet will have all of the Task model's fields and those fields' lookups translated into input arguments. Here is the generated InputObjectType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 input TaskFilterSet { createdAt : DateTime createdAtDate : Date createdAtDateGt : Date createdAtDateGte : Date createdAtDateIn : [ Date !] createdAtDateLt : Date createdAtDateLte : Date createdAtDateRange : [ Date !] createdAtDay : Int createdAtDayContains : Int createdAtDayEndsWith : Int createdAtDayGt : Int createdAtDayGte : Int createdAtDayIn : [ Int !] createdAtDayLt : Int createdAtDayLte : Int createdAtDayRange : [ Int !] createdAtDayStartsWith : Int createdAtGt : DateTime createdAtGte : DateTime createdAtHour : Int createdAtHourContains : Int createdAtHourEndsWith : Int createdAtHourGt : Int createdAtHourGte : Int createdAtHourIn : [ Int !] createdAtHourLt : Int createdAtHourLte : Int createdAtHourRange : [ Int !] createdAtHourStartsWith : Int createdAtIn : [ DateTime !] createdAtIsoWeekDay : Int createdAtIsoWeekDayContains : Int createdAtIsoWeekDayEndsWith : Int createdAtIsoWeekDayGt : Int createdAtIsoWeekDayGte : Int createdAtIsoWeekDayIn : [ Int !] createdAtIsoWeekDayLt : Int createdAtIsoWeekDayLte : Int createdAtIsoWeekDayRange : [ Int !] createdAtIsoWeekDayStartsWith : Int createdAtIsoYear : Int createdAtIsoYearContains : Int createdAtIsoYearEndsWith : Int createdAtIsoYearGt : Int createdAtIsoYearGte : Int createdAtIsoYearIn : [ Int !] createdAtIsoYearLt : Int createdAtIsoYearLte : Int createdAtIsoYearRange : [ Int !] createdAtIsoYearStartsWith : Int createdAtLt : DateTime createdAtLte : DateTime createdAtMinute : Int createdAtMinuteContains : Int createdAtMinuteEndsWith : Int createdAtMinuteGt : Int createdAtMinuteGte : Int createdAtMinuteIn : [ Int !] createdAtMinuteLt : Int createdAtMinuteLte : Int createdAtMinuteRange : [ Int !] createdAtMinuteStartsWith : Int createdAtMonth : Int createdAtMonthContains : Int createdAtMonthEndsWith : Int createdAtMonthGt : Int createdAtMonthGte : Int createdAtMonthIn : [ Int !] createdAtMonthLt : Int createdAtMonthLte : Int createdAtMonthRange : [ Int !] createdAtMonthStartsWith : Int createdAtQuarter : Int createdAtQuarterContains : Int createdAtQuarterEndsWith : Int createdAtQuarterGt : Int createdAtQuarterGte : Int createdAtQuarterIn : [ Int !] createdAtQuarterLt : Int createdAtQuarterLte : Int createdAtQuarterRange : [ Int !] createdAtQuarterStartsWith : Int createdAtRange : [ DateTime !] createdAtSecond : Int createdAtSecondContains : Int createdAtSecondEndsWith : Int createdAtSecondGt : Int createdAtSecondGte : Int createdAtSecondIn : [ Int !] createdAtSecondLt : Int createdAtSecondLte : Int createdAtSecondRange : [ Int !] createdAtSecondStartsWith : Int createdAtTime : Time createdAtTimeContains : Time createdAtTimeEndsWith : Time createdAtTimeGt : Time createdAtTimeGte : Time createdAtTimeIn : [ Time !] createdAtTimeLt : Time createdAtTimeLte : Time createdAtTimeRange : [ Time !] createdAtTimeStartsWith : Time createdAtWeek : Int createdAtWeekContains : Int createdAtWeekDay : Int createdAtWeekDayContains : Int createdAtWeekDayEndsWith : Int createdAtWeekDayGt : Int createdAtWeekDayGte : Int createdAtWeekDayIn : [ Int !] createdAtWeekDayLt : Int createdAtWeekDayLte : Int createdAtWeekDayRange : [ Int !] createdAtWeekDayStartsWith : Int createdAtWeekEndsWith : Int createdAtWeekGt : Int createdAtWeekGte : Int createdAtWeekIn : [ Int !] createdAtWeekLt : Int createdAtWeekLte : Int createdAtWeekRange : [ Int !] createdAtWeekStartsWith : Int createdAtYear : Int createdAtYearContains : Int createdAtYearEndsWith : Int createdAtYearGt : Int createdAtYearGte : Int createdAtYearIn : [ Int !] createdAtYearLt : Int createdAtYearLte : Int createdAtYearRange : [ Int !] createdAtYearStartsWith : Int done : Boolean name : String nameContains : String nameContainsExact : String nameEndsWith : String nameEndsWithExact : String nameExact : String nameIn : [ String !] nameStartsWith : String nameStartsWithExact : String pk : Int pkContains : Int pkEndsWith : Int pkGt : Int pkGte : Int pkIn : [ Int !] pkLt : Int pkLte : Int pkRange : [ Int !] pkStartsWith : Int project : Int projectGt : Int projectGte : Int projectIn : [ Int !] projectIsNull : Boolean projectLt : Int projectLte : Int NOT : TaskFilterSet AND : TaskFilterSet OR : TaskFilterSet XOR : TaskFilterSet } About Filter names Usually the names of the Filters generated by auto-generation correspond to the lookup in Django, but for text-based fields, names are changed slightly to lean towards using case-insensitive lookups first: Filter name uses __iexact and nameExact uses __exact . Similarly, nameStartsWith uses __istartswith while nameStartsWithExact uses __startswith , etc. To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the FilterSet class definition. With this, you can leave the FilterSet class body empty. 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], auto = True , exclude = [ \"created_at\" ]): ... You can also exclude specific model lookups, e.g. created_at__gte .","title":"Auto-generation"},{"location":"filtering/#logical-operators","text":"A FilterSet always provides the logical operators NOT , AND , OR , XOR , allowing users to freely create more complex conditions from defined filters. Let's assume you've added an auto-generated TaskFilterSet to a QueryType named TaskType . Normally, when multiple filter's are used, we'll get results where all results match all filters. 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameStartsWith : \"a\" done : true } ) { name } } However, by adding the filter to an OR block, we can get results where any of the conditions match: 1 2 3 4 5 6 7 8 9 10 11 12 query { tasks ( filter : { OR : { nameStartsWith : \"a\" done : true } } ) { name } } Note that only the results inside the conditional block will use that logical combinator. For example, in the following example, only tasks that contains an \"e\" AND EITHER start with \"a\" OR are done will be returned: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { nameContains : \"e\" OR : { nameStartsWith : \"a\" done : true } } ) { name } }","title":"Logical operators"},{"location":"filtering/#filter-queryset","text":"Together with its Filters , a FilterSet also provides a __filter_queryset__ classmethod. This method can be used to add filtering that should always be applied when fetching objects through QueryTypes using this FilterSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_staff : return queryset . none () return queryset As QueryTypes also have a __filter_queryset__ classmethod, its important to note the order in which these are applied by the Optimizer .","title":"Filter queryset"},{"location":"filtering/#schema-name","text":"By default, the name of the generated InputObjectType is the same as the name of the FilterSet class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], schema_name = \"TaskFilterInput\" ): name = Filter ()","title":"Schema name"},{"location":"filtering/#description","text":"You can provide a description using the description argument. 1 2 3 4 5 6 7 8 9 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): \"\"\"Description.\"\"\" name = Filter ()","title":"Description"},{"location":"filtering/#directives","text":"You can add directives to the FilterSet by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_OBJECT ]): ... class TaskFilterSet ( FilterSet [ Task ], directives = [ MyDirective ()]): name = Filter () See the Directives section for more details on directives.","title":"Directives"},{"location":"filtering/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a FilterSet from certain users by adding the visible argument to the FilterSet . Hiding a filterset means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"filtering/#graphql-extensions","text":"You can provide custom extensions for the FilterSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the FilterSet . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Filter () FilterSet extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The FilterSet itself is found in the extensions under a key defined by the FILTERSET_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"filtering/#filter","text":"A Filter is a class that is used to define a possible filter input for a FilterSet . Usually Filters correspond to fields on the Django model for their respective FilterSet . In GraphQL, it represents an GraphQLInputField in an InputObjectType . A Filter always requires a reference from which it will create the proper GraphQL resolver, input type for the Filter .","title":"Filter"},{"location":"filtering/#model-field-references","text":"For Filters corresponding to Django model fields, the Filter can be used without passing in a reference, as its attribute name in the FilterSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): title = Filter ( \"name\" )","title":"Model field references"},{"location":"filtering/#expression-references","text":"Django ORM expressions can also be used as the references. These create an alias in the queryset when the Filter is used. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_upper = Filter ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Filter , FilterSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): copies = Filter ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"filtering/#function-references","text":"Functions (or methods) can also be used to create Filters . This can be done by decorating a method with the Filter class. 1 2 3 4 5 6 7 8 9 10 11 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : return Q ( name__iexact = value ) The Filter method should return a Q expression. The type of the value argument is used as the input type for the Filter , so typing it is required. About method signature The decorated method is treated as a static method by the Filter . The self argument is not an instance of the FilterSet , but the instance of the Filter that is being used. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument is the value provided for the filter. It should always be named \"value\", and is required to be a keyword only argument.","title":"Function references"},{"location":"filtering/#lookup","text":"By default, when defining a Filter on a FilterSet , the \"exact\" lookup expression is used. This can be changed by providing the lookup argument to the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( lookup = \"icontains\" )","title":"Lookup"},{"location":"filtering/#many","text":"The many argument changes the behavior of the Filter such that it takes a list of values instead of a single value. Then, each of the values are combined as defined by the match argument to form a single filter condition. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" ) This would create the following filter input: 1 2 3 input TaskFilterSet { name : [ String !] } So if a query is filtered using this filter with the value [\"foo\", \"bar\"] , the filter condition would be Q(name__icontains=\"foo\") | Q(name__icontains=\"bar\") .","title":"Many"},{"location":"filtering/#match","text":"The match changes the behavior of the many argument to combine the provided values with a different operation. The default is any , which means that the filter condition will include an item if it matches any of the provided values. The match argument can be set to all if all of the values should match, or one_of if only one of the values should match. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( many = True , lookup = \"icontains\" , match = \"all\" )","title":"Match"},{"location":"filtering/#distinct","text":"If using some Filter would require a call to queryset.distinct() (e.g. lookups spanning \"to-many\" relations), you can use the distinct argument to tell the FilterSet for the Filter to do that if the Filter is used in a query. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( distinct = True )","title":"Distinct"},{"location":"filtering/#required","text":"By default, all Filter are not required (nullable in GraphQL terms). If you want to make a Filter required, you can do so by setting the required argument to True . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( required = True )","title":"Required"},{"location":"filtering/#aliases","text":"Sometimes a Filter may require additional expressions to be added as aliases to the queryset when the Filter is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import F , OuterRef , Q from undine import DjangoExpression , Filter , FilterSet , GQLInfo from undine.utils.model_utils import SubqueryCount from .models import Task class TaskFilterSet ( FilterSet [ Task ]): has_more_copies = Filter ( Q ( copies__gt = F ( \"non_copies\" ))) @has_more_copies . aliases def has_more_copies_aliases ( self , info : GQLInfo , * , value : bool ) -> dict [ str , DjangoExpression ]: return { \"copies\" : SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))), \"non_copies\" : SubqueryCount ( Task . objects . exclude ( name = OuterRef ( \"name\" ))), }","title":"Aliases"},{"location":"filtering/#empty-values","text":"By default, Filters will ignore some values which are considered \"empty\" in the context of filtering. These values are set globally by the EMPTY_VALUES setting. Usually this is what you want, as it allows you to set default values in our GraphQL variables. If you wish to change what's considered an empty value for an individual Filter , you can do so by setting the empty_values argument to a list of values. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): # Allow filtering with the empty string or None title = Filter ( empty_values = [])","title":"Empty values"},{"location":"filtering/#field-name","text":"A field_name can be provided to explicitly set the Django model field name that the Filter corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): field_name = Filter ( field_name = \"name\" )","title":"Field name"},{"location":"filtering/#schema-name_1","text":"A schema_name can be provided to override the name of the Filter in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Filter attribute name. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( schema_name = \"title\" )","title":"Schema name"},{"location":"filtering/#description_1","text":"By default, a Filter is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( description = \"Get only tasks with the given name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () \"\"\"Get only tasks with the given name.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : \"\"\"Get only tasks with the given name.\"\"\" return Q ( name__iexact = value )","title":"Description"},{"location":"filtering/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Filter as deprecated. This is for documentation purposes only, and does not affect the use of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"filtering/#empty-filter-result","text":"A special EmptyFilterResult exception can be raised from a Filter to indicate that the usage of the Filter should result in an empty queryset, e.g. because of the value given or for permission reasons. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet , GQLInfo from undine.exceptions import EmptyFilterResult from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> bool : if value == \"secret\" : raise EmptyFilterResult return True Raising this exceptions skips the rest of the Filter logic and results in an empty queryset.","title":"Empty filter result"},{"location":"filtering/#permissions","text":"You can add permissions check to individual Filters by using a custom function and adding the permission check inline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from django.db.models import Q from undine import Filter , FilterSet , GQLInfo from undine.exceptions import GraphQLPermissionError from .models import Task class TaskFilterSet ( FilterSet [ Task ]): @Filter def name ( self , info : GQLInfo , * , value : str ) -> Q : if not info . context . user . is_authenticated : msg = \"Only authenticated users can filter by task names.\" raise GraphQLPermissionError ( msg ) return Q ( name__icontains = value ) You can also raise the EmptyFilterResult exception if the usage of the filter should result in an empty queryset instead of an error.","title":"Permissions"},{"location":"filtering/#directives_1","text":"You can add directives to the Filter by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Filter , FilterSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( directives = [ MyDirective ()]) See the Directives section for more details on directives.","title":"Directives"},{"location":"filtering/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Filter from certain users by adding the visible argument to the Filter . Hiding a filter means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Filter , FilterSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"filtering/#graphql-extensions_1","text":"You can provide custom extensions for the Filter by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Filter . 1 2 3 4 5 6 7 from undine import Filter , FilterSet from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name = Filter ( extensions = { \"foo\" : \"bar\" }) Filter extensions are made available in the GraphQL InputField extensions after the schema is created. The Filter itself is found in the extensions under a key defined by the FILTER_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"getting-started/","text":"Getting Started \ud83d\udd17 New to GraphQL? \ud83d\udd17 It's recommended to read the official GraphQL docs first to get a better understanding of what GraphQL is and how it works, and use the GraphQL spec as a reference when necessary. New to Django? \ud83d\udd17 We recommend going though the official Django tutorial first before diving into Undine, since we'll assume you have some familiarity with Django. New to Undine? \ud83d\udd17 After going thought the installation steps below, we have a tutorial that will walk you through creating a simple GraphQL server using Undine. Undine is built on top of graphql-core , which is port of the GraphQL.js reference implementation of GraphQL. Knowing how graphql-core works can help you understand how Undine works, but is not required to get started. Installation \ud83d\udd17 Undine is available on PyPI and can be installed with pip : 1 pip install undine Next, you'll need to add Undine it to your INSTALLED_APPS setting in your Django project's settings.py file: 1 2 3 4 INSTALLED_APPS = [ # ... \"undine\" , ] To test that Undine is working, you can run the following command: 1 python manage.py check undine You should see the message \"System check identified no issues (0 silenced).\" Undine requires the \"django.contrib.contenttypes\" app to be installed, but there is no need to place \"undine\" in any specific order in the INSTALLED_APPS setting.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#new-to-graphql","text":"It's recommended to read the official GraphQL docs first to get a better understanding of what GraphQL is and how it works, and use the GraphQL spec as a reference when necessary.","title":"New to GraphQL?"},{"location":"getting-started/#new-to-django","text":"We recommend going though the official Django tutorial first before diving into Undine, since we'll assume you have some familiarity with Django.","title":"New to Django?"},{"location":"getting-started/#new-to-undine","text":"After going thought the installation steps below, we have a tutorial that will walk you through creating a simple GraphQL server using Undine. Undine is built on top of graphql-core , which is port of the GraphQL.js reference implementation of GraphQL. Knowing how graphql-core works can help you understand how Undine works, but is not required to get started.","title":"New to Undine?"},{"location":"getting-started/#installation","text":"Undine is available on PyPI and can be installed with pip : 1 pip install undine Next, you'll need to add Undine it to your INSTALLED_APPS setting in your Django project's settings.py file: 1 2 3 4 INSTALLED_APPS = [ # ... \"undine\" , ] To test that Undine is working, you can run the following command: 1 python manage.py check undine You should see the message \"System check identified no issues (0 silenced).\" Undine requires the \"django.contrib.contenttypes\" app to be installed, but there is no need to place \"undine\" in any specific order in the INSTALLED_APPS setting.","title":"Installation"},{"location":"global-object-ids/","text":"Global Object IDs \ud83d\udd17 In this section, we'll cover how to add support for object refetching and client caching using the Relay Global Object Identification specification. For Relay-compliant clients, see the Connection section for adding support for pagination with Connections . Node Interface \ud83d\udd17 Your QueryTypes can implement the Node interface to add support for Global Object IDs . 1 2 3 4 5 6 7 from undine import QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... This will add an id field to the TaskType for resolving Global Object IDs . 1 2 3 4 5 6 7 8 9 interface Node { id : ID ! } type TaskType implements Node { id : ID ! name : String ! # Rest of the fields... } Note that most Django models already contain an id field for as the primary key of the table, and that implementing this interface will override it with the Global Object ID field. To access the model id field, you can use the pk field instead. Node Entrypoint \ud83d\udd17 A Global Object ID can be used for refetching objects from a special Node Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , QueryType from undine.relay import Connection , Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... class Query ( QueryType ): node = Entrypoint ( Node ) tasks = Entrypoint ( Connection ( TaskType )) To use this Entrypoint , we must first query the schema in some other way, for example using the tasks Connection Entrypoint in the above example. Then, we can use the fetched Global Object ID to refetch the Task from the Node Entrypoint . 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType { name } } } Note that Global Object IDs (e.g. U3Vyc29yOnVzZXJuYW1lOjE= in the above example) are meant to be opaque to the client, meaning they aren't supposed to know what they contain or how to parse them.","title":"Global Object IDs"},{"location":"global-object-ids/#global-object-ids","text":"In this section, we'll cover how to add support for object refetching and client caching using the Relay Global Object Identification specification. For Relay-compliant clients, see the Connection section for adding support for pagination with Connections .","title":"Global Object IDs"},{"location":"global-object-ids/#node-interface","text":"Your QueryTypes can implement the Node interface to add support for Global Object IDs . 1 2 3 4 5 6 7 from undine import QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... This will add an id field to the TaskType for resolving Global Object IDs . 1 2 3 4 5 6 7 8 9 interface Node { id : ID ! } type TaskType implements Node { id : ID ! name : String ! # Rest of the fields... } Note that most Django models already contain an id field for as the primary key of the table, and that implementing this interface will override it with the Global Object ID field. To access the model id field, you can use the pk field instead.","title":"Node Interface"},{"location":"global-object-ids/#node-entrypoint","text":"A Global Object ID can be used for refetching objects from a special Node Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , QueryType from undine.relay import Connection , Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): ... class Query ( QueryType ): node = Entrypoint ( Node ) tasks = Entrypoint ( Connection ( TaskType )) To use this Entrypoint , we must first query the schema in some other way, for example using the tasks Connection Entrypoint in the above example. Then, we can use the fetched Global Object ID to refetch the Task from the Node Entrypoint . 1 2 3 4 5 6 7 8 query { node ( id : \"U3Vyc29yOnVzZXJuYW1lOjE=\" ) { id ... on TaskType { name } } } Note that Global Object IDs (e.g. U3Vyc29yOnVzZXJuYW1lOjE= in the above example) are meant to be opaque to the client, meaning they aren't supposed to know what they contain or how to parse them.","title":"Node Entrypoint"},{"location":"hacking-undine/","text":"Hacking Undine \ud83d\udd17 While Undine aims to offer a batteries-included solution for building GraphQL APIs on top of Django, it is designed to be easy to modify and extend to suit the needs of any project. For example, your project may include custom model fields, or require dates or times to be parsed in a specific way. Converters \ud83d\udd17 In this section, we will go through Undine's many converters, which are implemented using single-dispatch generic functions . A singe-dispatch generic function is a function that has different implementations based on the argument it receives. You can think of it as a dynamic switch statement. You may know the @singledispatch decorator from the python standard library, which implements this pattern. Undine implements its own version of it, which allows for more flexible dispatching. This pattern allows users to override and extend the behavior of any converter without having to modify Undine's code directly. The different converters available are listed below. convert_to_graphql_type \ud83d\udd17 This function is used to convert a value to a GraphQL input or output type. For example, a QueryType Field may be based on a model field, and so the Field needs to know which GraphQL type corresponds to the model's field. In addition to the value to convert, the function also accepts a model parameter, which is the Django model associated with the value, and a is_input parameter, which is a boolean indicating whether the converter should return an input or output type. convert_to_graphql_argument_map \ud83d\udd17 This function is used to convert a value to a GraphQL argument map. It's used by Fields and Entrypoints to figure out which parameters their GraphQL fields should have. For example, if a QueryType is used in a list Entrypoint , it should get its FilterSet and/or OrderSet as arguments. Similarly, a Connection should get its pagination arguments from this converter. In addition to the value to convert, the function also accepts a many parameter, which is a boolean indicating whether the converter should return a list of arguments or not, and a entrypoint parameter, which is a boolean indicating whether the converter is used in an Entrypoint or not. convert_lookup_to_graphql_type \ud83d\udd17 This function is used to convert a lookup expression to a GraphQL type. It's used in Filters to figure out the Filter's input type after the its lookup expression has been added. For example a __date lookup changes the expected input for a DateTimeField Filter from DateTime to Date . In addition to the lookup expression to convert, the function also accepts a default_type parameter, which is the GraphQLType for the parent field the lookup is for. convert_to_python_type \ud83d\udd17 This function is used to convert a value to a Python type. It has miscellaneous uses, for example in parsing model relation info, or in convert_lookup_to_graphql_type . In addition to the value to convert, the function also accepts a is_input parameter, which is a boolean indicating whether the converter should return an input or output type. convert_to_field_ref \ud83d\udd17 This function is used by Fields to handle their given reference. Most of the time, registering an implementation for this converter is only required to allow a new kind of Field reference to be used, but may also be used to add optimizations or convert the reference to a more general form (e.g. a string to a model field). In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. This allows the converter to access the Field's attributes however it sees fit. convert_to_input_ref \ud83d\udd17 This function is used by Inputs to handle their given reference. Otherwise, it works the same as convert_to_field_ref . convert_to_order_ref \ud83d\udd17 This function is used by Orders to handle their given reference. Otherwise, it works the same as convert_to_field_ref . convert_to_filter_ref \ud83d\udd17 This function is used by Filters to handle their given reference. Otherwise, it works the same as convert_to_field_ref . convert_to_field_resolver \ud83d\udd17 This function is used to convert a value to a GraphQL field resolver. It's used by Fields to figure out which resolver function should be used to resolve the field during a query. For example, related fields require a different resolver from a regular field. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. convert_to_entrypoint_resolver \ud83d\udd17 This function is the Entrypoint equivalent of the convert_to_field_resolver converter. A separate converter is needed since Entrypoints may resolve differently than Fields , or they can run the Optimizer. convert_to_filter_resolver \ud83d\udd17 This function is used to convert a value to a Filter expression resolver. This resolver receives the input of a Filter and returns a Django expression used for filtering. In addition to the value to convert, the function also accepts a caller parameter, which is the Filter instance that is calling this function. convert_to_description \ud83d\udd17 This function is used to convert a value to a GraphQL description. It's used by Fields , Inputs , Filters and Orders to figure out the description to use for their GraphQL types. For example, a the description for a model field is it's help_text attribute. convert_to_default_value \ud83d\udd17 This function is used to convert a value to a GraphQL default value. It's used by Inputs to figure out the default value for their GraphQL types. For example, a model field's default value is it's default attribute. However, a default value is only added to an Input for a create mutation. convert_to_bad_lookups \ud83d\udd17 This function is used to convert a given model field to a list of lookups that are not supported by the field, even if a lookup is registered for it. For example, if you check BooleanField.get_lookups() , it show many generic lookups registered for the base Field class, which don't actually work on a BooleanField (e.g. contains or iendswith ). This function is used to remove those lookups when auto-generating Filters for a FilterSet . convert_to_field_complexity \ud83d\udd17 This function is used to convert a Field reference to its complexity value. Field's complexity is used to limit the \"size\" of a query in order to prevent requesting too much data in a single request. For example, model relations have a complexity of 1, so that users do not query too many related objects in a single request. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. is_field_nullable \ud83d\udd17 This function is used by Fields to determine whether their reference is nullable or not. For example, a model field reference is nullable if it's null attribute is True . In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. is_input_hidden \ud83d\udd17 This function is used by Inputs to determine whether their reference indicates a hidden input, meaning an input that is not included in the schema. For example, a model field can be hidden if it's hidden attribute is True , for example for the reverse side of a ForeignKey that starts with a \"+\". In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_input_only \ud83d\udd17 This function is used by Inputs to determine whether their reference is only used for input, or also saved on the model instance that is the target of the mutation. For example, a non-model field is input-only since it doesn't get saved to the database. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_input_required \ud83d\udd17 This function is used by Inputs to determine whether their reference is required. For example, a model field is required depending on the mutation it is used in, if it has a default value, if it has null=True , etc. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function. is_many \ud83d\udd17 This function is used to determine whether a value indicates a list of objects or not. For example, a \"many-to-many\" field would return True . In addition to the value to convert, the function also accepts a model parameter, which is the Django model associated with the value, and a name parameter, which is a name associated with the value (e.g. field name). extend_expression \ud83d\udd17 This function is used to rewrite a Django expression as if it was referenced from a given model field. For example, an F expression F(\"name\") can be rewritten to extend from field_name as F(\"field_name__name\") , and similarly, a Q(name__exact=\"foo\") can be rewritten as Q(field_name__name__exact=\"foo\") . This is used by the optimizer to rewrite expressions from \"to-one\" fields to the fields if the related model can be fetched using select_related . In addition to the expression to convert, the function also accepts a field_name parameter, which is the name of the field to extend the expression from. Registering implementations \ud83d\udd17 To register new implementations for a converter, you need to decorate a function using the <converter>.register method. 1 2 3 4 5 6 7 8 9 10 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : type [ str ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString With this implementation registered fo the convert_to_graphql_type converter, calling convert_to_graphql_type(str) will return a GraphQLString object. However, calling convert_to_graphql_type(\"foo\") will not, since registration distinguishes between types and instances of types. A converter implementation should always accept **kwargs: Any , since those can be used to pass any additional arguments required by the converter. For example, the convert_to_graphql_type converter gets a model parameter, which indicates the Django model associated with the value. With this, we could register a different implementation for str that would return a GraphQL type based on the model field with the given name. 1 2 3 4 5 6 7 8 9 10 11 12 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type from undine.utils.model_utils import get_model_field @convert_to_graphql_type . register def _ ( ref : str , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : model_field = get_model_field ( model = kwargs [ \"model\" ], lookup = ref ) return convert_to_graphql_type ( model_field , ** kwargs ) If an implementation can be used for many different types, you can register it using a type union. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from django.db.models import CharField , TextField from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : CharField | TextField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString In a class hierarchy, you don't need to register implementations for all the subclasses, if the implementation of a superclass is can be used for the child class as well. Converters will automatically look up implementations based on the method resolution order of a class if an implementation is not found for the exact type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from typing import Any from django.db.models import BooleanField , NullBooleanField from graphql import GraphQLBoolean , GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : BooleanField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLBoolean # Uses the implementation for BooleanField, since NullBooleanField inherits from BooleanField. convert_to_graphql_type ( NullBooleanField ()) Literal types can also be used, in which case an implementation is registered for all the possible values of the literal type. When the converter is called with a value which can be a literal value, the converter will first check for any implementations for literals before checking for implementations for the type itself. 1 2 3 4 5 6 7 8 9 10 from typing import Any , Literal from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : Literal [ \"foo\" , \"bar\" ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If you need a different implementation for lambda functions as opposed to regular functions, you can register an implementation for the special Lambda type. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type from undine.typing import Lambda @convert_to_graphql_type . register def _ ( _ : Lambda , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString You can also register a default implementation for a converter using Any . Usually this is not needed and should be left for Undine to handle, since its likely you want an error to be raised by a converter for an unsupported type. Supporting new references \ud83d\udd17 Using the converters described above, we can extend the functionality of Undine objects to support new references by registering new implementations for specific converters. A new implementation might not be required for all converters if the new type is a subtype of some existing type, which already has a implementation that works for it. Fields \ud83d\udd17 Here are the converters that a new Field reference might need to implement: convert_to_field_ref to allow the new reference to be used in Fields . convert_to_field_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_field_complexity to know the complexity of resolving the field. convert_to_description to convert the reference to a description. is_field_nullable to know whether the reference is nullable or not. is_many to know whether the reference contains many objects or not. Inputs \ud83d\udd17 Here are the converters that a new Input reference might need to implement: convert_to_input_ref to allow the new reference to be used in Inputs . convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_default_value to determine the default value of the input. convert_to_description to convert the reference to a description. is_input_only to know whether the reference is only used for input or not. is_input_hidden to know whether the reference is hidden from the schema or not. is_input_required to know whether the reference is required or not. is_many to know whether the reference contains many objects or not. Filters \ud83d\udd17 Here are the converters that a new Filter reference might need to implement: convert_to_filter_ref to allow the new reference to be used in Filters . convert_to_filter_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_description to convert the reference to a description. Orders \ud83d\udd17 Here are the converters that a new Order reference might need to implement: convert_to_order_ref to allow the new reference to be used in Orders . convert_to_description to convert the reference to a description. Interfaces \ud83d\udd17 Here are the converters that a new InterfaceType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function. Unions \ud83d\udd17 Here are the converters that a new UnionType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Hacking Undine"},{"location":"hacking-undine/#hacking-undine","text":"While Undine aims to offer a batteries-included solution for building GraphQL APIs on top of Django, it is designed to be easy to modify and extend to suit the needs of any project. For example, your project may include custom model fields, or require dates or times to be parsed in a specific way.","title":"Hacking Undine"},{"location":"hacking-undine/#converters","text":"In this section, we will go through Undine's many converters, which are implemented using single-dispatch generic functions . A singe-dispatch generic function is a function that has different implementations based on the argument it receives. You can think of it as a dynamic switch statement. You may know the @singledispatch decorator from the python standard library, which implements this pattern. Undine implements its own version of it, which allows for more flexible dispatching. This pattern allows users to override and extend the behavior of any converter without having to modify Undine's code directly. The different converters available are listed below.","title":"Converters"},{"location":"hacking-undine/#convert_to_graphql_type","text":"This function is used to convert a value to a GraphQL input or output type. For example, a QueryType Field may be based on a model field, and so the Field needs to know which GraphQL type corresponds to the model's field. In addition to the value to convert, the function also accepts a model parameter, which is the Django model associated with the value, and a is_input parameter, which is a boolean indicating whether the converter should return an input or output type.","title":"convert_to_graphql_type"},{"location":"hacking-undine/#convert_to_graphql_argument_map","text":"This function is used to convert a value to a GraphQL argument map. It's used by Fields and Entrypoints to figure out which parameters their GraphQL fields should have. For example, if a QueryType is used in a list Entrypoint , it should get its FilterSet and/or OrderSet as arguments. Similarly, a Connection should get its pagination arguments from this converter. In addition to the value to convert, the function also accepts a many parameter, which is a boolean indicating whether the converter should return a list of arguments or not, and a entrypoint parameter, which is a boolean indicating whether the converter is used in an Entrypoint or not.","title":"convert_to_graphql_argument_map"},{"location":"hacking-undine/#convert_lookup_to_graphql_type","text":"This function is used to convert a lookup expression to a GraphQL type. It's used in Filters to figure out the Filter's input type after the its lookup expression has been added. For example a __date lookup changes the expected input for a DateTimeField Filter from DateTime to Date . In addition to the lookup expression to convert, the function also accepts a default_type parameter, which is the GraphQLType for the parent field the lookup is for.","title":"convert_lookup_to_graphql_type"},{"location":"hacking-undine/#convert_to_python_type","text":"This function is used to convert a value to a Python type. It has miscellaneous uses, for example in parsing model relation info, or in convert_lookup_to_graphql_type . In addition to the value to convert, the function also accepts a is_input parameter, which is a boolean indicating whether the converter should return an input or output type.","title":"convert_to_python_type"},{"location":"hacking-undine/#convert_to_field_ref","text":"This function is used by Fields to handle their given reference. Most of the time, registering an implementation for this converter is only required to allow a new kind of Field reference to be used, but may also be used to add optimizations or convert the reference to a more general form (e.g. a string to a model field). In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function. This allows the converter to access the Field's attributes however it sees fit.","title":"convert_to_field_ref"},{"location":"hacking-undine/#convert_to_input_ref","text":"This function is used by Inputs to handle their given reference. Otherwise, it works the same as convert_to_field_ref .","title":"convert_to_input_ref"},{"location":"hacking-undine/#convert_to_order_ref","text":"This function is used by Orders to handle their given reference. Otherwise, it works the same as convert_to_field_ref .","title":"convert_to_order_ref"},{"location":"hacking-undine/#convert_to_filter_ref","text":"This function is used by Filters to handle their given reference. Otherwise, it works the same as convert_to_field_ref .","title":"convert_to_filter_ref"},{"location":"hacking-undine/#convert_to_field_resolver","text":"This function is used to convert a value to a GraphQL field resolver. It's used by Fields to figure out which resolver function should be used to resolve the field during a query. For example, related fields require a different resolver from a regular field. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"convert_to_field_resolver"},{"location":"hacking-undine/#convert_to_entrypoint_resolver","text":"This function is the Entrypoint equivalent of the convert_to_field_resolver converter. A separate converter is needed since Entrypoints may resolve differently than Fields , or they can run the Optimizer.","title":"convert_to_entrypoint_resolver"},{"location":"hacking-undine/#convert_to_filter_resolver","text":"This function is used to convert a value to a Filter expression resolver. This resolver receives the input of a Filter and returns a Django expression used for filtering. In addition to the value to convert, the function also accepts a caller parameter, which is the Filter instance that is calling this function.","title":"convert_to_filter_resolver"},{"location":"hacking-undine/#convert_to_description","text":"This function is used to convert a value to a GraphQL description. It's used by Fields , Inputs , Filters and Orders to figure out the description to use for their GraphQL types. For example, a the description for a model field is it's help_text attribute.","title":"convert_to_description"},{"location":"hacking-undine/#convert_to_default_value","text":"This function is used to convert a value to a GraphQL default value. It's used by Inputs to figure out the default value for their GraphQL types. For example, a model field's default value is it's default attribute. However, a default value is only added to an Input for a create mutation.","title":"convert_to_default_value"},{"location":"hacking-undine/#convert_to_bad_lookups","text":"This function is used to convert a given model field to a list of lookups that are not supported by the field, even if a lookup is registered for it. For example, if you check BooleanField.get_lookups() , it show many generic lookups registered for the base Field class, which don't actually work on a BooleanField (e.g. contains or iendswith ). This function is used to remove those lookups when auto-generating Filters for a FilterSet .","title":"convert_to_bad_lookups"},{"location":"hacking-undine/#convert_to_field_complexity","text":"This function is used to convert a Field reference to its complexity value. Field's complexity is used to limit the \"size\" of a query in order to prevent requesting too much data in a single request. For example, model relations have a complexity of 1, so that users do not query too many related objects in a single request. In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"convert_to_field_complexity"},{"location":"hacking-undine/#is_field_nullable","text":"This function is used by Fields to determine whether their reference is nullable or not. For example, a model field reference is nullable if it's null attribute is True . In addition to the value to convert, the function also accepts a caller parameter, which is the Field instance that is calling this function.","title":"is_field_nullable"},{"location":"hacking-undine/#is_input_hidden","text":"This function is used by Inputs to determine whether their reference indicates a hidden input, meaning an input that is not included in the schema. For example, a model field can be hidden if it's hidden attribute is True , for example for the reverse side of a ForeignKey that starts with a \"+\". In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_hidden"},{"location":"hacking-undine/#is_input_only","text":"This function is used by Inputs to determine whether their reference is only used for input, or also saved on the model instance that is the target of the mutation. For example, a non-model field is input-only since it doesn't get saved to the database. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_only"},{"location":"hacking-undine/#is_input_required","text":"This function is used by Inputs to determine whether their reference is required. For example, a model field is required depending on the mutation it is used in, if it has a default value, if it has null=True , etc. In addition to the value to convert, the function also accepts a caller parameter, which is the Input instance that is calling this function.","title":"is_input_required"},{"location":"hacking-undine/#is_many","text":"This function is used to determine whether a value indicates a list of objects or not. For example, a \"many-to-many\" field would return True . In addition to the value to convert, the function also accepts a model parameter, which is the Django model associated with the value, and a name parameter, which is a name associated with the value (e.g. field name).","title":"is_many"},{"location":"hacking-undine/#extend_expression","text":"This function is used to rewrite a Django expression as if it was referenced from a given model field. For example, an F expression F(\"name\") can be rewritten to extend from field_name as F(\"field_name__name\") , and similarly, a Q(name__exact=\"foo\") can be rewritten as Q(field_name__name__exact=\"foo\") . This is used by the optimizer to rewrite expressions from \"to-one\" fields to the fields if the related model can be fetched using select_related . In addition to the expression to convert, the function also accepts a field_name parameter, which is the name of the field to extend the expression from.","title":"extend_expression"},{"location":"hacking-undine/#registering-implementations","text":"To register new implementations for a converter, you need to decorate a function using the <converter>.register method. 1 2 3 4 5 6 7 8 9 10 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : type [ str ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString With this implementation registered fo the convert_to_graphql_type converter, calling convert_to_graphql_type(str) will return a GraphQLString object. However, calling convert_to_graphql_type(\"foo\") will not, since registration distinguishes between types and instances of types. A converter implementation should always accept **kwargs: Any , since those can be used to pass any additional arguments required by the converter. For example, the convert_to_graphql_type converter gets a model parameter, which indicates the Django model associated with the value. With this, we could register a different implementation for str that would return a GraphQL type based on the model field with the given name. 1 2 3 4 5 6 7 8 9 10 11 12 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type from undine.utils.model_utils import get_model_field @convert_to_graphql_type . register def _ ( ref : str , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : model_field = get_model_field ( model = kwargs [ \"model\" ], lookup = ref ) return convert_to_graphql_type ( model_field , ** kwargs ) If an implementation can be used for many different types, you can register it using a type union. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from django.db.models import CharField , TextField from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : CharField | TextField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString In a class hierarchy, you don't need to register implementations for all the subclasses, if the implementation of a superclass is can be used for the child class as well. Converters will automatically look up implementations based on the method resolution order of a class if an implementation is not found for the exact type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from typing import Any from django.db.models import BooleanField , NullBooleanField from graphql import GraphQLBoolean , GraphQLInputType , GraphQLOutputType from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( ref : BooleanField , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLBoolean # Uses the implementation for BooleanField, since NullBooleanField inherits from BooleanField. convert_to_graphql_type ( NullBooleanField ()) Literal types can also be used, in which case an implementation is registered for all the possible values of the literal type. When the converter is called with a value which can be a literal value, the converter will first check for any implementations for literals before checking for implementations for the type itself. 1 2 3 4 5 6 7 8 9 10 from typing import Any , Literal from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type @convert_to_graphql_type . register def _ ( _ : Literal [ \"foo\" , \"bar\" ], ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString If you need a different implementation for lambda functions as opposed to regular functions, you can register an implementation for the special Lambda type. 1 2 3 4 5 6 7 8 9 10 11 from typing import Any from graphql import GraphQLInputType , GraphQLOutputType , GraphQLString from undine.converters import convert_to_graphql_type from undine.typing import Lambda @convert_to_graphql_type . register def _ ( _ : Lambda , ** kwargs : Any ) -> GraphQLInputType | GraphQLOutputType : return GraphQLString You can also register a default implementation for a converter using Any . Usually this is not needed and should be left for Undine to handle, since its likely you want an error to be raised by a converter for an unsupported type.","title":"Registering implementations"},{"location":"hacking-undine/#supporting-new-references","text":"Using the converters described above, we can extend the functionality of Undine objects to support new references by registering new implementations for specific converters. A new implementation might not be required for all converters if the new type is a subtype of some existing type, which already has a implementation that works for it.","title":"Supporting new references"},{"location":"hacking-undine/#fields","text":"Here are the converters that a new Field reference might need to implement: convert_to_field_ref to allow the new reference to be used in Fields . convert_to_field_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_field_complexity to know the complexity of resolving the field. convert_to_description to convert the reference to a description. is_field_nullable to know whether the reference is nullable or not. is_many to know whether the reference contains many objects or not.","title":"Fields"},{"location":"hacking-undine/#inputs","text":"Here are the converters that a new Input reference might need to implement: convert_to_input_ref to allow the new reference to be used in Inputs . convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_default_value to determine the default value of the input. convert_to_description to convert the reference to a description. is_input_only to know whether the reference is only used for input or not. is_input_hidden to know whether the reference is hidden from the schema or not. is_input_required to know whether the reference is required or not. is_many to know whether the reference contains many objects or not.","title":"Inputs"},{"location":"hacking-undine/#filters","text":"Here are the converters that a new Filter reference might need to implement: convert_to_filter_ref to allow the new reference to be used in Filters . convert_to_filter_resolver to convert the reference to a resolver function. convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_description to convert the reference to a description.","title":"Filters"},{"location":"hacking-undine/#orders","text":"Here are the converters that a new Order reference might need to implement: convert_to_order_ref to allow the new reference to be used in Orders . convert_to_description to convert the reference to a description.","title":"Orders"},{"location":"hacking-undine/#interfaces","text":"Here are the converters that a new InterfaceType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Interfaces"},{"location":"hacking-undine/#unions","text":"Here are the converters that a new UnionType reference might need to implement: convert_to_graphql_type to convert the reference to a GraphQL type. convert_to_graphql_argument_map to convert the reference to a GraphQL argument map. convert_to_entrypoint_resolver to convert the reference to a resolver function.","title":"Unions"},{"location":"integrations/","text":"Integrations \ud83d\udd17 In this section, we'll cover the integrations to other libraries that Undine includes. channels \ud83d\udd17 1 pip install undine[channels] Undine provides support for the GraphQL over WebSocket protocol by integrating with channels library. Using the channels integration requires turning on Undine's Async Support . Additionally, you need to configure the Django in asgi.py so that websocket requests are sent to Undine's channels consumer. 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_enabled_app application = get_websocket_enabled_app ( django_application ) This will add a new route to the Django application that will handle the WebSocket requests. The path for this route is defined using the WEBSOCKET_PATH setting. django-debug-toolbar \ud83d\udd17 1 pip install undine[debug] Undine integrates with django-debug-toolbar by modifying the debug toolbar so that it works with GraphiQL . After installing the debug toolbar , Undine should automatically patch the toolbar without any additional configuration. django-modeltranslation \ud83d\udd17 Undine integrates with django-modeltranslation by allowing you to modify how auto-generated Fields , Inputs , Filters and Orders are created. Specifically, this happens using two settings: MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS . Let's say you the following model and translation options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models from modeltranslation.decorators import register from modeltranslation.translator import TranslationOptions # In settings.py: # # MODELTRANSLATION_LANGUAGES = (\"en\", \"fi\") class Task ( models . Model ): name = models . CharField ( max_length = 255 ) # From modeltranslation name_en : str | None name_fi : str | None @register ( Task ) class TaskTranslationOptions ( TranslationOptions ): fields = [ \"name\" ] As noted in the example, due to the way that django-modeltranslation works, your models will get additional fields for each language you have defined. We'll call the fields for which the translations are created \"translatable\" fields, and the fields that are created for each language \"translation\" fields. Using the MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS settings, you can control which of these fields undine will add to your schema using auto-generation. By default, only the translation fields are added. You can of course always add the translatable fields manually. Note that due to the way that django-modeltranslation works, the translation fields are always nullable, even for the default language. pytest \ud83d\udd17 Undine comes with a pytest plugin that includes a testing client and few fixtures to help you write tests for your GraphQL APIs. The GraphQLClient class is wrapper around Django's test client that makes testing your GraphQL API easier. It can be added to a test using the graphql fixture. Here is a simple example: 1 2 3 4 5 6 def test_graphql ( graphql ) -> None : # Setup... query = \"query { test }\" response = graphql ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } GraphQL requests can be made by calling the client as shown above. This makes a request to the GraphQL endpoint set by the GRAPHQL_PATH setting. GraphQL variables can be passed using the variables argument. If these variables include any files, the client will automatically create a GraphQL multipart request instead of a normal GraphQL request. The client returns a custom response object GraphQLClientResponse , which has a number of useful properties for introspecting the response. The response object also has details on the database queries that were executed during the request, which can be useful for debugging the performance of your GraphQL API. An async version of the client is also available, which can be accessed from the graphql_async fixture. The plugin also includes a undine_settings fixture that allows modifying Undine's settings during testing more easily. If the channels integration is installed, the test client can also send GraphQL over WebSocket requests using the over_websocket method. 1 2 3 4 5 6 7 8 9 10 11 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_graphql ( graphql ) -> None : # Setup... query = \"query { test }\" async for response in graphql . over_websocket ( query ): assert response . data == { \"test\" : \"Hello, World!\" }","title":"Integrations"},{"location":"integrations/#integrations","text":"In this section, we'll cover the integrations to other libraries that Undine includes.","title":"Integrations"},{"location":"integrations/#channels","text":"1 pip install undine[channels] Undine provides support for the GraphQL over WebSocket protocol by integrating with channels library. Using the channels integration requires turning on Undine's Async Support . Additionally, you need to configure the Django in asgi.py so that websocket requests are sent to Undine's channels consumer. 1 2 3 4 5 6 7 8 9 10 11 import os from django.core.asgi import get_asgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"...\" ) django_application = get_asgi_application () # Needs be imported after 'django_application' is created! from undine.integrations.channels import get_websocket_enabled_app application = get_websocket_enabled_app ( django_application ) This will add a new route to the Django application that will handle the WebSocket requests. The path for this route is defined using the WEBSOCKET_PATH setting.","title":"channels"},{"location":"integrations/#django-debug-toolbar","text":"1 pip install undine[debug] Undine integrates with django-debug-toolbar by modifying the debug toolbar so that it works with GraphiQL . After installing the debug toolbar , Undine should automatically patch the toolbar without any additional configuration.","title":"django-debug-toolbar"},{"location":"integrations/#django-modeltranslation","text":"Undine integrates with django-modeltranslation by allowing you to modify how auto-generated Fields , Inputs , Filters and Orders are created. Specifically, this happens using two settings: MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS . Let's say you the following model and translation options: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models from modeltranslation.decorators import register from modeltranslation.translator import TranslationOptions # In settings.py: # # MODELTRANSLATION_LANGUAGES = (\"en\", \"fi\") class Task ( models . Model ): name = models . CharField ( max_length = 255 ) # From modeltranslation name_en : str | None name_fi : str | None @register ( Task ) class TaskTranslationOptions ( TranslationOptions ): fields = [ \"name\" ] As noted in the example, due to the way that django-modeltranslation works, your models will get additional fields for each language you have defined. We'll call the fields for which the translations are created \"translatable\" fields, and the fields that are created for each language \"translation\" fields. Using the MODELTRANSLATION_INCLUDE_TRANSLATABLE and MODELTRANSLATION_INCLUDE_TRANSLATIONS settings, you can control which of these fields undine will add to your schema using auto-generation. By default, only the translation fields are added. You can of course always add the translatable fields manually. Note that due to the way that django-modeltranslation works, the translation fields are always nullable, even for the default language.","title":"django-modeltranslation"},{"location":"integrations/#pytest","text":"Undine comes with a pytest plugin that includes a testing client and few fixtures to help you write tests for your GraphQL APIs. The GraphQLClient class is wrapper around Django's test client that makes testing your GraphQL API easier. It can be added to a test using the graphql fixture. Here is a simple example: 1 2 3 4 5 6 def test_graphql ( graphql ) -> None : # Setup... query = \"query { test }\" response = graphql ( query ) assert response . data == { \"hello\" : \"Hello, World!\" } GraphQL requests can be made by calling the client as shown above. This makes a request to the GraphQL endpoint set by the GRAPHQL_PATH setting. GraphQL variables can be passed using the variables argument. If these variables include any files, the client will automatically create a GraphQL multipart request instead of a normal GraphQL request. The client returns a custom response object GraphQLClientResponse , which has a number of useful properties for introspecting the response. The response object also has details on the database queries that were executed during the request, which can be useful for debugging the performance of your GraphQL API. An async version of the client is also available, which can be accessed from the graphql_async fixture. The plugin also includes a undine_settings fixture that allows modifying Undine's settings during testing more easily. If the channels integration is installed, the test client can also send GraphQL over WebSocket requests using the over_websocket method. 1 2 3 4 5 6 7 8 9 10 11 import pytest @pytest . mark . asyncio # Requires the `pytest-asyncio` plugin @pytest . mark . django_db ( transaction = True ) # For sessions async def test_graphql ( graphql ) -> None : # Setup... query = \"query { test }\" async for response in graphql . over_websocket ( query ): assert response . data == { \"test\" : \"Hello, World!\" }","title":"pytest"},{"location":"interfaces/","text":"Interfaces \ud83d\udd17 In this section, we'll cover how GraphQL Interfaces work in Undine. Interfaces are abstract GraphQL types that represent a group of fields that an ObjectType can implement. InterfaceType \ud83d\udd17 In Undine, a GraphQL Interface is implemented using the InterfaceType class and defining a number of InterfaceFields in its class body. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) QueryTypes can implement InterfaceTypes by adding them to the QueryType using the interfaces argument in their class definition. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... You can also use a decorator syntax to add an InterfaceType to a QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... InterfaceTypes can also implement other InterfaceTypes . 1 2 3 4 5 6 7 8 9 10 11 from graphql import GraphQLInt , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class Person ( InterfaceType , interfaces = [ Named ]): age = InterfaceField ( GraphQLNonNull ( GraphQLInt )) Usage in Entrypoints \ud83d\udd17 By default, an Entrypoint for an InterfaceType can be created that returns all implementations of the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 12 query { named { name ... on TaskType { createdAt } ... on StepType { done } __typename } } Filtering \ud83d\udd17 By default, the InterfaceType will return all instances of the QueryTypes that implement it. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the InterfaceType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , FilterSet , InterfaceField , InterfaceType , OrderSet , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], interfaces = [ Named ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class StepFilterSet ( FilterSet [ Step ]): ... class StepOrderSet ( OrderSet [ Step ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ], filterset = StepFilterSet , orderset = StepOrderSet ): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { named ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterStep : StepFilterSet orderByStep : [ StepOrderSet !] ): [ Named !]! } This allows filtering the different types of models in the InterfaceType separately. Pagination \ud83d\udd17 To paginate InterfaceTypes , you can use the Connection Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from undine.relay import Connection from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Connection ( Named )) See the Pagination section for more details on pagination. Schema name \ud83d\udd17 By default, the name of the generated Interface is the same as the name of the InterfaceType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , schema_name = \"HasName\" ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Description \ud83d\udd17 To provide a description for the InterfaceType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): \"\"\"Description.\"\"\" name = InterfaceField ( GraphQLNonNull ( GraphQLString )) GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the InterfaceType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceType . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , extensions = { \"foo\" : \"bar\" }): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) InterfaceType extensions are made available in the GraphQL Interface extensions after the schema is created. The InterfaceType itself is found in the extensions under a key defined by the INTERFACE_TYPE_EXTENSIONS_KEY setting. InterfaceField \ud83d\udd17 The Fields required by an interface are defined using InterfaceFields . Minimally, an InterfaceField requires the output type. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Optionally, you can define arguments that the InterfaceField requires. 1 2 3 4 5 6 7 8 9 10 from graphql import GraphQLArgument , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), args = { \"name\" : GraphQLArgument ( GraphQLNonNull ( GraphQLString ))}, ) Schema name \ud83d\udd17 A schema_name can be provided to override the name of the InterfaceField in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the InterfaceField attribute name. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), schema_name = \"name\" ) Description \ud83d\udd17 A description for a field can be provided in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), description = \"The name of the object.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) \"\"\"The name of the object.\"\"\" Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the InterfaceField as deprecated. This is for documentation purposes only, and does not affect the use of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use `title` instead.\" ) GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the InterfaceField by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) InterfaceField extensions are made available in the GraphQL InterfaceField extensions after the schema is created. The InterfaceField itself is found in the extensions under a key defined by the INTERFACE_FIELD_EXTENSIONS_KEY setting.","title":"Interfaces"},{"location":"interfaces/#interfaces","text":"In this section, we'll cover how GraphQL Interfaces work in Undine. Interfaces are abstract GraphQL types that represent a group of fields that an ObjectType can implement.","title":"Interfaces"},{"location":"interfaces/#interfacetype","text":"In Undine, a GraphQL Interface is implemented using the InterfaceType class and defining a number of InterfaceFields in its class body. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) QueryTypes can implement InterfaceTypes by adding them to the QueryType using the interfaces argument in their class definition. 1 2 3 4 5 6 7 8 9 10 11 12 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... You can also use a decorator syntax to add an InterfaceType to a QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType , QueryType from .models import Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) @Named class TaskType ( QueryType [ Task ]): ... InterfaceTypes can also implement other InterfaceTypes . 1 2 3 4 5 6 7 8 9 10 11 from graphql import GraphQLInt , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class Person ( InterfaceType , interfaces = [ Named ]): age = InterfaceField ( GraphQLNonNull ( GraphQLInt ))","title":"InterfaceType"},{"location":"interfaces/#usage-in-entrypoints","text":"By default, an Entrypoint for an InterfaceType can be created that returns all implementations of the InterfaceType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 12 query { named { name ... on TaskType { createdAt } ... on StepType { done } __typename } }","title":"Usage in Entrypoints"},{"location":"interfaces/#filtering","text":"By default, the InterfaceType will return all instances of the QueryTypes that implement it. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the InterfaceType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , FilterSet , InterfaceField , InterfaceType , OrderSet , QueryType , RootType from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], interfaces = [ Named ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class StepFilterSet ( FilterSet [ Step ]): ... class StepOrderSet ( OrderSet [ Step ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ], filterset = StepFilterSet , orderset = StepOrderSet ): ... class Query ( RootType ): named = Entrypoint ( Named , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { named ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterStep : StepFilterSet orderByStep : [ StepOrderSet !] ): [ Named !]! } This allows filtering the different types of models in the InterfaceType separately.","title":"Filtering"},{"location":"interfaces/#pagination","text":"To paginate InterfaceTypes , you can use the Connection Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from graphql import GraphQLNonNull , GraphQLString from undine import Entrypoint , InterfaceField , InterfaceType , QueryType , RootType from undine.relay import Connection from .models import Step , Task class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) class TaskType ( QueryType [ Task ], interfaces = [ Named ]): ... class StepType ( QueryType [ Step ], interfaces = [ Named ]): ... class Query ( RootType ): named = Entrypoint ( Connection ( Named )) See the Pagination section for more details on pagination.","title":"Pagination"},{"location":"interfaces/#schema-name","text":"By default, the name of the generated Interface is the same as the name of the InterfaceType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , schema_name = \"HasName\" ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ))","title":"Schema name"},{"location":"interfaces/#description","text":"To provide a description for the InterfaceType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): \"\"\"Description.\"\"\" name = InterfaceField ( GraphQLNonNull ( GraphQLString ))","title":"Description"},{"location":"interfaces/#graphql-extensions","text":"You can provide custom extensions for the InterfaceType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceType . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType , extensions = { \"foo\" : \"bar\" }): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) InterfaceType extensions are made available in the GraphQL Interface extensions after the schema is created. The InterfaceType itself is found in the extensions under a key defined by the INTERFACE_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"interfaces/#interfacefield","text":"The Fields required by an interface are defined using InterfaceFields . Minimally, an InterfaceField requires the output type. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) Optionally, you can define arguments that the InterfaceField requires. 1 2 3 4 5 6 7 8 9 10 from graphql import GraphQLArgument , GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), args = { \"name\" : GraphQLArgument ( GraphQLNonNull ( GraphQLString ))}, )","title":"InterfaceField"},{"location":"interfaces/#schema-name_1","text":"A schema_name can be provided to override the name of the InterfaceField in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the InterfaceField attribute name. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), schema_name = \"name\" )","title":"Schema name"},{"location":"interfaces/#description_1","text":"A description for a field can be provided in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), description = \"The name of the object.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString )) \"\"\"The name of the object.\"\"\"","title":"Description"},{"location":"interfaces/#deprecation-reason","text":"A deprecation_reason can be provided to mark the InterfaceField as deprecated. This is for documentation purposes only, and does not affect the use of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), deprecation_reason = \"Use `title` instead.\" )","title":"Deprecation reason"},{"location":"interfaces/#graphql-extensions_1","text":"You can provide custom extensions for the InterfaceField by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the InterfaceField . 1 2 3 4 5 6 7 from graphql import GraphQLNonNull , GraphQLString from undine import InterfaceField , InterfaceType class Named ( InterfaceType ): name = InterfaceField ( GraphQLNonNull ( GraphQLString ), extensions = { \"foo\" : \"bar\" }) InterfaceField extensions are made available in the GraphQL InterfaceField extensions after the schema is created. The InterfaceField itself is found in the extensions under a key defined by the INTERFACE_FIELD_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"lifecycle-hooks/","text":"Lifecycle Hooks \ud83d\udd17 In this section, we'll cover Undine's lifecycle hooks, which allow you to hook into the execution of a GraphQL request. LifecycleHook \ud83d\udd17 A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation. LifecycleHooks allow you to hook into the these steps to run custom logic before or after each of these steps, or before and after the whole operation. Here is a basic example of a LifecycleHook . 1 2 3 4 5 6 7 8 9 10 from collections.abc import Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): def run ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) To implement a hook, you need to create a class that inherits from LifecycleHook and implement the run method. run should be a generator function that yields once, marking the point in which the hook should run. Anything before the yield statement will be executed before the hooking point, and anything after the yield statement will be executed after the hooking point. You can add this hook the different steps using settings: 1 2 3 4 5 6 UNDINE = { \"PARSE_HOOKS\" : [ \"path.to.ExampleHook\" ], \"VALIDATION_HOOKS\" : [ \"path.to.ExampleHook\" ], \"EXECUTION_HOOKS\" : [ \"path.to.ExampleHook\" ], \"OPERATION_HOOKS\" : [ \"path.to.ExampleHook\" ], } When multiple hooks are registered for the same hooking point, they will be run in the order they are registered. This means that the first hook registered will have its \"before\" portion run first and its \"after\" portion run last. You can think of them as a stack of context managers. Lifecycle hooks can have a different implementation in async context using the run_async method. If no async implementation is provided, the synchronous version will be used. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): def run ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) async def run_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) Async hooks are also used for subscriptions . LifecycleHookContext \ud83d\udd17 Each hook is passed a LifecycleHookContext object ( self.context ), which contains information about the current state of the GraphQL request. This includes: source : Source GraphQL document string. document : Parsed GraphQL document AST. Available after parsing is complete. variables : Variables passed to the GraphQL operation. operation_name : The name of the GraphQL operation. extensions : GraphQL operation extensions received from the client. request : Django request during which the GraphQL request is being executed. result : Execution result of the GraphQL operation. Examples \ud83d\udd17 Here's some more complex examples of possible lifecycle hooks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from collections.abc import Generator from graphql import ExecutionResult , GraphQLError from undine.hooks import LifecycleHook class ErrorEnrichmentHook ( LifecycleHook ): \"\"\"Catch errors and enrich them with status codes and error codes.\"\"\" def run ( self ) -> Generator [ None , None , None ]: try : yield # Catch all exceptions raised in the hooking point and turn them into ExecutionResults. except Exception as err : msg = str ( err ) extensions = { \"status_code\" : 500 , \"error_code\" : \"INTERNAL_SERVER_ERROR\" } new_error = GraphQLError ( msg , extensions = extensions ) self . context . result = ExecutionResult ( errors = [ new_error ]) return if self . context . result is None or self . context . result . errors is None : return # Enrich errors with status codes and error codes. for error in self . context . result . errors : if error . extensions is None : error . extensions = {} error . extensions . setdefault ( \"status_code\" , 400 ) error . extensions . setdefault ( \"error_code\" , \"INTERNAL_SERVER_ERROR\" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import json from collections.abc import Generator from django.core.cache import cache from graphql import ExecutionResult from undine.hooks import LifecycleHook class CachingHook ( LifecycleHook ): \"\"\"Cache execution results.\"\"\" TIMEOUT = 60 def run ( self ) -> Generator [ None , None , None ]: cache_key = f \" { self . context . source } : { json . dumps ( self . context . variables ) } \" was_cached = False # Check if the result is already cached. if cache_key in cache : data = cache . get ( cache_key ) was_cached = True # Setting results early will cause the hooking point to not run # and the graphql execution to exit early with this result. self . context . result = ExecutionResult ( data = data ) yield # If results where cached, the hooking point will not run, but the # hook's \"after\" portion will. Therefore, don't re-cache the result # if it was already cached. if was_cached : return if self . context . result is not None and self . context . result . data is not None : cache . set ( cache_key , self . context . result . data , timeout = self . TIMEOUT )","title":"Lifecycle Hooks"},{"location":"lifecycle-hooks/#lifecycle-hooks","text":"In this section, we'll cover Undine's lifecycle hooks, which allow you to hook into the execution of a GraphQL request.","title":"Lifecycle Hooks"},{"location":"lifecycle-hooks/#lifecyclehook","text":"A GraphQL operation is executed in a series of steps. These steps are: Parsing the GraphQL source document to a GraphQL AST. Validation of the GraphQL AST against the GraphQL schema. Execution of the GraphQL operation. LifecycleHooks allow you to hook into the these steps to run custom logic before or after each of these steps, or before and after the whole operation. Here is a basic example of a LifecycleHook . 1 2 3 4 5 6 7 8 9 10 from collections.abc import Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): def run ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) To implement a hook, you need to create a class that inherits from LifecycleHook and implement the run method. run should be a generator function that yields once, marking the point in which the hook should run. Anything before the yield statement will be executed before the hooking point, and anything after the yield statement will be executed after the hooking point. You can add this hook the different steps using settings: 1 2 3 4 5 6 UNDINE = { \"PARSE_HOOKS\" : [ \"path.to.ExampleHook\" ], \"VALIDATION_HOOKS\" : [ \"path.to.ExampleHook\" ], \"EXECUTION_HOOKS\" : [ \"path.to.ExampleHook\" ], \"OPERATION_HOOKS\" : [ \"path.to.ExampleHook\" ], } When multiple hooks are registered for the same hooking point, they will be run in the order they are registered. This means that the first hook registered will have its \"before\" portion run first and its \"after\" portion run last. You can think of them as a stack of context managers. Lifecycle hooks can have a different implementation in async context using the run_async method. If no async implementation is provided, the synchronous version will be used. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from collections.abc import AsyncGenerator , Generator from undine.hooks import LifecycleHook class ExampleHook ( LifecycleHook ): def run ( self ) -> Generator [ None , None , None ]: print ( \"before\" ) yield print ( \"after\" ) async def run_async ( self ) -> AsyncGenerator [ None , None ]: print ( \"before async\" ) yield print ( \"after async\" ) Async hooks are also used for subscriptions .","title":"LifecycleHook"},{"location":"lifecycle-hooks/#lifecyclehookcontext","text":"Each hook is passed a LifecycleHookContext object ( self.context ), which contains information about the current state of the GraphQL request. This includes: source : Source GraphQL document string. document : Parsed GraphQL document AST. Available after parsing is complete. variables : Variables passed to the GraphQL operation. operation_name : The name of the GraphQL operation. extensions : GraphQL operation extensions received from the client. request : Django request during which the GraphQL request is being executed. result : Execution result of the GraphQL operation.","title":"LifecycleHookContext"},{"location":"lifecycle-hooks/#examples","text":"Here's some more complex examples of possible lifecycle hooks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from collections.abc import Generator from graphql import ExecutionResult , GraphQLError from undine.hooks import LifecycleHook class ErrorEnrichmentHook ( LifecycleHook ): \"\"\"Catch errors and enrich them with status codes and error codes.\"\"\" def run ( self ) -> Generator [ None , None , None ]: try : yield # Catch all exceptions raised in the hooking point and turn them into ExecutionResults. except Exception as err : msg = str ( err ) extensions = { \"status_code\" : 500 , \"error_code\" : \"INTERNAL_SERVER_ERROR\" } new_error = GraphQLError ( msg , extensions = extensions ) self . context . result = ExecutionResult ( errors = [ new_error ]) return if self . context . result is None or self . context . result . errors is None : return # Enrich errors with status codes and error codes. for error in self . context . result . errors : if error . extensions is None : error . extensions = {} error . extensions . setdefault ( \"status_code\" , 400 ) error . extensions . setdefault ( \"error_code\" , \"INTERNAL_SERVER_ERROR\" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import json from collections.abc import Generator from django.core.cache import cache from graphql import ExecutionResult from undine.hooks import LifecycleHook class CachingHook ( LifecycleHook ): \"\"\"Cache execution results.\"\"\" TIMEOUT = 60 def run ( self ) -> Generator [ None , None , None ]: cache_key = f \" { self . context . source } : { json . dumps ( self . context . variables ) } \" was_cached = False # Check if the result is already cached. if cache_key in cache : data = cache . get ( cache_key ) was_cached = True # Setting results early will cause the hooking point to not run # and the graphql execution to exit early with this result. self . context . result = ExecutionResult ( data = data ) yield # If results where cached, the hooking point will not run, but the # hook's \"after\" portion will. Therefore, don't re-cache the result # if it was already cached. if was_cached : return if self . context . result is not None and self . context . result . data is not None : cache . set ( cache_key , self . context . result . data , timeout = self . TIMEOUT )","title":"Examples"},{"location":"mutations/","text":"Mutations \ud83d\udd17 In this section, we'll cover Undine's MutationTypes which allow you to expose your Django models through the GraphQL schema for mutations, expanding on the basics introduced in the Tutorial . If you to mutate data outside of your Django models, see the Function References section in the Schema documentation. MutationTypes \ud83d\udd17 A MutationType represents a GraphQL InputObjectType for mutating a Django model in the GraphQL schema. A basic MutationType is created by subclassing MutationType and adding a Django model to it as a generic type parameter: 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () done = Input () Mutation kind \ud83d\udd17 MutationType can be used for create , update , delete as well as custom mutations. The kind of mutation a certain MutationType is for is determined by its kind , which can be set in the MutationType class definition. This allows Undine link the correct mutation resolver to the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () kind can also be omitted, in which case the MutationType will determine the mutation kind using these rules: If the word create can be found in the name of the MutationType , kind will be create . If the word update can be found in the name of the MutationType , kind will be update . If the word delete can be found in the name of the MutationType , kind will be delete . If either the __mutate__ or __bulk_mutate__ method has been defined on the MutationType , kind will be custom (see custom mutations ). Otherwise, an error will be raised. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task # Create mutation, since has \"create\" in the name. class TaskCreateMutation ( MutationType [ Task ]): name = Input () Auto-generation \ud83d\udd17 A MutationType can automatically introspect its Django model and convert the model's fields to Inputs on the MutationType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL InputObjectType for a MutationType for a create mutation using auto-generation would be: 1 2 3 4 5 input TaskCreateMutation { name : String ! done : Boolean ! = true # `createdAt` not included since it has `auto_now_add=True` } For an update mutation, the pk field is included for selecting the mutation target, the rest of the fields are all made nullable (=not required), and no default values are added. 1 2 3 4 5 input TaskUpdateMutation { pk : Int ! name : String done : Boolean } For a delete mutation, only the pk field is included for selecting the mutation target. 1 2 3 input TaskDeleteMutation { pk : Int ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the MutationType class definition. With this, you can leave the MutationType class body empty. 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True , exclude = [ \"name\" ]): ... Output type \ud83d\udd17 A MutationType requires a QueryType for the same model to exist in the schema, since the MutationType will use the ObjectType generated from the QueryType as the output type of the mutation. You don't need to explicitly link the QueryType to the MutationType since MutationType will automatically look up the QueryType for the same model from the QueryType registry . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would generate the following mutation in the GraphQL schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } input TaskCreateMutation { name : String ! done : Boolean ! = false } type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } If you wanted to link the QueryType explicitly, you could do so by overriding the __query_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , Input , MutationType , QueryType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __query_type__ ( cls ) -> type [ QueryType ]: return TaskType Permissions \ud83d\udd17 You can add mutation-level permission checks for a MutationType by defining the __permissions__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can create tasks.\" raise GraphQLPermissionError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model, without any of the input_data values applied. This also means that it doesn't have a primary key yet. For update and delete mutations, the instance is the instance that is being mutated, with the input_data values applied. This method will be called for each instance of Task that is mutated by this MutationType . For bulk mutations, this means that the method will be called for each item in the mutation input data. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Validation \ud83d\udd17 You can add mutation-level validation for a MutationType by defining the __validate__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if len ( input_data [ \"name\" ]) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model, without any of the input_data values applied. This also means that it doesn't have a primary key yet. For update and delete mutations, the instance is the instance that is being mutated, with the input_data values applied. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module. After mutation handling \ud83d\udd17 You can add custom handling that happens after the mutation is done by defining the __after__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : pass # Some post-mutation handling here About method signature For create and update mutations, the instance is the instance that was either created or updated, with the input_data values applied. input_data contains the input data for the mutation. For delete mutations, the instance is the instance that was deleted. This means that its relations have been disconnected, and its primary key has been set to None . This can be useful for doing things like sending emails. Custom mutations \ud83d\udd17 You can define your own custom logic by defining the __mutate__ or __bulk_mutate__ method on the MutationType class for single or bulk mutations respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance In the above example, the MutationType is still considered a create kind of mutation, just with some custom mutation logic. The MutationType kind still affects auto-generation , which resolvers are used, as well as some inference rules for its Inputs . You can also use a special custom mutation kind when using custom resolvers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"custom\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance This affects the creation of the MutationType in the following ways: Auto-generation is not used, even if it is enabled No Input is input-only by default These MutationTypes will otherwise resolve like create or update mutations, depending on if an Input named pk is present in the MutationType . By default, the output type of a custom mutation is still the ObjectType from the QueryType matching the MutationType's model. If your custom mutation returns an instance of that model, it will work without additional changes. However, if you want to return a different type, you can do so by overriding the __output_type__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields ) Related mutations \ud83d\udd17 Let's say you have the following models: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) If you wanted to create both a Task and its related Project in a single mutation, you could link two mutation types using a special related kind of MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProject ) This creates the following InputObjectTypes : 1 2 3 4 5 6 7 8 9 10 input TaskProject { pk : Int name : String } input TaskCreateMutation { name : String ! done : Boolean ! = false project : TaskProject ! } Auto-generation and inference rules for related MutationTypes are the same as for update MutationTypes , except the pk field is also not required. This allows you to create, update, link, or unlink new or existing related models during the mutation as you see fit. Let's give a few examples. Assuming you added the TaskCreateMutation to the schema with an Entrypoint create_task , you can create a new Task together with a new Project like this: 1 2 3 4 5 6 7 8 9 10 11 12 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { pk } } Or you can link an existing Project to a new Task like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { pk name } } Or you can link an existing project while modifying it: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Updated project\" } } ) { pk name } } Permission an validation checks are run for related MutationTypes and their Inputs as well, although existing instances are not fetched from the database even if the input contains its primary key. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo , input_data : dict [ str , Any ]) -> None : # Some permission check logic here return class TaskCreateMutation ( MutationType [ Task ]): name = Input () project = Input ( TaskProject ) Note that if the Input connecting the related MutationType defines a permission or validation check, that check is run instead of the related MutationType permission or validation check. Related mutation action \ud83d\udd17 When updating an instance and its relations using a related mutation, that instance may already have existing related objects. For some relations, it's clear what should happen to relations that are not selected in the related mutation. Forward one-to-one relation : Selects the new related object to attach to, or set the relation to null. Reverse one-to-one relation can always be missing. Forward foreign key (many-to-one) relation : Selects the new related object to attach to, or set the relation to null. Reverse relations do not have any constraints. Many-to-many relations : Selects the new related objects that the current instance should be linked to. Non-selected objects are unlinked, meaning through table rows are deleted. For other relations, you might need different behavior depending on the situation: Reverse one-to-one relation : You might want to delete the exiting related object, or set the relation to null (although the forward part of the relation might not be nullable). Reverse foreign key (one-to-many) relation : You might want to delete exiting related objects, or set their relation to null (although the forward part of the relation might not be nullable). You might even want to leave the existing relations as they are. The action that should be taken for the relations is defined by the MutationType related_action argument. The actions are as follows: null : Set the relaton to null. If the relation is not nullable, an error is raised. Default action. delete : Delete the related objects. ignore : Leave the existing relations as they are. For one-to-one relations, an error is raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Input , MutationType from .models import Project , Task class ProjectTask ( MutationType [ Task ], kind = \"related\" ): pk = Input () name = Input () class ProjectUpdateMutation ( MutationType [ Project ], related_action = \"delete\" ): pk = Input () name = Input () done = Input () tasks = Input ( ProjectTask ) Note that this action applies to all related mutations executed from the \"parent\" MutationType . If you need more granular control, you should make the mutation a custom mutation instead. Order of operations \ud83d\udd17 The order of operations for executing a mutation using a MutationType is as follows: MutationType permissions and Input permissions are checked MutationType validation and Input validation are run Mutation is executed MutationType after handling is run If GraphQLErrors are raised during steps 1 and 2, the validation and permission checks continue until step 3, and then all exceptions are raised at once. The error's path will point to the Input where the exception was raised. Example result with multiple errors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"name\" ] }, { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"done\" ] } ] } Schema name \ud83d\udd17 By default, the name of the generated InputObjectType is the same as the name of the MutationType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], schema_name = \"CreateTask\" ): name = Input () Description \ud83d\udd17 To provide a description for the MutationType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): \"\"\"Description.\"\"\" name = Input () Directives \ud83d\udd17 You can add directives to the MutationType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ], directives = [ MyDirective ()]): name = Input () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a MutationType from certain users by adding the visible argument to the MutationType . Hiding a mutation type means that it will not be included in introspection queries for that user, and entrypoints using that mutation type cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the MutationType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Input () MutationType extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The MutationType itself is found in the extensions under a key defined by the MUTATION_TYPE_EXTENSIONS_KEY setting. Inputs \ud83d\udd17 An Input is a class that is used to define a possible input for a MutationType . Usually Inputs correspond to fields on the Django model for their respective MutationType . In GraphQL, an Input represents a GraphQLInputField in an InputObjectType . An Input always requires a reference from which it will create the proper input type and default value for the Input . Model field references \ud83d\udd17 For Inputs corresponding to Django model fields, the Input can be used without passing in a reference, as its attribute name in the MutationType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( Task . name ) Function references \ud83d\udd17 Functions (or methods) can also be used to create Inputs . This can be done by decorating a method with the Input class. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : return value . upper () About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument can be left out: 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def current_user ( self , info : GQLInfo ) -> int | None : return info . context . user . id This makes the Input hidden in the GraphQL schema since it takes no user input. Also, since current_user is not a field on the Task model, the Input is also input_only . Model references \ud83d\udd17 Models classes can also be used as Input references. In this case, the model will be fetched to the input data before permission and validation checks. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Project , Task class TaskCreateMutation ( MutationType [ Task ]): project = Input ( Project ) The model doesn't necessarily need to be a related model of the parent MutationType model, but if it is not, the input will be an input-only input by default. Otherwise, if the model instance is not found, the input will raise an error before any other checks are run. Permissions \ud83d\udd17 You can restrict the use of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can set task names.\" raise GraphQLPermissionError ( msg ) About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. This method will be called for each instance of Task that is mutated by this MutationType . For bulk mutations, this means that the method will be called for each item in the mutation input data. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module. Validation \ud83d\udd17 You can validate the value of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.validate decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module. Conversion \ud83d\udd17 Normally, values for Inputs are parsed and converted based on the Input's Scalar . However, you can add additional convertion for an individual Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.convert decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . convert def convert_name ( self , value : str ) -> str : return value . upper () About method signature The self argument is not an instance of the MutationType , but the Input whose value is being coerced. The value argument is the value provided for the Input . Note that conversion functions are also run for default values . Default values \ud83d\udd17 By default, an Input is able to determine its default value based on its reference. For example, for a model field, the default value is taken from its default attribute. However, default values are only added automatically for create mutations, as update mutations should only update fields that have been provided. If you want to set the default value for an Input manually, you can set the default_value argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( default_value = \"New task\" ) Note that the default value needs to be a valid GraphQL default value (i.e. a string, integer, float, boolean, or null, or a list or dictionary of these). Input-only inputs \ud83d\udd17 Input-only Inputs show up in the GraphQL schema, but are not part of the actual mutation, usually because they are not part of the model being mutated. They can be used as additional data for validation and permissions checks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): logging_enabled = Input ( bool , input_only = True ) @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data . get ( \"logging_enabled\" ): print ( \"Logging enabled\" ) Notice that the Input reference is bool . This is to indicate the input type, as there is no model field to infer the type from. For the same reason, you don't actually need to specify the input_only argument. Hidden inputs \ud83d\udd17 Hidden Inputs are not included in the GraphQL schema, but their values are added before the mutation is executed. They can be used, for example, to set default values for fields that should not be overridden by users. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( hidden = True , default_value = \"New task\" ) One common use case for hidden inputs is to set the current user as the default value for a relational field. Let's suppose that the Task model has a foreign key user to the User model. To assign a new task to the current user during creation, you can define a hidden input for the user field: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.contrib.auth.models import User from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def user ( self , info : GQLInfo ) -> User | None : if info . context . user . is_anonymous : return None return info . context . user See Function References for more details. Required inputs \ud83d\udd17 By default, an Input is able to determine whether it is required or not based on is reference, as well as the kind of MutationType it is used in. If you want to override this, you can set the required argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( required = True ) Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django model field name that the Input corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): title = Input ( field_name = \"name\" ) Schema name \ud83d\udd17 An Input is also able to override the name of the Input in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Input attribute name. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( schema_name = \"title\" ) Descriptions \ud83d\udd17 By default, an Input is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : \"\"\"Name of the task.\"\"\" return value . upper () Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Input Input This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the Input by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input ( directives = [ MyDirective ()]) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Input from certain users by adding the visible argument to the Input . Hiding an input means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Input by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( extensions = { \"foo\" : \"bar\" }) Input extensions are made available in the GraphQL InputField extensions after the schema is created. The Input itself is found in the extensions under a key defined by the INPUT_EXTENSIONS_KEY setting.","title":"Mutations"},{"location":"mutations/#mutations","text":"In this section, we'll cover Undine's MutationTypes which allow you to expose your Django models through the GraphQL schema for mutations, expanding on the basics introduced in the Tutorial . If you to mutate data outside of your Django models, see the Function References section in the Schema documentation.","title":"Mutations"},{"location":"mutations/#mutationtypes","text":"A MutationType represents a GraphQL InputObjectType for mutating a Django model in the GraphQL schema. A basic MutationType is created by subclassing MutationType and adding a Django model to it as a generic type parameter: 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () done = Input ()","title":"MutationTypes"},{"location":"mutations/#mutation-kind","text":"MutationType can be used for create , update , delete as well as custom mutations. The kind of mutation a certain MutationType is for is determined by its kind , which can be set in the MutationType class definition. This allows Undine link the correct mutation resolver to the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () kind can also be omitted, in which case the MutationType will determine the mutation kind using these rules: If the word create can be found in the name of the MutationType , kind will be create . If the word update can be found in the name of the MutationType , kind will be update . If the word delete can be found in the name of the MutationType , kind will be delete . If either the __mutate__ or __bulk_mutate__ method has been defined on the MutationType , kind will be custom (see custom mutations ). Otherwise, an error will be raised. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task # Create mutation, since has \"create\" in the name. class TaskCreateMutation ( MutationType [ Task ]): name = Input ()","title":"Mutation kind"},{"location":"mutations/#auto-generation","text":"A MutationType can automatically introspect its Django model and convert the model's fields to Inputs on the MutationType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL InputObjectType for a MutationType for a create mutation using auto-generation would be: 1 2 3 4 5 input TaskCreateMutation { name : String ! done : Boolean ! = true # `createdAt` not included since it has `auto_now_add=True` } For an update mutation, the pk field is included for selecting the mutation target, the rest of the fields are all made nullable (=not required), and no default values are added. 1 2 3 4 5 input TaskUpdateMutation { pk : Int ! name : String done : Boolean } For a delete mutation, only the pk field is included for selecting the mutation target. 1 2 3 input TaskDeleteMutation { pk : Int ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the MutationType class definition. With this, you can leave the MutationType class body empty. 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], auto = True , exclude = [ \"name\" ]): ...","title":"Auto-generation"},{"location":"mutations/#output-type","text":"A MutationType requires a QueryType for the same model to exist in the schema, since the MutationType will use the ObjectType generated from the QueryType as the output type of the mutation. You don't need to explicitly link the QueryType to the MutationType since MutationType will automatically look up the QueryType for the same model from the QueryType registry . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would generate the following mutation in the GraphQL schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } input TaskCreateMutation { name : String ! done : Boolean ! = false } type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } If you wanted to link the QueryType explicitly, you could do so by overriding the __query_type__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , Input , MutationType , QueryType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __query_type__ ( cls ) -> type [ QueryType ]: return TaskType","title":"Output type"},{"location":"mutations/#permissions","text":"You can add mutation-level permission checks for a MutationType by defining the __permissions__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can create tasks.\" raise GraphQLPermissionError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model, without any of the input_data values applied. This also means that it doesn't have a primary key yet. For update and delete mutations, the instance is the instance that is being mutated, with the input_data values applied. This method will be called for each instance of Task that is mutated by this MutationType . For bulk mutations, this means that the method will be called for each item in the mutation input data. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module.","title":"Permissions"},{"location":"mutations/#validation","text":"You can add mutation-level validation for a MutationType by defining the __validate__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from typing import Any from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if len ( input_data [ \"name\" ]) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature For create mutations, the instance is a brand new instance of the model, without any of the input_data values applied. This also means that it doesn't have a primary key yet. For update and delete mutations, the instance is the instance that is being mutated, with the input_data values applied. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module.","title":"Validation"},{"location":"mutations/#after-mutation-handling","text":"You can add custom handling that happens after the mutation is done by defining the __after__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __after__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : pass # Some post-mutation handling here About method signature For create and update mutations, the instance is the instance that was either created or updated, with the input_data values applied. input_data contains the input data for the mutation. For delete mutations, the instance is the instance that was deleted. This means that its relations have been disconnected, and its primary key has been set to None . This can be useful for doing things like sending emails.","title":"After mutation handling"},{"location":"mutations/#custom-mutations","text":"You can define your own custom logic by defining the __mutate__ or __bulk_mutate__ method on the MutationType class for single or bulk mutations respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance In the above example, the MutationType is still considered a create kind of mutation, just with some custom mutation logic. The MutationType kind still affects auto-generation , which resolvers are used, as well as some inference rules for its Inputs . You can also use a special custom mutation kind when using custom resolvers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskMutation ( MutationType [ Task ], kind = \"custom\" ): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> Task : # Some custom mutation logic here return instance This affects the creation of the MutationType in the following ways: Auto-generation is not used, even if it is enabled No Input is input-only by default These MutationTypes will otherwise resolve like create or update mutations, depending on if an Input named pk is present in the MutationType . By default, the output type of a custom mutation is still the ObjectType from the QueryType matching the MutationType's model. If your custom mutation returns an instance of that model, it will work without additional changes. However, if you want to return a different type, you can do so by overriding the __output_type__ classmethod on the MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from typing import Any from graphql import GraphQLField , GraphQLInt , GraphQLNonNull , GraphQLObjectType from undine import GQLInfo , Input , MutationType from undine.utils.graphql.type_registry import get_or_create_graphql_object_type from .models import Task class TaskMutation ( MutationType [ Task ]): name = Input () @classmethod def __mutate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> dict [ str , Any ]: return { \"foo\" : 1 } @classmethod def __output_type__ ( cls ) -> GraphQLObjectType : fields = { \"foo\" : GraphQLField ( GraphQLNonNull ( GraphQLInt ))} return get_or_create_graphql_object_type ( name = \"TaskMutationOutput\" , fields = fields )","title":"Custom mutations"},{"location":"mutations/#related-mutations","text":"Let's say you have the following models: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE , related_name = \"tasks\" ) If you wanted to create both a Task and its related Project in a single mutation, you could link two mutation types using a special related kind of MutationType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProject ) This creates the following InputObjectTypes : 1 2 3 4 5 6 7 8 9 10 input TaskProject { pk : Int name : String } input TaskCreateMutation { name : String ! done : Boolean ! = false project : TaskProject ! } Auto-generation and inference rules for related MutationTypes are the same as for update MutationTypes , except the pk field is also not required. This allows you to create, update, link, or unlink new or existing related models during the mutation as you see fit. Let's give a few examples. Assuming you added the TaskCreateMutation to the schema with an Entrypoint create_task , you can create a new Task together with a new Project like this: 1 2 3 4 5 6 7 8 9 10 11 12 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { pk } } Or you can link an existing Project to a new Task like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { pk name } } Or you can link an existing project while modifying it: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Updated project\" } } ) { pk name } } Permission an validation checks are run for related MutationTypes and their Inputs as well, although existing instances are not fetched from the database even if the input contains its primary key. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Project , Task class TaskProject ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo , input_data : dict [ str , Any ]) -> None : # Some permission check logic here return class TaskCreateMutation ( MutationType [ Task ]): name = Input () project = Input ( TaskProject ) Note that if the Input connecting the related MutationType defines a permission or validation check, that check is run instead of the related MutationType permission or validation check.","title":"Related mutations"},{"location":"mutations/#related-mutation-action","text":"When updating an instance and its relations using a related mutation, that instance may already have existing related objects. For some relations, it's clear what should happen to relations that are not selected in the related mutation. Forward one-to-one relation : Selects the new related object to attach to, or set the relation to null. Reverse one-to-one relation can always be missing. Forward foreign key (many-to-one) relation : Selects the new related object to attach to, or set the relation to null. Reverse relations do not have any constraints. Many-to-many relations : Selects the new related objects that the current instance should be linked to. Non-selected objects are unlinked, meaning through table rows are deleted. For other relations, you might need different behavior depending on the situation: Reverse one-to-one relation : You might want to delete the exiting related object, or set the relation to null (although the forward part of the relation might not be nullable). Reverse foreign key (one-to-many) relation : You might want to delete exiting related objects, or set their relation to null (although the forward part of the relation might not be nullable). You might even want to leave the existing relations as they are. The action that should be taken for the relations is defined by the MutationType related_action argument. The actions are as follows: null : Set the relaton to null. If the relation is not nullable, an error is raised. Default action. delete : Delete the related objects. ignore : Leave the existing relations as they are. For one-to-one relations, an error is raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Input , MutationType from .models import Project , Task class ProjectTask ( MutationType [ Task ], kind = \"related\" ): pk = Input () name = Input () class ProjectUpdateMutation ( MutationType [ Project ], related_action = \"delete\" ): pk = Input () name = Input () done = Input () tasks = Input ( ProjectTask ) Note that this action applies to all related mutations executed from the \"parent\" MutationType . If you need more granular control, you should make the mutation a custom mutation instead.","title":"Related mutation action"},{"location":"mutations/#order-of-operations","text":"The order of operations for executing a mutation using a MutationType is as follows: MutationType permissions and Input permissions are checked MutationType validation and Input validation are run Mutation is executed MutationType after handling is run If GraphQLErrors are raised during steps 1 and 2, the validation and permission checks continue until step 3, and then all exceptions are raised at once. The error's path will point to the Input where the exception was raised. Example result with multiple errors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"name\" ] }, { \"message\" : \"Validation error.\" , \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" }, \"path\" : [ \"createTask\" , \"done\" ] } ] }","title":"Order of operations"},{"location":"mutations/#schema-name","text":"By default, the name of the generated InputObjectType is the same as the name of the MutationType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], schema_name = \"CreateTask\" ): name = Input ()","title":"Schema name"},{"location":"mutations/#description","text":"To provide a description for the MutationType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): \"\"\"Description.\"\"\" name = Input ()","title":"Description"},{"location":"mutations/#directives","text":"You can add directives to the MutationType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ], directives = [ MyDirective ()]): name = Input () See the Directives section for more details on directives.","title":"Directives"},{"location":"mutations/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a MutationType from certain users by adding the visible argument to the MutationType . Hiding a mutation type means that it will not be included in introspection queries for that user, and entrypoints using that mutation type cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"mutations/#graphql-extensions","text":"You can provide custom extensions for the MutationType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the MutationType . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Input () MutationType extensions are made available in the GraphQL InputObjectType extensions after the schema is created. The MutationType itself is found in the extensions under a key defined by the MUTATION_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"mutations/#inputs","text":"An Input is a class that is used to define a possible input for a MutationType . Usually Inputs correspond to fields on the Django model for their respective MutationType . In GraphQL, an Input represents a GraphQLInputField in an InputObjectType . An Input always requires a reference from which it will create the proper input type and default value for the Input .","title":"Inputs"},{"location":"mutations/#model-field-references","text":"For Inputs corresponding to Django model fields, the Input can be used without passing in a reference, as its attribute name in the MutationType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( Task . name )","title":"Model field references"},{"location":"mutations/#function-references","text":"Functions (or methods) can also be used to create Inputs . This can be done by decorating a method with the Input class. 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : return value . upper () About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. The value argument can be left out: 1 2 3 4 5 6 7 8 9 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def current_user ( self , info : GQLInfo ) -> int | None : return info . context . user . id This makes the Input hidden in the GraphQL schema since it takes no user input. Also, since current_user is not a field on the Task model, the Input is also input_only .","title":"Function references"},{"location":"mutations/#model-references","text":"Models classes can also be used as Input references. In this case, the model will be fetched to the input data before permission and validation checks. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Project , Task class TaskCreateMutation ( MutationType [ Task ]): project = Input ( Project ) The model doesn't necessarily need to be a related model of the parent MutationType model, but if it is not, the input will be an input-only input by default. Otherwise, if the model instance is not found, the input will raise an error before any other checks are run.","title":"Model references"},{"location":"mutations/#permissions_1","text":"You can restrict the use of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can set task names.\" raise GraphQLPermissionError ( msg ) About method signature The decorated method is treated as a static method by the Input . The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. This method will be called for each instance of Task that is mutated by this MutationType . For bulk mutations, this means that the method will be called for each item in the mutation input data. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLPermissionError from the undine.exceptions module.","title":"Permissions"},{"location":"mutations/#validation_1","text":"You can validate the value of an Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.validate decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters long.\" raise GraphQLValidationError ( msg ) About method signature The self argument is not an instance of the MutationType , but the model instance that is being mutated. The info argument is the GraphQL resolve info for the request. The value argument is the value provided for the input. You can raise any GraphQLError when validation fails, but it's recommended to raise a GraphQLValidationError from the undine.exceptions module.","title":"Validation"},{"location":"mutations/#conversion","text":"Normally, values for Inputs are parsed and converted based on the Input's Scalar . However, you can add additional convertion for an individual Input by first defining the Input in the class body of the MutationType and then adding a method with the @<input_name>.convert decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . convert def convert_name ( self , value : str ) -> str : return value . upper () About method signature The self argument is not an instance of the MutationType , but the Input whose value is being coerced. The value argument is the value provided for the Input . Note that conversion functions are also run for default values .","title":"Conversion"},{"location":"mutations/#default-values","text":"By default, an Input is able to determine its default value based on its reference. For example, for a model field, the default value is taken from its default attribute. However, default values are only added automatically for create mutations, as update mutations should only update fields that have been provided. If you want to set the default value for an Input manually, you can set the default_value argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( default_value = \"New task\" ) Note that the default value needs to be a valid GraphQL default value (i.e. a string, integer, float, boolean, or null, or a list or dictionary of these).","title":"Default values"},{"location":"mutations/#input-only-inputs","text":"Input-only Inputs show up in the GraphQL schema, but are not part of the actual mutation, usually because they are not part of the model being mutated. They can be used as additional data for validation and permissions checks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): logging_enabled = Input ( bool , input_only = True ) @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data . get ( \"logging_enabled\" ): print ( \"Logging enabled\" ) Notice that the Input reference is bool . This is to indicate the input type, as there is no model field to infer the type from. For the same reason, you don't actually need to specify the input_only argument.","title":"Input-only inputs"},{"location":"mutations/#hidden-inputs","text":"Hidden Inputs are not included in the GraphQL schema, but their values are added before the mutation is executed. They can be used, for example, to set default values for fields that should not be overridden by users. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( hidden = True , default_value = \"New task\" ) One common use case for hidden inputs is to set the current user as the default value for a relational field. Let's suppose that the Task model has a foreign key user to the User model. To assign a new task to the current user during creation, you can define a hidden input for the user field: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.contrib.auth.models import User from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def user ( self , info : GQLInfo ) -> User | None : if info . context . user . is_anonymous : return None return info . context . user See Function References for more details.","title":"Hidden inputs"},{"location":"mutations/#required-inputs","text":"By default, an Input is able to determine whether it is required or not based on is reference, as well as the kind of MutationType it is used in. If you want to override this, you can set the required argument on the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( required = True )","title":"Required inputs"},{"location":"mutations/#field-name","text":"A field_name can be provided to explicitly set the Django model field name that the Input corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): title = Input ( field_name = \"name\" )","title":"Field name"},{"location":"mutations/#schema-name_1","text":"An Input is also able to override the name of the Input in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Input attribute name. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( schema_name = \"title\" )","title":"Schema name"},{"location":"mutations/#descriptions","text":"By default, an Input is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 from undine import GQLInfo , Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @Input def name ( self , info : GQLInfo , value : str ) -> str : \"\"\"Name of the task.\"\"\" return value . upper ()","title":"Descriptions"},{"location":"mutations/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Input Input This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"mutations/#directives_1","text":"You can add directives to the Input by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Input , MutationType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . INPUT_FIELD_DEFINITION ]): ... class TaskCreateMutation ( MutationType [ Task ]): name = Input ( directives = [ MyDirective ()]) See the Directives section for more details on directives.","title":"Directives"},{"location":"mutations/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Input from certain users by adding the visible argument to the Input . Hiding an input means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Input , MutationType from undine.typing import DjangoRequestProtocol from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"mutations/#graphql-extensions_1","text":"You can provide custom extensions for the Input by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Input . 1 2 3 4 5 6 7 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input ( extensions = { \"foo\" : \"bar\" }) Input extensions are made available in the GraphQL InputField extensions after the schema is created. The Input itself is found in the extensions under a key defined by the INPUT_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"optimizer/","text":"Optimizer \ud83d\udd17 This section covers Undine's query optimizer, which is responsible for optimizing queries to your GraphQL schema in order to reduce the amount of database queries that are made when resolving a request. The Problems \ud83d\udd17 Before we take a look at how the optimizer works, let's first understand why it exists by going over some common problems that arise when using GraphQL to fetch data from a relational database. The N+1 Problem \ud83d\udd17 Let's say you have a collection of models like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) description = models . TextField () project = models . ForeignKey ( Project , on_delete = models . CASCADE ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE ) And a schema like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type ProjectType { pk : Int ! name : String ! } type StepType { pk : Int ! name : String ! done : Boolean ! } type TaskType { pk : Int ! name : String ! description : String ! project : ProjectType ! steps : [ StepType !]! } type Query { tasks : [ TaskType !]! } Now, let's say you query tasks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name description project { pk name } steps { pk name done } } } In GraphQL, each field in the query will be resolved separately, and most importantly, if a field returns a list of objects with subfields, the resolvers for those subfields will be called for each object in the list. Normally, a field's resolver knows nothing about the query it is in, and so it only fetches the data it needs. In this case, the top level resolver for tasks will fetch all Task objects, but won't make any joins to related models its subfields might need. For example, when the subfield for the related Project resolves, that resolver will try to look up the Project from the root Task instance it received, but since the Project was not fetched along with the Task , it needs to make another query to the database. This means that for the whole query we first fetch all Tasks , and then all Projects and Steps for each Task . If we had 100 Tasks , each of which is linked to a Project , but also to 10 Steps . In total this would result in 201 queries to the database! It's important to notice that the amount of queries is proportional to the amount of Tasks in the database. You can imagine how this can get out of hand quickly, especially when you start nesting relations deeper and deeper. Each additional level of nesting will grow the number of queries exponentially! That's why it's called the N+1 problem : 1 query for the root object, and N queries for all subfields, where N is the amount of root objects. Over-fetching \ud83d\udd17 Another issue with resolving Django models using normal resolvers is that when a model is fetched from the database, all of its non-relational fields are also fetched by default. This means that we'll fetch fields that are not needed in the query. This can be expensive if the model has many fields or fields that contain a lot of data. This is called over-fetching , in contrast to the N+1 problem, which is a problem of under-fetching . The Optimizer \ud83d\udd17 Undine includes an optimizer that fixes the above problems automatically by introspecting the incoming query and generating the appropriate QuerySet optimizations like prefetch_related and select_related calls. It plugs into the top-level resolvers in the schema, so in the above example, the resolver for the tasks entrypoint, and makes the necessary optimizations to reduce the amount of database queries made. This way all subfields can resolve normally, knowing that the data they need is already fetched. For the most part, this is all you need to know about the optimizer. However, there are a few things you need to know to not break these optimizations. Be careful when overriding Field resolvers. If you define a custom resolver for model field which uses model data outside of the field itself, those fields may not have been fetched if they are not also part of the query. More generally, you need to be careful when using models outside of the GraphQL context. A common place where this may happen is in permission checks, which often need to access model data for object permissions, etc. To deal with this, Undine includes methods to specify additional optimizations manually, see the Manual Optimizations section below. Manual Optimizations \ud83d\udd17 Undine includes two hooks for adding additional manual optimizations your schema. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) data . add_select_related ( \"project\" , query_type = ProjectType ) data . add_prefetch_related ( \"steps\" , query_type = StepType ) class StepType ( QueryType [ Step ]): ... The QueryType.__optimizations__ method is called by the optimizer when it encounters a new QueryType during optimizations. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) class StepType ( QueryType [ Step ]): ... The <field_name>.optimize method is called by the optimizer when it encounters a new Field during optimizations. See optimization data on how to add the optimizations. Optimization data \ud83d\udd17 The OptimizationData object holds the optimizations that the optimizer has gathered from the query. You can add new optimizations to the data to ensure that, e.g., required fields are fetched, even if they are otherwise not needed in the query. Let's go over the structure of the OptimizationData object. model \ud83d\udd17 This is the model class which the optimizations in the data correspond to. info \ud83d\udd17 The resolver info object for the request, as it applies for this OptimizationData . During field resolving, the field_name , field_nodes , return_type and parent_type of the resolver info object are different depending on the ObjectType being resolved, so each OptimizationData needs to know how the resolver info would look when its optimizations are needed. Various methods in Undine get passed this info object so that users of the library can use it do their own introspections. related_field \ud83d\udd17 The model field being optimized. Can be None if the OptimizationData is for the root-level. parent \ud83d\udd17 If the OptimizationData is for a related model, this links to the optimization data of the parent model. Conversely, the parent OptimizationData has a link this OptimizationData using either select_related , prefetch_related or generic_prefetches . only_fields \ud83d\udd17 Contains fields that will be applied to QuerySet.only() . This prevents the over-fetching issue by only fetching the required fields for the query. aliases \ud83d\udd17 Contains the expressions that will be applied to QuerySet.alias() . Various methods in Undine can add to these aliases to enable more clearer use of for annotations . annotations \ud83d\udd17 Contains the expressions that will be applied to QuerySet.annotate() . Fields that resolve using an expression will store the expression here. select_related \ud83d\udd17 Contains OptimizationData for related fields that should be fetched together using QuerySet.select_related() . New related fields should be added using add_select_related to ensure that the correct references are places in both OptimizationData . prefetch_related \ud83d\udd17 Contains OptimizationData for related fields that should be fetched together using QuerySet.prefetch_related() . New related fields should be added using add_prefetch_related to ensure that the correct references are places in both OptimizationData . Note that the key in the mapping can be either the name of the related field, or an alias that the data should be fetched with (using Prefetch(..., to_attr=<alias>) ). generic_prefetches \ud83d\udd17 Contains OptimizationData for generic foreign keys that should be fetched together using QuerySet.prefetch_related() . New generic prefetches should be added using add_generic_prefetch_related to ensure that the correct references are places in both OptimizationData . filters \ud83d\udd17 Contains Q expressions that will be applied to QuerySet.filter() . Normally, these are compiled from a FilterSet . order_by \ud83d\udd17 Contains OrderBy expressions that will be applied to QuerySet.order_by() . Normally, these are compiled from an OrderSet . distinct \ud83d\udd17 Whether QuerySet.distinct() should be applied. Normally, the optimizer is able to determine this based on the FilterSet Filters used in the query. none \ud83d\udd17 Whether QuerySet.none() should be applied. Note that using QuerySet.none() will result in an empty QuerySet regardless of other optimizations. Normally, this is only applied if a FilterSet Filter raises an EmptyFilterResult exception. pagination \ud83d\udd17 Contains the pagination information for the QuerySet in the form of a PaginationHandler object. Normally, this is set by the optimizer automatically based on if the field uses a Connection or not. queryset_callback \ud83d\udd17 A callback function that initializes the QuerySet for the OptimizationData . By default, this is set to use the Manager.get_queryset() method of the OptimizationData's model's default manager, or the QueryType.__get_queryset__ method for related fields to other QueryTypes . pre_filter_callback \ud83d\udd17 A callback function that will be called before order_by , distinct , filters , or field_calculations are applied to the QuerySet . Normally, this is populated using the QueryType.__filter_queryset__ method, if it has been overridden from the default. post_filter_callback \ud83d\udd17 A callback function that will be called after order_by , distinct , filters , and field_calculations are applied to the QuerySet . Normally, this is populated using the FilterSet.__filter_queryset__ method, if it has been overridden from the default. field_calculations \ud83d\udd17 A list of Calculation instances that should be run and annotated to the QuerySet . Normally, the optimizer will automatically add Fields using Calculation objects to this list. add_select_related() \ud83d\udd17 A method for adding a new select_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created select_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. add_prefetch_related() \ud83d\udd17 A method for adding a new prefetch_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use, as well as a to_attr for the prefetch alias. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. The string passed in to_attr will be used in Prefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch \"to-many\" relations to aliases of custom schema names. add_generic_prefetch_related() \ud83d\udd17 A method for adding a new generic_prefetch_related optimization. Must provide the field_name for the model relation, the related_model that the generic prefetch should be done for, and optionally a QueryType that the relation should use, and to_attr for the prefetch alias. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created generic_prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. The string passed in to_attr will be used in GenericPrefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch \"to-many\" relations to aliases of custom schema names. Optimization results \ud83d\udd17 Once the whole query has been analyzed, the OptimizationData is processed to OptimizationResults , which can then be applied to the QuerySet . OptimizationData processing simply copies over most of the data from the OptimizationData , but notably, it also converts any select_related , prefetch_related , or generic_prefetch_related optimizations to values that can be applied to a QuerySet . For select_related , this means either promotion to a prefetch , or extending the related field's optimizations to the parent model (e.g. querying the name of a Project related to a Task will extend the name lookups to the Task model: project__name , and add it to the Task model's OptimizationResults.only_fields ). For prefetch_related , the prefetch OptimizationResults are processed and applied to the queryset from taken from OptimizationResults.queryset_callback . The resulting Prefetch() object is added to the parent OptimizationResults.prefetch_related . generic_prefetch_related is processed similarly to prefetch_related , expect a GenericPrefetch() object is created instead. Promotion to prefetch \ud83d\udd17 In certain cases, a select_related optimization must be promoted to a prefetch_related . This can happen for one of the following reasons: Any annotations (or aliases ) are requested from the relation. A prefetch must be made so that the annotation remains available in the related object. Any field_calculations are present. Calculation will become annotations, so the reason is the same as above. A pre_filter_callback or post_filter_callback is needed. Since these callbacks might filter out the related object, a prefetch must be done to ensure this. Note that this might result in a null value for a field that would otherwise not be null! Order of optimizations \ud83d\udd17 The order in which the optimizations are applied is as follows: If none is True , return an empty QuerySet and exit early. If select_related is not empty, apply select_related optimizations using QuerySet.select_related() . If prefetch_related is not empty, apply prefetch_related optimizations using QuerySet.prefetch_related() . If only_fields is not empty, and apply the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is not False, only_fields optimizations using QuerySet.only() . If aliases is not empty, apply aliases optimizations using QuerySet.alias() . If annotations is not empty, apply annotations optimizations using QuerySet.annotate() . If pre_filter_callback exists, call it. If order_by is not empty, apply order_by optimizations using QuerySet.order_by() . If distinct is True , apply QuerySet.distinct() . If field_calculations is not empty, run the Calculation and annotate the result to the QuerySet using the Calculation's __field_name__ . If filters is not empty, apply filters optimizations using QuerySet.filter() If post_filter_callback exists, call it. If pagination is not empty, run either pagination.paginate_queryset() or pagination.paginate_prefetch_queryset() depending on whether a related_field exists or not. Return the optimized QuerySet .","title":"Optimizer"},{"location":"optimizer/#optimizer","text":"This section covers Undine's query optimizer, which is responsible for optimizing queries to your GraphQL schema in order to reduce the amount of database queries that are made when resolving a request.","title":"Optimizer"},{"location":"optimizer/#the-problems","text":"Before we take a look at how the optimizer works, let's first understand why it exists by going over some common problems that arise when using GraphQL to fetch data from a relational database.","title":"The Problems"},{"location":"optimizer/#the-n1-problem","text":"Let's say you have a collection of models like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) description = models . TextField () project = models . ForeignKey ( Project , on_delete = models . CASCADE ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE ) And a schema like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type ProjectType { pk : Int ! name : String ! } type StepType { pk : Int ! name : String ! done : Boolean ! } type TaskType { pk : Int ! name : String ! description : String ! project : ProjectType ! steps : [ StepType !]! } type Query { tasks : [ TaskType !]! } Now, let's say you query tasks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name description project { pk name } steps { pk name done } } } In GraphQL, each field in the query will be resolved separately, and most importantly, if a field returns a list of objects with subfields, the resolvers for those subfields will be called for each object in the list. Normally, a field's resolver knows nothing about the query it is in, and so it only fetches the data it needs. In this case, the top level resolver for tasks will fetch all Task objects, but won't make any joins to related models its subfields might need. For example, when the subfield for the related Project resolves, that resolver will try to look up the Project from the root Task instance it received, but since the Project was not fetched along with the Task , it needs to make another query to the database. This means that for the whole query we first fetch all Tasks , and then all Projects and Steps for each Task . If we had 100 Tasks , each of which is linked to a Project , but also to 10 Steps . In total this would result in 201 queries to the database! It's important to notice that the amount of queries is proportional to the amount of Tasks in the database. You can imagine how this can get out of hand quickly, especially when you start nesting relations deeper and deeper. Each additional level of nesting will grow the number of queries exponentially! That's why it's called the N+1 problem : 1 query for the root object, and N queries for all subfields, where N is the amount of root objects.","title":"The N+1 Problem"},{"location":"optimizer/#over-fetching","text":"Another issue with resolving Django models using normal resolvers is that when a model is fetched from the database, all of its non-relational fields are also fetched by default. This means that we'll fetch fields that are not needed in the query. This can be expensive if the model has many fields or fields that contain a lot of data. This is called over-fetching , in contrast to the N+1 problem, which is a problem of under-fetching .","title":"Over-fetching"},{"location":"optimizer/#the-optimizer","text":"Undine includes an optimizer that fixes the above problems automatically by introspecting the incoming query and generating the appropriate QuerySet optimizations like prefetch_related and select_related calls. It plugs into the top-level resolvers in the schema, so in the above example, the resolver for the tasks entrypoint, and makes the necessary optimizations to reduce the amount of database queries made. This way all subfields can resolve normally, knowing that the data they need is already fetched. For the most part, this is all you need to know about the optimizer. However, there are a few things you need to know to not break these optimizations. Be careful when overriding Field resolvers. If you define a custom resolver for model field which uses model data outside of the field itself, those fields may not have been fetched if they are not also part of the query. More generally, you need to be careful when using models outside of the GraphQL context. A common place where this may happen is in permission checks, which often need to access model data for object permissions, etc. To deal with this, Undine includes methods to specify additional optimizations manually, see the Manual Optimizations section below.","title":"The Optimizer"},{"location":"optimizer/#manual-optimizations","text":"Undine includes two hooks for adding additional manual optimizations your schema. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) data . add_select_related ( \"project\" , query_type = ProjectType ) data . add_prefetch_related ( \"steps\" , query_type = StepType ) class StepType ( QueryType [ Step ]): ... The QueryType.__optimizations__ method is called by the optimizer when it encounters a new QueryType during optimizations. See optimization data on how to add the optimizations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): ... class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : data . only_fields . add ( \"name\" ) class StepType ( QueryType [ Step ]): ... The <field_name>.optimize method is called by the optimizer when it encounters a new Field during optimizations. See optimization data on how to add the optimizations.","title":"Manual Optimizations"},{"location":"optimizer/#optimization-data","text":"The OptimizationData object holds the optimizations that the optimizer has gathered from the query. You can add new optimizations to the data to ensure that, e.g., required fields are fetched, even if they are otherwise not needed in the query. Let's go over the structure of the OptimizationData object.","title":"Optimization data"},{"location":"optimizer/#model","text":"This is the model class which the optimizations in the data correspond to.","title":"model"},{"location":"optimizer/#info","text":"The resolver info object for the request, as it applies for this OptimizationData . During field resolving, the field_name , field_nodes , return_type and parent_type of the resolver info object are different depending on the ObjectType being resolved, so each OptimizationData needs to know how the resolver info would look when its optimizations are needed. Various methods in Undine get passed this info object so that users of the library can use it do their own introspections.","title":"info"},{"location":"optimizer/#related_field","text":"The model field being optimized. Can be None if the OptimizationData is for the root-level.","title":"related_field"},{"location":"optimizer/#parent","text":"If the OptimizationData is for a related model, this links to the optimization data of the parent model. Conversely, the parent OptimizationData has a link this OptimizationData using either select_related , prefetch_related or generic_prefetches .","title":"parent"},{"location":"optimizer/#only_fields","text":"Contains fields that will be applied to QuerySet.only() . This prevents the over-fetching issue by only fetching the required fields for the query.","title":"only_fields"},{"location":"optimizer/#aliases","text":"Contains the expressions that will be applied to QuerySet.alias() . Various methods in Undine can add to these aliases to enable more clearer use of for annotations .","title":"aliases"},{"location":"optimizer/#annotations","text":"Contains the expressions that will be applied to QuerySet.annotate() . Fields that resolve using an expression will store the expression here.","title":"annotations"},{"location":"optimizer/#select_related","text":"Contains OptimizationData for related fields that should be fetched together using QuerySet.select_related() . New related fields should be added using add_select_related to ensure that the correct references are places in both OptimizationData .","title":"select_related"},{"location":"optimizer/#prefetch_related","text":"Contains OptimizationData for related fields that should be fetched together using QuerySet.prefetch_related() . New related fields should be added using add_prefetch_related to ensure that the correct references are places in both OptimizationData . Note that the key in the mapping can be either the name of the related field, or an alias that the data should be fetched with (using Prefetch(..., to_attr=<alias>) ).","title":"prefetch_related"},{"location":"optimizer/#generic_prefetches","text":"Contains OptimizationData for generic foreign keys that should be fetched together using QuerySet.prefetch_related() . New generic prefetches should be added using add_generic_prefetch_related to ensure that the correct references are places in both OptimizationData .","title":"generic_prefetches"},{"location":"optimizer/#filters","text":"Contains Q expressions that will be applied to QuerySet.filter() . Normally, these are compiled from a FilterSet .","title":"filters"},{"location":"optimizer/#order_by","text":"Contains OrderBy expressions that will be applied to QuerySet.order_by() . Normally, these are compiled from an OrderSet .","title":"order_by"},{"location":"optimizer/#distinct","text":"Whether QuerySet.distinct() should be applied. Normally, the optimizer is able to determine this based on the FilterSet Filters used in the query.","title":"distinct"},{"location":"optimizer/#none","text":"Whether QuerySet.none() should be applied. Note that using QuerySet.none() will result in an empty QuerySet regardless of other optimizations. Normally, this is only applied if a FilterSet Filter raises an EmptyFilterResult exception.","title":"none"},{"location":"optimizer/#pagination","text":"Contains the pagination information for the QuerySet in the form of a PaginationHandler object. Normally, this is set by the optimizer automatically based on if the field uses a Connection or not.","title":"pagination"},{"location":"optimizer/#queryset_callback","text":"A callback function that initializes the QuerySet for the OptimizationData . By default, this is set to use the Manager.get_queryset() method of the OptimizationData's model's default manager, or the QueryType.__get_queryset__ method for related fields to other QueryTypes .","title":"queryset_callback"},{"location":"optimizer/#pre_filter_callback","text":"A callback function that will be called before order_by , distinct , filters , or field_calculations are applied to the QuerySet . Normally, this is populated using the QueryType.__filter_queryset__ method, if it has been overridden from the default.","title":"pre_filter_callback"},{"location":"optimizer/#post_filter_callback","text":"A callback function that will be called after order_by , distinct , filters , and field_calculations are applied to the QuerySet . Normally, this is populated using the FilterSet.__filter_queryset__ method, if it has been overridden from the default.","title":"post_filter_callback"},{"location":"optimizer/#field_calculations","text":"A list of Calculation instances that should be run and annotated to the QuerySet . Normally, the optimizer will automatically add Fields using Calculation objects to this list.","title":"field_calculations"},{"location":"optimizer/#add_select_related","text":"A method for adding a new select_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created select_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly.","title":"add_select_related()"},{"location":"optimizer/#add_prefetch_related","text":"A method for adding a new prefetch_related optimization. Must provide the field_name for the model relation, and optionally a QueryType that the relation should use, as well as a to_attr for the prefetch alias. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. The string passed in to_attr will be used in Prefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch \"to-many\" relations to aliases of custom schema names.","title":"add_prefetch_related()"},{"location":"optimizer/#add_generic_prefetch_related","text":"A method for adding a new generic_prefetch_related optimization. Must provide the field_name for the model relation, the related_model that the generic prefetch should be done for, and optionally a QueryType that the relation should use, and to_attr for the prefetch alias. Passing the QueryType will fill the queryset_callback , pre_filter_callback , and post_filter_callback from the QueryType automatically. Otherwise, the method will make sure that the created generic_prefetch_related optimization has the correct references to its parent OptimizationData , which it needs so that it can be compiled correctly. The string passed in to_attr will be used in GenericPrefetch(..., to_attr=<to_attr>) , which will prefetch the related field to the given attribute name. Normally, the optimizer uses this to fetch \"to-many\" relations to aliases of custom schema names.","title":"add_generic_prefetch_related()"},{"location":"optimizer/#optimization-results","text":"Once the whole query has been analyzed, the OptimizationData is processed to OptimizationResults , which can then be applied to the QuerySet . OptimizationData processing simply copies over most of the data from the OptimizationData , but notably, it also converts any select_related , prefetch_related , or generic_prefetch_related optimizations to values that can be applied to a QuerySet . For select_related , this means either promotion to a prefetch , or extending the related field's optimizations to the parent model (e.g. querying the name of a Project related to a Task will extend the name lookups to the Task model: project__name , and add it to the Task model's OptimizationResults.only_fields ). For prefetch_related , the prefetch OptimizationResults are processed and applied to the queryset from taken from OptimizationResults.queryset_callback . The resulting Prefetch() object is added to the parent OptimizationResults.prefetch_related . generic_prefetch_related is processed similarly to prefetch_related , expect a GenericPrefetch() object is created instead.","title":"Optimization results"},{"location":"optimizer/#promotion-to-prefetch","text":"In certain cases, a select_related optimization must be promoted to a prefetch_related . This can happen for one of the following reasons: Any annotations (or aliases ) are requested from the relation. A prefetch must be made so that the annotation remains available in the related object. Any field_calculations are present. Calculation will become annotations, so the reason is the same as above. A pre_filter_callback or post_filter_callback is needed. Since these callbacks might filter out the related object, a prefetch must be done to ensure this. Note that this might result in a null value for a field that would otherwise not be null!","title":"Promotion to prefetch"},{"location":"optimizer/#order-of-optimizations","text":"The order in which the optimizations are applied is as follows: If none is True , return an empty QuerySet and exit early. If select_related is not empty, apply select_related optimizations using QuerySet.select_related() . If prefetch_related is not empty, apply prefetch_related optimizations using QuerySet.prefetch_related() . If only_fields is not empty, and apply the DISABLE_ONLY_FIELDS_OPTIMIZATION setting is not False, only_fields optimizations using QuerySet.only() . If aliases is not empty, apply aliases optimizations using QuerySet.alias() . If annotations is not empty, apply annotations optimizations using QuerySet.annotate() . If pre_filter_callback exists, call it. If order_by is not empty, apply order_by optimizations using QuerySet.order_by() . If distinct is True , apply QuerySet.distinct() . If field_calculations is not empty, run the Calculation and annotate the result to the QuerySet using the Calculation's __field_name__ . If filters is not empty, apply filters optimizations using QuerySet.filter() If post_filter_callback exists, call it. If pagination is not empty, run either pagination.paginate_queryset() or pagination.paginate_prefetch_queryset() depending on whether a related_field exists or not. Return the optimized QuerySet .","title":"Order of optimizations"},{"location":"ordering/","text":"Ordering \ud83d\udd17 In this section, we'll cover the everything necessary for ordering results returned by your QueryTypes . OrderSet \ud83d\udd17 An OrderSet is a collection of Order objects that can be applied to a QueryType . In GraphQL, they represent a GraphQL Enum , which when added to a QueryType creates an input argument for ordering the results of a QueryType . A basic OrderSet is created by subclassing OrderSet and adding its Django Model as a generic type parameter. Then, the OrderSet can be added to a QueryType using the orderset argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): name = Field () You can also add the OrderSet using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () @TaskOrderSet class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 An OrderSet can automatically introspect its Django model and convert the model's fields to Orders on the OrderSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) An auto-generated OrderSet has all of the Task model's fields translated into GraphQL Enum values, both in ascending and descending directions. 1 2 3 4 5 6 7 8 9 10 enum TaskOrderSet { pkAsc pkDesc nameAsc nameDesc doneAsc doneDesc createdAtAsc createdAtDesc } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the OrderSet class definition. With this, you can leave the OrderSet class body empty. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True ): name = Order () Your can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True , exclude = [ \"pk\" ]): ... Schema name \ud83d\udd17 By default, the name of the generated Enum is the same as the name of the OrderSet class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], schema_name = \"TaskOrderingChoices\" ): name = Order () Description \ud83d\udd17 You can provide a description using the description argument. 1 2 3 4 5 6 7 8 9 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): \"\"\"Description.\"\"\" name = Order () Directives \ud83d\udd17 You can add directives to the OrderSet by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ MyDirective ()]): name = Order () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an OrderSet from certain users by adding the visible argument to the OrderSet . Hiding an orderset set means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the OrderSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the OrderSet . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Order () OrderSet extensions are made available in the GraphQL Enum extensions after the schema is created. The OrderSet itself is found in the extensions under a key defined by the ORDERSET_EXTENSIONS_KEY setting. Order \ud83d\udd17 An Order is a class that is used to define a possible ordering for an OrderSet . Usually Orders correspond to fields on the Django model for their respective OrderSet . In GraphQL, it represents an EnumValue in a GraphQL Enum . An Order always requires a reference which it will use to create the Django OrderBy expression for the Order . Model field references \ud83d\udd17 For Orders corresponding to Django model fields, the Order can be used without passing in a reference, as its attribute name in the OrderSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as the references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Reverse from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Reverse ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Order , OrderSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskOrderSet ( OrderSet [ Task ]): copies = Order ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Null placement \ud83d\udd17 If the model field or expression used by the Order is nullable, the null_placement argument can be used to specify the position of null values. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( null_placement = \"first\" ) created_at = Order ( null_placement = \"last\" ) By default, null values are placed according to your database default. Aliases \ud83d\udd17 Sometimes a Order may require additional expressions to be added as aliases to the queryset when the Order is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models.functions import Lower from undine import DjangoExpression , GQLInfo , Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name_lower\" ) @name . aliases def name_lower ( self , info : GQLInfo , * , descending : bool ) -> dict [ str , DjangoExpression ]: return { \"name_lower\" : Lower ( \"name\" )} Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django model field name that the Order corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( field_name = \"name\" ) Schema name \ud83d\udd17 A schema_name can be provided to override the name of the Order in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Order attribute name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( schema_name = \"title\" ) Description \ud83d\udd17 By default, an Order is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( description = \"Order by task name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () \"\"\"Order by task name.\"\"\" Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Order as deprecated. This is for documentation purposes only, and does not affect the use of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the Order by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( directives = [ MyDirective ()]) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Order from certain users by adding the visible argument to the Order . Hiding an order means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Order by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( extensions = { \"foo\" : \"bar\" }) Order extensions are made available in the GraphQL Enum value extensions after the schema is created. The Order itself is found in the extensions under a key defined by the ORDER_EXTENSIONS_KEY setting.","title":"Ordering"},{"location":"ordering/#ordering","text":"In this section, we'll cover the everything necessary for ordering results returned by your QueryTypes .","title":"Ordering"},{"location":"ordering/#orderset","text":"An OrderSet is a collection of Order objects that can be applied to a QueryType . In GraphQL, they represent a GraphQL Enum , which when added to a QueryType creates an input argument for ordering the results of a QueryType . A basic OrderSet is created by subclassing OrderSet and adding its Django Model as a generic type parameter. Then, the OrderSet can be added to a QueryType using the orderset argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): name = Field () You can also add the OrderSet using decorator syntax. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () done = Order () created_at = Order () @TaskOrderSet class TaskType ( QueryType [ Task ]): name = Field ()","title":"OrderSet"},{"location":"ordering/#auto-generation","text":"An OrderSet can automatically introspect its Django model and convert the model's fields to Orders on the OrderSet . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) An auto-generated OrderSet has all of the Task model's fields translated into GraphQL Enum values, both in ascending and descending directions. 1 2 3 4 5 6 7 8 9 10 enum TaskOrderSet { pkAsc pkDesc nameAsc nameDesc doneAsc doneDesc createdAtAsc createdAtDesc } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the OrderSet class definition. With this, you can leave the OrderSet class body empty. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True ): name = Order () Your can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], auto = True , exclude = [ \"pk\" ]): ...","title":"Auto-generation"},{"location":"ordering/#schema-name","text":"By default, the name of the generated Enum is the same as the name of the OrderSet class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], schema_name = \"TaskOrderingChoices\" ): name = Order ()","title":"Schema name"},{"location":"ordering/#description","text":"You can provide a description using the description argument. 1 2 3 4 5 6 7 8 9 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): \"\"\"Description.\"\"\" name = Order ()","title":"Description"},{"location":"ordering/#directives","text":"You can add directives to the OrderSet by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM ]): ... class TaskOrderSet ( OrderSet [ Task ], directives = [ MyDirective ()]): name = Order () See the Directives section for more details on directives.","title":"Directives"},{"location":"ordering/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an OrderSet from certain users by adding the visible argument to the OrderSet . Hiding an orderset set means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"ordering/#graphql-extensions","text":"You can provide custom extensions for the OrderSet by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the OrderSet . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ], extensions = { \"foo\" : \"bar\" }): name = Order () OrderSet extensions are made available in the GraphQL Enum extensions after the schema is created. The OrderSet itself is found in the extensions under a key defined by the ORDERSET_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"ordering/#order","text":"An Order is a class that is used to define a possible ordering for an OrderSet . Usually Orders correspond to fields on the Django model for their respective OrderSet . In GraphQL, it represents an EnumValue in a GraphQL Enum . An Order always requires a reference which it will use to create the Django OrderBy expression for the Order .","title":"Order"},{"location":"ordering/#model-field-references","text":"For Orders corresponding to Django model fields, the Order can be used without passing in a reference, as its attribute name in the OrderSet class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Task . name ) Being explicit like this is only required if the name of the attribute in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( \"name\" )","title":"Model field references"},{"location":"ordering/#expression-references","text":"Django ORM expressions can also be used as the references. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Reverse from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( Reverse ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Order , OrderSet from undine.utils.model_utils import SubqueryCount from .models import Task class TaskOrderSet ( OrderSet [ Task ]): copies = Order ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"ordering/#null-placement","text":"If the model field or expression used by the Order is nullable, the null_placement argument can be used to specify the position of null values. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( null_placement = \"first\" ) created_at = Order ( null_placement = \"last\" ) By default, null values are placed according to your database default.","title":"Null placement"},{"location":"ordering/#aliases","text":"Sometimes a Order may require additional expressions to be added as aliases to the queryset when the Order is used. For this, you can define a function that returns a dictionary of expressions and decorate it with the aliases decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models.functions import Lower from undine import DjangoExpression , GQLInfo , Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( \"name_lower\" ) @name . aliases def name_lower ( self , info : GQLInfo , * , descending : bool ) -> dict [ str , DjangoExpression ]: return { \"name_lower\" : Lower ( \"name\" )}","title":"Aliases"},{"location":"ordering/#field-name","text":"A field_name can be provided to explicitly set the Django model field name that the Order corresponds to. This can be useful when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): title = Order ( field_name = \"name\" )","title":"Field name"},{"location":"ordering/#schema-name_1","text":"A schema_name can be provided to override the name of the Order in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Order attribute name. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( schema_name = \"title\" )","title":"Schema name"},{"location":"ordering/#description_1","text":"By default, an Order is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, this can be done in two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( description = \"Order by task name.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () \"\"\"Order by task name.\"\"\"","title":"Description"},{"location":"ordering/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Order as deprecated. This is for documentation purposes only, and does not affect the use of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"ordering/#directives_1","text":"You can add directives to the Order by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Order , OrderSet from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . ENUM_VALUE ]): ... class TaskOrderSet ( OrderSet [ Task ]): name = Order ( directives = [ MyDirective ()]) See the Directives section for more details on directives.","title":"Directives"},{"location":"ordering/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Order from certain users by adding the visible argument to the Order . Hiding an order means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Order , OrderSet from undine.typing import DjangoRequestProtocol from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"ordering/#graphql-extensions_1","text":"You can provide custom extensions for the Order by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Order . 1 2 3 4 5 6 7 from undine import Order , OrderSet from .models import Task class TaskOrderSet ( OrderSet [ Task ]): name = Order ( extensions = { \"foo\" : \"bar\" }) Order extensions are made available in the GraphQL Enum value extensions after the schema is created. The Order itself is found in the extensions under a key defined by the ORDER_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"pagination/","text":"Pagination \ud83d\udd17 In this section, we'll cover the everything necessary for adding pagination to your GraphQL schema using the Relay Connection specification. For Relay-compliant clients, see the Global Object IDs section for adding support for the Node interface. Here are the models used in the examples below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.db import models class Person ( models . Model ): name = models . CharField ( max_length = 255 ) email = models . EmailField ( unique = True ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) assignees = models . ManyToManyField ( Person ) Connection \ud83d\udd17 To support pagination, you need to wrap QueryTypes in Entrypoints with the Connection class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) This will create the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type TaskTypeEdge { cursor : String ! node : TaskType } type PageInfo { hasNextPage : Boolean ! hasPreviousPage : Boolean ! startCursor : String endCursor : String } type TaskTypeConnection { totalCount : Int ! pageInfo : PageInfo ! edges : [ TaskTypeEdge !]! } type Query { pagedTasks ( after : String before : String first : Int last : Int offset : Int ) : TaskTypeConnection ! } Querying this Entrypoint will return a response like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \"data\" : { \"pagedTasks\" : { \"totalCount\" : 3 , \"pageInfo\" : { \"hasNextPage\" : false , \"hasPreviousPage\" : false , \"startCursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"endCursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" }, \"edges\" : [ { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"node\" : { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjE=\" , \"node\" : { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" , \"node\" : { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } } ] } } } One addition to the Relay specification is the inclusion of a totalCount field, which returns the total number of items that can be queried from the Connection . If a FilterSet or OrderSet has been added to your QueryType , those filters and orders will be added to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 type Query { pagedTasks ( after : String before : String first : Int last : Int offset : Int filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): TaskTypeConnection ! } Many-related Fields can also be paginated using the Connection class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.relay import Connection from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( Connection ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) Page size \ud83d\udd17 The default page size of a Connection is set by the CONNECTION_PAGE_SIZE setting. You can use a different page size by providing the page_size argument to the Connection . 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , page_size = 20 )) Custom pagination strategies \ud83d\udd17 Both top-level and nested connections are optimized by the Optimizer to only query the items that are needed for the current page. Both optimizations should be quite performant, but calculating totalCount for nested connections can be slow, since it requires a subquery for each parent item. If you need to modify the pagination behavior, you can do so by providing a custom PaginationHandler to the Connection . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection , PaginationHandler from .models import Task class CustomPaginationHandler ( PaginationHandler ): \"\"\"Custom pagination logic.\"\"\" class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , pagination_handler = CustomPaginationHandler ))","title":"Pagination"},{"location":"pagination/#pagination","text":"In this section, we'll cover the everything necessary for adding pagination to your GraphQL schema using the Relay Connection specification. For Relay-compliant clients, see the Global Object IDs section for adding support for the Node interface. Here are the models used in the examples below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from django.db import models class Person ( models . Model ): name = models . CharField ( max_length = 255 ) email = models . EmailField ( unique = True ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) assignees = models . ManyToManyField ( Person )","title":"Pagination"},{"location":"pagination/#connection","text":"To support pagination, you need to wrap QueryTypes in Entrypoints with the Connection class. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType )) This will create the following GraphQL types. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } type TaskTypeEdge { cursor : String ! node : TaskType } type PageInfo { hasNextPage : Boolean ! hasPreviousPage : Boolean ! startCursor : String endCursor : String } type TaskTypeConnection { totalCount : Int ! pageInfo : PageInfo ! edges : [ TaskTypeEdge !]! } type Query { pagedTasks ( after : String before : String first : Int last : Int offset : Int ) : TaskTypeConnection ! } Querying this Entrypoint will return a response like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \"data\" : { \"pagedTasks\" : { \"totalCount\" : 3 , \"pageInfo\" : { \"hasNextPage\" : false , \"hasPreviousPage\" : false , \"startCursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"endCursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" }, \"edges\" : [ { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjA=\" , \"node\" : { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjE=\" , \"node\" : { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true } }, { \"cursor\" : \"YXJyYXljb25uZWN0aW9uOjI=\" , \"node\" : { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } } ] } } } One addition to the Relay specification is the inclusion of a totalCount field, which returns the total number of items that can be queried from the Connection . If a FilterSet or OrderSet has been added to your QueryType , those filters and orders will be added to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 type Query { pagedTasks ( after : String before : String first : Int last : Int offset : Int filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): TaskTypeConnection ! } Many-related Fields can also be paginated using the Connection class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , Field , QueryType , RootType from undine.relay import Connection from .models import Person , Task class PersonType ( QueryType [ Person ]): ... class TaskType ( QueryType [ Task ]): assignees = Field ( Connection ( PersonType )) class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType ))","title":"Connection"},{"location":"pagination/#page-size","text":"The default page size of a Connection is set by the CONNECTION_PAGE_SIZE setting. You can use a different page size by providing the page_size argument to the Connection . 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , page_size = 20 ))","title":"Page size"},{"location":"pagination/#custom-pagination-strategies","text":"Both top-level and nested connections are optimized by the Optimizer to only query the items that are needed for the current page. Both optimizations should be quite performant, but calculating totalCount for nested connections can be slow, since it requires a subquery for each parent item. If you need to modify the pagination behavior, you can do so by providing a custom PaginationHandler to the Connection . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , QueryType , RootType from undine.relay import Connection , PaginationHandler from .models import Task class CustomPaginationHandler ( PaginationHandler ): \"\"\"Custom pagination logic.\"\"\" class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): paged_tasks = Entrypoint ( Connection ( TaskType , pagination_handler = CustomPaginationHandler ))","title":"Custom pagination strategies"},{"location":"persisted-documents/","text":"Persisted Documents \ud83d\udd17 In this section, we'll cover Undine's support for persisted documents \u2014 a way to persist known GraphQL documents on the server for caching, reducing network traffic, or to use as an operation allow-list. Installation \ud83d\udd17 To enable persisted documents, you must first add the undine.persisted_documents app to your INSTALLED_APPS : 1 2 3 4 5 6 INSTALLED_APPS = [ # ... \"undine\" , \"undine.persisted_documents\" , # ... ] Then, add the persisted document registration view to your URLconf: 1 2 3 4 5 6 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), path ( \"\" , include ( \"undine.persisted_documents.urls\" )), ] Before running migrations, you should have a look at the PersistedDocument model in undine.persisted_documents.model . This model can be swapped out with your own implementation using the UNDINE_PERSISTED_DOCUMENTS_MODEL setting, similar to how the User model can be swapped out with AUTH_USER_MODEL . Whether you decide to do this or not, remember to run migrations afterwards. Usage \ud83d\udd17 Once the app is installed, Undine is ready to accept persisted documents. This can be done from the same GraphQL endpoint used for regular GraphQL requests by providing a documentId instead of a query string. 1 2 3 4 { \"documentId\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"variables\" : {} } A documentId can be obtained by registering a persisted document using the PersistedDocument model. This can be done by posting the document to the registration view, as specified by the PERSISTED_DOCUMENTS_PATH setting. The view accepts a dictionary of documents like this: 1 2 3 4 5 6 { \"documents\" : { \"foo\" : \"query { example }\" , \"bar\" : \"query { testing }\" } } ...and returns a dictionary of documentIds like this: 1 2 3 4 5 6 7 8 { \"data\" : { \"documents\" : { \"foo\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"bar\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" } } } ...where each key in the documents dictionary is defined by the user, so that the corresponding documentId is returned in in the same key. The keys are not used for anything else. Note that a document with the same selection set produces a different documentId if they have different whitespace, newlines, or comments. This is to ensure that error locations stay consistent. Response for this view follows the GraphQL response format , so any errors are returned in the \"errors\" key. You likely want to protect this view with a permission check. This can be done by setting the PERSISTED_DOCUMENTS_PERMISSION_CALLBACK setting to a function that accepts a request and document_map as arguments. 1 2 3 4 5 6 7 8 9 from django.http import HttpRequest from undine.exceptions import GraphQLPermissionError def persisted_documents_permissions ( request : HttpRequest , document_map : dict [ str , str ]) -> None : if not request . user . is_superuser : msg = \"You do not have permission to register persisted documents.\" raise GraphQLPermissionError ( msg ) Allow-list mode \ud83d\udd17 As mentioned, persisted documents can be used to create an allow-list for GraphQL operations. Usually this is done to enhance security of a system by preventing malicious queries from being executed. Undine can be configured to only accept persisted documents by setting the PERSISTED_DOCUMENTS_ONLY setting to True . 1 2 3 UNDINE = { \"PERSISTED_DOCUMENTS_ONLY\" : True , } When operating in this mode, your clients should call PersistedDocumentsView during build time to register their queries and mutations.","title":"Persisted Documents"},{"location":"persisted-documents/#persisted-documents","text":"In this section, we'll cover Undine's support for persisted documents \u2014 a way to persist known GraphQL documents on the server for caching, reducing network traffic, or to use as an operation allow-list.","title":"Persisted Documents"},{"location":"persisted-documents/#installation","text":"To enable persisted documents, you must first add the undine.persisted_documents app to your INSTALLED_APPS : 1 2 3 4 5 6 INSTALLED_APPS = [ # ... \"undine\" , \"undine.persisted_documents\" , # ... ] Then, add the persisted document registration view to your URLconf: 1 2 3 4 5 6 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), path ( \"\" , include ( \"undine.persisted_documents.urls\" )), ] Before running migrations, you should have a look at the PersistedDocument model in undine.persisted_documents.model . This model can be swapped out with your own implementation using the UNDINE_PERSISTED_DOCUMENTS_MODEL setting, similar to how the User model can be swapped out with AUTH_USER_MODEL . Whether you decide to do this or not, remember to run migrations afterwards.","title":"Installation"},{"location":"persisted-documents/#usage","text":"Once the app is installed, Undine is ready to accept persisted documents. This can be done from the same GraphQL endpoint used for regular GraphQL requests by providing a documentId instead of a query string. 1 2 3 4 { \"documentId\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"variables\" : {} } A documentId can be obtained by registering a persisted document using the PersistedDocument model. This can be done by posting the document to the registration view, as specified by the PERSISTED_DOCUMENTS_PATH setting. The view accepts a dictionary of documents like this: 1 2 3 4 5 6 { \"documents\" : { \"foo\" : \"query { example }\" , \"bar\" : \"query { testing }\" } } ...and returns a dictionary of documentIds like this: 1 2 3 4 5 6 7 8 { \"data\" : { \"documents\" : { \"foo\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" , \"bar\" : \"sha256:75d3580309f2b2bbe92cecc1ff4faf7533e038f565895c8eef25dc23e6491b8d\" } } } ...where each key in the documents dictionary is defined by the user, so that the corresponding documentId is returned in in the same key. The keys are not used for anything else. Note that a document with the same selection set produces a different documentId if they have different whitespace, newlines, or comments. This is to ensure that error locations stay consistent. Response for this view follows the GraphQL response format , so any errors are returned in the \"errors\" key. You likely want to protect this view with a permission check. This can be done by setting the PERSISTED_DOCUMENTS_PERMISSION_CALLBACK setting to a function that accepts a request and document_map as arguments. 1 2 3 4 5 6 7 8 9 from django.http import HttpRequest from undine.exceptions import GraphQLPermissionError def persisted_documents_permissions ( request : HttpRequest , document_map : dict [ str , str ]) -> None : if not request . user . is_superuser : msg = \"You do not have permission to register persisted documents.\" raise GraphQLPermissionError ( msg )","title":"Usage"},{"location":"persisted-documents/#allow-list-mode","text":"As mentioned, persisted documents can be used to create an allow-list for GraphQL operations. Usually this is done to enhance security of a system by preventing malicious queries from being executed. Undine can be configured to only accept persisted documents by setting the PERSISTED_DOCUMENTS_ONLY setting to True . 1 2 3 UNDINE = { \"PERSISTED_DOCUMENTS_ONLY\" : True , } When operating in this mode, your clients should call PersistedDocumentsView during build time to register their queries and mutations.","title":"Allow-list mode"},{"location":"queries/","text":"Queries \ud83d\udd17 In this section, we'll cover Undine's QueryTypes which allow you to expose your Django models through the GraphQL schema for querying, expanding on the basics introduced in the Tutorial . If you need to query data outside of your Django models, see the function references section in the schema documentation. QueryTypes \ud83d\udd17 A QueryType represents a GraphQL ObjectType for querying data from a Django model in the GraphQL schema. A basic QueryType is created by subclassing QueryType and adding a Django model to it as a generic type parameter: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () Auto-generation \ud83d\udd17 A QueryType can automatically introspect its Django model and convert the model's fields to Fields on the QueryType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL ObjectType for the QueryType using auto-generation would be: 1 2 3 4 5 6 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the QueryType class definition. With this, you can leave the QueryType class body empty. 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True , exclude = [ \"name\" ]): ... Filtering \ud83d\udd17 Results from QueryTypes can be filtered in two ways: 1) Adding a FilterSet to the QueryType . These are explained in detail in the Filtering section. 2) Defining a __filter_queryset__ classmethod. This method is used to filter all results returned by the QueryType . Use it to filter out items that should never be returned by the QueryType , e.g. archived items. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . filter ( archived = False ) Ordering \ud83d\udd17 Results from QueryTypes can be ordered in two ways: 1) Adding an OrderSet to the QueryType . These are explained in detail in the Ordering section. 2) Defining a __filter_queryset__ classmethod. Same as custom filtering , this is used for all results returned by the QueryType . However, since queryset ordering is reset when a new ordering is applied to the queryset, ordering added here serves as the default ordering for the QueryType , and is overridden if any ordering is applied using an OrderSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . order_by ( \"name\" ) Permissions \ud83d\udd17 You can add a permission check for querying data from a QueryType by adding a __permissions__ classmethod it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query tasks.\" raise GraphQLPermissionError ( msg ) This method will be called for each instance of Task that is returned by this QueryType . For lists, this means that the method will be called for each item in the list. Instead of raising an exception, you might want to filter out items the user doesn't have permission to access. You can do this using the __filter_queryset__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_authenticated : return queryset . none () return queryset Now, when the QueryType is used in a list entrypoint or in \"to-many\" relations, items that the user doesn't have permission to access will be filtered out. For single-item entrypoints or \"to-one\" relations, a null value will be returned instead. Note that you'll need to manually check all Fields and Entrypoints where the QueryType is used and mark them as nullable if they would otherwise not be. If your permissions check requires data from outside of the GraphQL execution context, you should check the Optimizer section on how you can make sure permissions checks don't cause an excessive database queries. QueryType registry \ud83d\udd17 When a new QueryType is created, Undine automatically registers it for its given model. This allows other QueryTypes to look up the QueryType for linking relations (see relations ), and MutationTypes to find out their matching output type (see mutation output types ). The QueryType registry only allows one QueryType to be registered for each model. During QueryType registration, if a QueryType is already registered for the model, an error will be raised. If you need to create multiple QueryTypes for the same model, you can choose to not register a QueryType for the model by setting the register argument to False in the QueryType class definition. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () class OtherTaskType ( QueryType [ Task ], register = False ): pk = Field () You then need to use this QueryType explicitly when required. Custom optimizations \ud83d\udd17 The optimizer is covered more thoroughly in the Optimizer section. Usually touching the QueryType optimizations is not necessary, but if required, you can override the __optimizations__ classmethod on the QueryType to do so. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks. Schema name \ud83d\udd17 By default, the name of the generated ObjectType for a QueryType is the same as the name of the QueryType class. If you want to change the name of the ObjectType , you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], schema_name = \"Task\" ): name = Field () Description \ud83d\udd17 To provide a description for the QueryType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): \"\"\"Description.\"\"\" name = Field () Interfaces \ud83d\udd17 You can add interfaces to the QueryType by providing them using the interfaces argument. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): name = Field () See the Interfaces section for more details on interfaces. Directives \ud83d\udd17 You can add directives to the QueryType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class TaskType ( QueryType [ Task ], directives = [ MyDirective ()]): name = Field () See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a QueryType from certain users by adding the visible argument to the QueryType . Hiding a query type means that it will not be included in introspection queries for that user, and entrypoints (query or mutation output) and relations using that query type cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the QueryType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Field () QueryType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting. Fields \ud83d\udd17 A Field is a class that is used to define a queryable value for a QueryType . Usually Fields correspond to fields on the Django model for their respective QueryType . In GraphQL, a Field represents a GraphQLField in an ObjectType . A Field always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the Field . Model field references \ud83d\udd17 For Fields corresponding to Django model fields, the Field can be used without passing in a reference, as its attribute name in the QueryType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( Task . name ) Being explicit like this is only required if the name of the field in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( \"name\" ) Expression references \ud83d\udd17 Django ORM expressions can also be used as the references. These create an annotation on the model instances when fetched. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): upper_name = Field ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Field , QueryType from undine.utils.model_utils import SubqueryCount from .models import Task class TaskType ( QueryType [ Task ]): copies = Field ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" )))) Function references \ud83d\udd17 Functions (or methods) can also be used to create Fields . This can be done by decorating a method with the Field class. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo ) -> str : return \"Hello World!\" The Field will use the decorated method as its GraphQL resolver. The method's return type will be used as the output type for the Field , so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Arguments added to the function signatures will be added as Field arguments in the GraphQL schema. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo , * , name : str ) -> str : return f \"Hello, { name } !\" If the method requires fields from the root instance, you should add custom optimization rules for the Field so that the fields are available when the resolver is called. See custom optimizations for how to add these, although it might be simpler to use a Calculation reference . Calculation references \ud83d\udd17 A Calculation reference is like a combination of function references and expression references . They can accept data from input arguments like a function reference, and return an expression that should be annotated to a queryset like an expression reference. A Calculation references can be created by subclassing the Calculation class and adding the required CalculationArguments to its class body. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import Value from undine import Calculation , CalculationArgument , DjangoExpression , Field , GQLInfo , QueryType from .models import Task class ExampleCalculation ( Calculation [ int ]): value = CalculationArgument ( int ) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : # Some impressive calculation here return Value ( self . value ) class TaskType ( QueryType [ Task ]): calc = Field ( ExampleCalculation ) Calculation objects always require the generic type argument to be set, which describes the return type of the calculation. This should be a python type matching the expression that is returned in the __call__ method. CalculationArguments can be defined in the class body of the Calculation class. These define the input arguments for the calculation. When the calculation is executed, the CalculationArguments can be used to access the input data for that specific argument. The __call__ method should always be defined in the Calculation class. This should return a Django ORM expression that can be annotated to a queryset. You may access other fields using F -expressions and use request-specific data from the info argument. The Field will look like this in the GraphQL schema: 1 2 3 type TaskType { calc ( value : Int ! ) : Int ! } A Calculation reference is a good replacement for a function reference when the calculation is expensive enough that resolving it for each field would be slow. However, the calculation needs to be able to be executed in the database since __call__ needs to return a Django ORM expression to be annotated to a queryset. A Calculation reference is a good replacement for an expression reference when the expression requires input data from the request. Relations \ud83d\udd17 Let's say there is a Task model with a ForeignKey to a Project model: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE ) You can then create QueryTypes for both models and add Fields for the related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Field , QueryType from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () The QueryTypes will be linked together in the GraphQL schema by their relations: 1 2 3 4 5 6 7 8 9 10 11 12 13 type ProjectType { pk : Int ! name : String ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! project : ProjectType ! } Permissions \ud83d\udd17 You can add a permissions for querying any data from an individual Field by decorating a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query task names.\" raise GraphQLPermissionError ( msg ) If Field permissions are defined for a related field, the related QueryType permissions are overridden by the Field permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Project , Task class ProjectType ( QueryType [ Project ]): @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo ) -> None : # Not called if 'ProjectType' is accessed from 'TaskType.project' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class TaskType ( QueryType [ Task ]): project = Field () @project . permissions def project_permissions ( self , info : GQLInfo , value : Project ) -> None : if not info . context . user . is_authenticated : raise GraphQLPermissionError Instead of raising an exception, you might want a failed permission check to result in a null value instead of an error. You can do this overriding the Field's resolver and manually checking the permissions there, returning None when permission is denied. Note that you'll need to manually set the Field as nullable if it would otherwise not be. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = True ) @name . resolve def name_resolver ( self , info : GQLInfo ) -> str | None : if not info . context . user . is_authenticated : return None return self . name Descriptions \ud83d\udd17 By default, a Field is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" Many \ud83d\udd17 By default, a Field is able to determine whether it returns a list of items based on its reference. For example, for a model field, a ManyToManyField will return a list of items. If you want to configure this manually, you can do so by adding the many argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( many = False ) Nullable \ud83d\udd17 By default, a Field is able to determine whether it's nullable or not based on its reference. For example, for a model field, nullability is determined from its null attribute. If you want to configure this manually, you can do so by adding the nullable argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = False ) Complexity \ud83d\udd17 The complexity value of a Field is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. By default, a Field is able to determine its complexity based on its reference. For example, a related field has a complexity of 1, and a regular model field has a complexity of 0. If you want to configure this manually, you can do so by adding the complexity argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( complexity = 1 ) Field name \ud83d\udd17 A field_name can be provided to explicitly set the Django model field name that the Field corresponds to. This can be useful when you need multiple Fields for the same model field, or when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( field_name = \"name\" ) Schema name \ud83d\udd17 A schema_name can be provided to override the name of the Field in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Field attribute name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( schema_name = \"title\" ) Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Field as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( deprecation_reason = \"Use something else.\" ) Custom resolvers \ud83d\udd17 Usually using a custom Field resolver is not necessary, and should be avoided if possible. This is because most modifications to resolvers can result in canceling query optimizations (see the optimizer section for details). You can override the resolver for a Field by adding a method to the class body of the QueryType and decorating it with the @<field_name>.resolve decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve def resolve_name ( self , info : GQLInfo ) -> str : return self . name . upper () About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Custom optimizations \ud83d\udd17 The optimizer is covered more thoroughly in the Optimizer section. Usually touching the Field optimizations is not necessary, but if required, you can do so by adding a method to the class body of the QueryType and decorating it with the @<field_name>.optimize decorator. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks. Directives \ud83d\udd17 You can add directives to the Field by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field ( directives = [ MyDirective ()]) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Field from certain users by adding the visible argument to the Field . Hiding a field means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Field by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( extensions = { \"foo\" : \"bar\" }) Field extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"Queries"},{"location":"queries/#queries","text":"In this section, we'll cover Undine's QueryTypes which allow you to expose your Django models through the GraphQL schema for querying, expanding on the basics introduced in the Tutorial . If you need to query data outside of your Django models, see the function references section in the schema documentation.","title":"Queries"},{"location":"queries/#querytypes","text":"A QueryType represents a GraphQL ObjectType for querying data from a Django model in the GraphQL schema. A basic QueryType is created by subclassing QueryType and adding a Django model to it as a generic type parameter: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ()","title":"QueryTypes"},{"location":"queries/#auto-generation","text":"A QueryType can automatically introspect its Django model and convert the model's fields to Fields on the QueryType . For example, if the Task model has the following fields: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Then the GraphQL ObjectType for the QueryType using auto-generation would be: 1 2 3 4 5 6 type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! } To use auto-generation, either set AUTOGENERATION setting to True to enable it globally, or set the auto argument to True in the QueryType class definition. With this, you can leave the QueryType class body empty. 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True ): ... You can exclude some model fields from the auto-generation by setting the exclude argument: 1 2 3 4 5 6 from undine import QueryType from .models import Task class TaskType ( QueryType [ Task ], auto = True , exclude = [ \"name\" ]): ...","title":"Auto-generation"},{"location":"queries/#filtering","text":"Results from QueryTypes can be filtered in two ways: 1) Adding a FilterSet to the QueryType . These are explained in detail in the Filtering section. 2) Defining a __filter_queryset__ classmethod. This method is used to filter all results returned by the QueryType . Use it to filter out items that should never be returned by the QueryType , e.g. archived items. 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . filter ( archived = False )","title":"Filtering"},{"location":"queries/#ordering","text":"Results from QueryTypes can be ordered in two ways: 1) Adding an OrderSet to the QueryType . These are explained in detail in the Ordering section. 2) Defining a __filter_queryset__ classmethod. Same as custom filtering , this is used for all results returned by the QueryType . However, since queryset ordering is reset when a new ordering is applied to the queryset, ordering added here serves as the default ordering for the QueryType , and is overridden if any ordering is applied using an OrderSet . 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : return queryset . order_by ( \"name\" )","title":"Ordering"},{"location":"queries/#permissions","text":"You can add a permission check for querying data from a QueryType by adding a __permissions__ classmethod it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query tasks.\" raise GraphQLPermissionError ( msg ) This method will be called for each instance of Task that is returned by this QueryType . For lists, this means that the method will be called for each item in the list. Instead of raising an exception, you might want to filter out items the user doesn't have permission to access. You can do this using the __filter_queryset__ classmethod. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from django.db.models import QuerySet from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __filter_queryset__ ( cls , queryset : QuerySet , info : GQLInfo ) -> QuerySet : if not info . context . user . is_authenticated : return queryset . none () return queryset Now, when the QueryType is used in a list entrypoint or in \"to-many\" relations, items that the user doesn't have permission to access will be filtered out. For single-item entrypoints or \"to-one\" relations, a null value will be returned instead. Note that you'll need to manually check all Fields and Entrypoints where the QueryType is used and mark them as nullable if they would otherwise not be. If your permissions check requires data from outside of the GraphQL execution context, you should check the Optimizer section on how you can make sure permissions checks don't cause an excessive database queries.","title":"Permissions"},{"location":"queries/#querytype-registry","text":"When a new QueryType is created, Undine automatically registers it for its given model. This allows other QueryTypes to look up the QueryType for linking relations (see relations ), and MutationTypes to find out their matching output type (see mutation output types ). The QueryType registry only allows one QueryType to be registered for each model. During QueryType registration, if a QueryType is already registered for the model, an error will be raised. If you need to create multiple QueryTypes for the same model, you can choose to not register a QueryType for the model by setting the register argument to False in the QueryType class definition. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () class OtherTaskType ( QueryType [ Task ], register = False ): pk = Field () You then need to use this QueryType explicitly when required.","title":"QueryType registry"},{"location":"queries/#custom-optimizations","text":"The optimizer is covered more thoroughly in the Optimizer section. Usually touching the QueryType optimizations is not necessary, but if required, you can override the __optimizations__ classmethod on the QueryType to do so. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __optimizations__ ( cls , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks.","title":"Custom optimizations"},{"location":"queries/#schema-name","text":"By default, the name of the generated ObjectType for a QueryType is the same as the name of the QueryType class. If you want to change the name of the ObjectType , you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], schema_name = \"Task\" ): name = Field ()","title":"Schema name"},{"location":"queries/#description","text":"To provide a description for the QueryType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): \"\"\"Description.\"\"\" name = Field ()","title":"Description"},{"location":"queries/#interfaces","text":"You can add interfaces to the QueryType by providing them using the interfaces argument. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from undine.relay import Node from .models import Task class TaskType ( QueryType [ Task ], interfaces = [ Node ]): name = Field () See the Interfaces section for more details on interfaces.","title":"Interfaces"},{"location":"queries/#directives","text":"You can add directives to the QueryType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class TaskType ( QueryType [ Task ], directives = [ MyDirective ()]): name = Field () See the Directives section for more details on directives.","title":"Directives"},{"location":"queries/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a QueryType from certain users by adding the visible argument to the QueryType . Hiding a query type means that it will not be included in introspection queries for that user, and entrypoints (query or mutation output) and relations using that query type cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @classmethod def __is_visible__ ( cls , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"queries/#graphql-extensions","text":"You can provide custom extensions for the QueryType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the QueryType . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ], extensions = { \"foo\" : \"bar\" }): name = Field () QueryType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"queries/#fields","text":"A Field is a class that is used to define a queryable value for a QueryType . Usually Fields correspond to fields on the Django model for their respective QueryType . In GraphQL, a Field represents a GraphQLField in an ObjectType . A Field always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the Field .","title":"Fields"},{"location":"queries/#model-field-references","text":"For Fields corresponding to Django model fields, the Field can be used without passing in a reference, as its attribute name in the QueryType class body can be used to identify the corresponding model field. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () To be a bit more explicit, you could use a string referencing the model field: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( \"name\" ) For better type safety, you can also use the model field itself: 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( Task . name ) Being explicit like this is only required if the name of the field in the GraphQL schema is different from the model field name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( \"name\" )","title":"Model field references"},{"location":"queries/#expression-references","text":"Django ORM expressions can also be used as the references. These create an annotation on the model instances when fetched. 1 2 3 4 5 6 7 8 9 from django.db.models.functions import Upper from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): upper_name = Field ( Upper ( \"name\" )) Remember that subqueries are also counted as expressions. 1 2 3 4 5 6 7 8 9 10 from django.db.models import OuterRef from undine import Field , QueryType from undine.utils.model_utils import SubqueryCount from .models import Task class TaskType ( QueryType [ Task ]): copies = Field ( SubqueryCount ( Task . objects . filter ( name = OuterRef ( \"name\" ))))","title":"Expression references"},{"location":"queries/#function-references","text":"Functions (or methods) can also be used to create Fields . This can be done by decorating a method with the Field class. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo ) -> str : return \"Hello World!\" The Field will use the decorated method as its GraphQL resolver. The method's return type will be used as the output type for the Field , so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Arguments added to the function signatures will be added as Field arguments in the GraphQL schema. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def greeting ( self , info : GQLInfo , * , name : str ) -> str : return f \"Hello, { name } !\" If the method requires fields from the root instance, you should add custom optimization rules for the Field so that the fields are available when the resolver is called. See custom optimizations for how to add these, although it might be simpler to use a Calculation reference .","title":"Function references"},{"location":"queries/#calculation-references","text":"A Calculation reference is like a combination of function references and expression references . They can accept data from input arguments like a function reference, and return an expression that should be annotated to a queryset like an expression reference. A Calculation references can be created by subclassing the Calculation class and adding the required CalculationArguments to its class body. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from django.db.models import Value from undine import Calculation , CalculationArgument , DjangoExpression , Field , GQLInfo , QueryType from .models import Task class ExampleCalculation ( Calculation [ int ]): value = CalculationArgument ( int ) def __call__ ( self , info : GQLInfo ) -> DjangoExpression : # Some impressive calculation here return Value ( self . value ) class TaskType ( QueryType [ Task ]): calc = Field ( ExampleCalculation ) Calculation objects always require the generic type argument to be set, which describes the return type of the calculation. This should be a python type matching the expression that is returned in the __call__ method. CalculationArguments can be defined in the class body of the Calculation class. These define the input arguments for the calculation. When the calculation is executed, the CalculationArguments can be used to access the input data for that specific argument. The __call__ method should always be defined in the Calculation class. This should return a Django ORM expression that can be annotated to a queryset. You may access other fields using F -expressions and use request-specific data from the info argument. The Field will look like this in the GraphQL schema: 1 2 3 type TaskType { calc ( value : Int ! ) : Int ! } A Calculation reference is a good replacement for a function reference when the calculation is expensive enough that resolving it for each field would be slow. However, the calculation needs to be able to be executed in the database since __call__ needs to return a Django ORM expression to be annotated to a queryset. A Calculation reference is a good replacement for an expression reference when the expression requires input data from the request.","title":"Calculation references"},{"location":"queries/#relations","text":"Let's say there is a Task model with a ForeignKey to a Project model: 1 2 3 4 5 6 7 8 9 10 11 12 13 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . CASCADE ) You can then create QueryTypes for both models and add Fields for the related fields. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Field , QueryType from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () The QueryTypes will be linked together in the GraphQL schema by their relations: 1 2 3 4 5 6 7 8 9 10 11 12 13 type ProjectType { pk : Int ! name : String ! tasks : [ TaskType !]! } type TaskType { pk : Int ! name : String ! done : Boolean ! createdAt : DateTime ! project : ProjectType ! }","title":"Relations"},{"location":"queries/#permissions_1","text":"You can add a permissions for querying any data from an individual Field by decorating a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if not info . context . user . is_authenticated : msg = \"Only authenticated users can query task names.\" raise GraphQLPermissionError ( msg ) If Field permissions are defined for a related field, the related QueryType permissions are overridden by the Field permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Project , Task class ProjectType ( QueryType [ Project ]): @classmethod def __permissions__ ( cls , instance : Project , info : GQLInfo ) -> None : # Not called if 'ProjectType' is accessed from 'TaskType.project' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class TaskType ( QueryType [ Task ]): project = Field () @project . permissions def project_permissions ( self , info : GQLInfo , value : Project ) -> None : if not info . context . user . is_authenticated : raise GraphQLPermissionError Instead of raising an exception, you might want a failed permission check to result in a null value instead of an error. You can do this overriding the Field's resolver and manually checking the permissions there, returning None when permission is denied. Note that you'll need to manually set the Field as nullable if it would otherwise not be. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = True ) @name . resolve def name_resolver ( self , info : GQLInfo ) -> str | None : if not info . context . user . is_authenticated : return None return self . name","title":"Permissions"},{"location":"queries/#descriptions","text":"By default, a Field is able to determine its description based on its reference. For example, for a model field, the description is taken from its help_text . If the reference has no description, or you wish to add a different one, you can provide a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( description = \"The name of the task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () \"\"\"The name of the task.\"\"\" When using function references , instead of a class attribute docstring, you add a docstring to the function/method used as the reference instead. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): @Field def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\"","title":"Descriptions"},{"location":"queries/#many","text":"By default, a Field is able to determine whether it returns a list of items based on its reference. For example, for a model field, a ManyToManyField will return a list of items. If you want to configure this manually, you can do so by adding the many argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( many = False )","title":"Many"},{"location":"queries/#nullable","text":"By default, a Field is able to determine whether it's nullable or not based on its reference. For example, for a model field, nullability is determined from its null attribute. If you want to configure this manually, you can do so by adding the nullable argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( nullable = False )","title":"Nullable"},{"location":"queries/#complexity","text":"The complexity value of a Field is used by Undine to calculate how expensive a given query to the schema would be. Queries are rejected by Undine if they would exceed the maximum allowed complexity, as set by the MAX_QUERY_COMPLEXITY setting. By default, a Field is able to determine its complexity based on its reference. For example, a related field has a complexity of 1, and a regular model field has a complexity of 0. If you want to configure this manually, you can do so by adding the complexity argument to the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( complexity = 1 )","title":"Complexity"},{"location":"queries/#field-name","text":"A field_name can be provided to explicitly set the Django model field name that the Field corresponds to. This can be useful when you need multiple Fields for the same model field, or when the field has a different name and type in the GraphQL schema than in the model. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): title = Field ( field_name = \"name\" )","title":"Field name"},{"location":"queries/#schema-name_1","text":"A schema_name can be provided to override the name of the Field in the GraphQL schema. This can be useful for renaming fields for the schema, or when the desired name is a Python keyword and cannot be used as the Field attribute name. 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( schema_name = \"title\" )","title":"Schema name"},{"location":"queries/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Field as deprecated. This is for documentation purposes only, and does not affect the use of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"queries/#custom-resolvers","text":"Usually using a custom Field resolver is not necessary, and should be avoided if possible. This is because most modifications to resolvers can result in canceling query optimizations (see the optimizer section for details). You can override the resolver for a Field by adding a method to the class body of the QueryType and decorating it with the @<field_name>.resolve decorator. 1 2 3 4 5 6 7 8 9 10 11 from undine import Field , GQLInfo , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . resolve def resolve_name ( self , info : GQLInfo ) -> str : return self . name . upper () About method signature The decorated method is treated as a static method by the Field . The self argument is not an instance of the QueryType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for a Field is the model instance being queried. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation.","title":"Custom resolvers"},{"location":"queries/#custom-optimizations_1","text":"The optimizer is covered more thoroughly in the Optimizer section. Usually touching the Field optimizations is not necessary, but if required, you can do so by adding a method to the class body of the QueryType and decorating it with the @<field_name>.optimize decorator. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , GQLInfo , QueryType from undine.optimizer import OptimizationData from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . optimize def optimize_name ( self , data : OptimizationData , info : GQLInfo ) -> None : pass # Some optimization here This hook can be helpful when you require data from outside the GraphQL execution context to e.g. make permission checks.","title":"Custom optimizations"},{"location":"queries/#directives_1","text":"You can add directives to the Field by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Field , QueryType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): name = Field ( directives = [ MyDirective ()]) See the Directives section for more details on directives.","title":"Directives"},{"location":"queries/#visibility_1","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide a Field from certain users by adding the visible argument to the Field . Hiding a field means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Field , QueryType from undine.typing import DjangoRequestProtocol from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . visible def name_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"queries/#graphql-extensions_1","text":"You can provide custom extensions for the Field by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Field . 1 2 3 4 5 6 7 from undine import Field , QueryType from .models import Task class TaskType ( QueryType [ Task ]): name = Field ( extensions = { \"foo\" : \"bar\" }) Field extensions are made available in the GraphQL ObjectType extensions after the schema is created. The QueryType itself is found in the extensions under a key defined by the QUERY_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"scalars/","text":"Scalars \ud83d\udd17 In this section, we'll cover how GraphQL scalars work in Undine. Scalars are GraphQL types that represent concrete data types like strings, numbers, and booleans. Built-in Scalars \ud83d\udd17 In addition to GraphQL's built-in scalars of Int , Float , String , Boolean , and ID , Undine provides its own scalars that are useful for representing common data types in Python. Any \ud83d\udd17 Represent any value accepted by GraphQL. Used for e.g. for union types. Base16 \ud83d\udd17 Represents a base16-encoded string as defined in RFC 4648 . Base32 \ud83d\udd17 Represents a base32-encoded string as defined in RFC 4648 . Base64 \ud83d\udd17 Represents a base64-encoded string as defined in RFC 4648 . Date \ud83d\udd17 Represents a date value as specified by ISO 8601. Maps to the Python datetime.date type. See RFC 3339 . DateTime \ud83d\udd17 Represents a date and time value as specified by ISO 8601. Maps to the Python datetime.datetime type. See RFC 3339 . Decimal \ud83d\udd17 Represents a number as a string for correctly rounded floating point arithmetic. Maps to the Python decimal.Decimal type. Duration \ud83d\udd17 Represents a duration of time in seconds. Maps to the Python datetime.timedelta type. Email \ud83d\udd17 Represents a valid email address. See RFC 5322 . File \ud83d\udd17 Represents any kind of file. See the file upload section. IP \ud83d\udd17 Represents a valid IPv4 or IPv6 address. See RFC 8200 . and RFC 791 . IPv4 \ud83d\udd17 Represents a valid IPv4 address. See RFC 791 . IPv6 \ud83d\udd17 Represents a valid IPv6 address. See RFC 8200 . Image \ud83d\udd17 Represents an image file. See the file upload section. JSON \ud83d\udd17 Represents a JSON serializable object. Maps to the Python dict type. See RFC 8259 . Null \ud83d\udd17 Represents represents an always null value. Maps to the Python None value. Time \ud83d\udd17 Represents a time value as specified by ISO 8601. Maps to the Python datetime.time type. See RFC 3339 . URL \ud83d\udd17 Represents a valid URL. See RFC 3986 . UUID \ud83d\udd17 Represents a universally unique identifier string. Maps to Python's uuid.UUID type. See RFC 9562 . Modifying existing scalars \ud83d\udd17 All scalars have two functions that define its operation: parse and serialize These are used to parse incoming data to python types and serialize python data to GraphQL accepted types respectively. In Undine's additional built-in scalars, these functions are single dispatch generic functions . This means that we can register different implementations for the functions which are called depending on the type of the input value \u2014 think of it like a dynamic switch statement. This allows us to replace or extend the behavior of a scalar depending on our use case. For example, we might want to use the whenever library instead or in addition to python's built-in datetime . To do this, we can register a new implementation for the parse function of the DateTime scalar. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from whenever import Instant , PlainDateTime , ZonedDateTime from undine.scalars.datetime import datetime_scalar @datetime_scalar . parse . register def _ ( value : str ) -> ZonedDateTime : # Default \"str\" parse overridden to use 'whenever' return ZonedDateTime . parse_common_iso ( value ) @datetime_scalar . serialize . register def _ ( value : Instant | ZonedDateTime | PlainDateTime ) -> str : # Extend serialization with types from 'whenever'. # Same implementation for all types in the union return value . format_common_iso () Custom scalars \ud83d\udd17 We can also define our own scalars to represent types that cannot be represented by any of Undine's built-in scalars. Let's create a new scalar named Vector3 that represents a 3D vector using a tuple of three integers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from django.core.exceptions import ValidationError from undine.scalars import ScalarType Vector3 = tuple [ int , int , int ] # Create a new ScalarType for our custom scalar. # In `ScalarType[Vector3, str]`, the first type parameter is the type that # the scalar will parse to, and the second the type that it will serialize to. vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , ) # Create the GraphQLScalarType from graphql-core. # This is the actual scalar we can add to our schema. GraphQLVector3 = vector3_scalar . as_graphql_scalar () # Register the parse and serialize functions for our scalar. @vector3_scalar . parse . register def _ ( value : str ) -> Vector3 : try : x , y , z = value . split ( \",\" ) return int ( x . strip ()), int ( y . strip ()), int ( z . strip ()) except ValueError as error : msg = f \"Invalid vector format: { value } \" raise ValidationError ( msg ) from error @vector3_scalar . serialize . register def _ ( value : tuple ) -> str : if len ( value ) != 3 : msg = f \"Vector must have 3 components, got { len ( value ) } \" raise ValidationError ( msg ) if not isinstance ( value [ 0 ], int ): msg = f \"Vector component X is not an integer, got { value [ 0 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 1 ], int ): msg = f \"Vector component Y is not an integer, got { value [ 1 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 2 ], int ): msg = f \"Vector component Z is not an integer, got { value [ 2 ] } \" raise ValidationError ( msg ) return f \" { value [ 0 ] } , { value [ 1 ] } , { value [ 2 ] } \" If Vector3 corresponds to a Django model field, we could also let Undine know about it by registering it for its many built-in converters. This way a model field can be converted automatically to our scalar for QueryType Fields and MutationType Inputs . More on this in the \"Hacking Undine\" section.","title":"Scalars"},{"location":"scalars/#scalars","text":"In this section, we'll cover how GraphQL scalars work in Undine. Scalars are GraphQL types that represent concrete data types like strings, numbers, and booleans.","title":"Scalars"},{"location":"scalars/#built-in-scalars","text":"In addition to GraphQL's built-in scalars of Int , Float , String , Boolean , and ID , Undine provides its own scalars that are useful for representing common data types in Python.","title":"Built-in Scalars"},{"location":"scalars/#any","text":"Represent any value accepted by GraphQL. Used for e.g. for union types.","title":"Any"},{"location":"scalars/#base16","text":"Represents a base16-encoded string as defined in RFC 4648 .","title":"Base16"},{"location":"scalars/#base32","text":"Represents a base32-encoded string as defined in RFC 4648 .","title":"Base32"},{"location":"scalars/#base64","text":"Represents a base64-encoded string as defined in RFC 4648 .","title":"Base64"},{"location":"scalars/#date","text":"Represents a date value as specified by ISO 8601. Maps to the Python datetime.date type. See RFC 3339 .","title":"Date"},{"location":"scalars/#datetime","text":"Represents a date and time value as specified by ISO 8601. Maps to the Python datetime.datetime type. See RFC 3339 .","title":"DateTime"},{"location":"scalars/#decimal","text":"Represents a number as a string for correctly rounded floating point arithmetic. Maps to the Python decimal.Decimal type.","title":"Decimal"},{"location":"scalars/#duration","text":"Represents a duration of time in seconds. Maps to the Python datetime.timedelta type.","title":"Duration"},{"location":"scalars/#email","text":"Represents a valid email address. See RFC 5322 .","title":"Email"},{"location":"scalars/#file","text":"Represents any kind of file. See the file upload section.","title":"File"},{"location":"scalars/#ip","text":"Represents a valid IPv4 or IPv6 address. See RFC 8200 . and RFC 791 .","title":"IP"},{"location":"scalars/#ipv4","text":"Represents a valid IPv4 address. See RFC 791 .","title":"IPv4"},{"location":"scalars/#ipv6","text":"Represents a valid IPv6 address. See RFC 8200 .","title":"IPv6"},{"location":"scalars/#image","text":"Represents an image file. See the file upload section.","title":"Image"},{"location":"scalars/#json","text":"Represents a JSON serializable object. Maps to the Python dict type. See RFC 8259 .","title":"JSON"},{"location":"scalars/#null","text":"Represents represents an always null value. Maps to the Python None value.","title":"Null"},{"location":"scalars/#time","text":"Represents a time value as specified by ISO 8601. Maps to the Python datetime.time type. See RFC 3339 .","title":"Time"},{"location":"scalars/#url","text":"Represents a valid URL. See RFC 3986 .","title":"URL"},{"location":"scalars/#uuid","text":"Represents a universally unique identifier string. Maps to Python's uuid.UUID type. See RFC 9562 .","title":"UUID"},{"location":"scalars/#modifying-existing-scalars","text":"All scalars have two functions that define its operation: parse and serialize These are used to parse incoming data to python types and serialize python data to GraphQL accepted types respectively. In Undine's additional built-in scalars, these functions are single dispatch generic functions . This means that we can register different implementations for the functions which are called depending on the type of the input value \u2014 think of it like a dynamic switch statement. This allows us to replace or extend the behavior of a scalar depending on our use case. For example, we might want to use the whenever library instead or in addition to python's built-in datetime . To do this, we can register a new implementation for the parse function of the DateTime scalar. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from whenever import Instant , PlainDateTime , ZonedDateTime from undine.scalars.datetime import datetime_scalar @datetime_scalar . parse . register def _ ( value : str ) -> ZonedDateTime : # Default \"str\" parse overridden to use 'whenever' return ZonedDateTime . parse_common_iso ( value ) @datetime_scalar . serialize . register def _ ( value : Instant | ZonedDateTime | PlainDateTime ) -> str : # Extend serialization with types from 'whenever'. # Same implementation for all types in the union return value . format_common_iso ()","title":"Modifying existing scalars"},{"location":"scalars/#custom-scalars","text":"We can also define our own scalars to represent types that cannot be represented by any of Undine's built-in scalars. Let's create a new scalar named Vector3 that represents a 3D vector using a tuple of three integers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from django.core.exceptions import ValidationError from undine.scalars import ScalarType Vector3 = tuple [ int , int , int ] # Create a new ScalarType for our custom scalar. # In `ScalarType[Vector3, str]`, the first type parameter is the type that # the scalar will parse to, and the second the type that it will serialize to. vector3_scalar : ScalarType [ Vector3 , str ] = ScalarType ( name = \"Vector3\" , description = \"Represents a 3D vector as a string in format 'X,Y,Z'.\" , ) # Create the GraphQLScalarType from graphql-core. # This is the actual scalar we can add to our schema. GraphQLVector3 = vector3_scalar . as_graphql_scalar () # Register the parse and serialize functions for our scalar. @vector3_scalar . parse . register def _ ( value : str ) -> Vector3 : try : x , y , z = value . split ( \",\" ) return int ( x . strip ()), int ( y . strip ()), int ( z . strip ()) except ValueError as error : msg = f \"Invalid vector format: { value } \" raise ValidationError ( msg ) from error @vector3_scalar . serialize . register def _ ( value : tuple ) -> str : if len ( value ) != 3 : msg = f \"Vector must have 3 components, got { len ( value ) } \" raise ValidationError ( msg ) if not isinstance ( value [ 0 ], int ): msg = f \"Vector component X is not an integer, got { value [ 0 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 1 ], int ): msg = f \"Vector component Y is not an integer, got { value [ 1 ] } \" raise ValidationError ( msg ) if not isinstance ( value [ 2 ], int ): msg = f \"Vector component Z is not an integer, got { value [ 2 ] } \" raise ValidationError ( msg ) return f \" { value [ 0 ] } , { value [ 1 ] } , { value [ 2 ] } \" If Vector3 corresponds to a Django model field, we could also let Undine know about it by registering it for its many built-in converters. This way a model field can be converted automatically to our scalar for QueryType Fields and MutationType Inputs . More on this in the \"Hacking Undine\" section.","title":"Custom scalars"},{"location":"schema/","text":"Schema \ud83d\udd17 In this section, we'll cover how you can set up entrypoints to you GraphQL schema in Undine, expanding on the basics introduced in the Tutorial . RootTypes \ud83d\udd17 A GraphQL schema defines a RootType for each kind of operation that it supports. In GraphQL terms, a RootType is just a regular ObjectType that just happens to be the root of the GraphQL Schema. Let's take a look at the basic setup from the Tutorial . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" schema = create_schema ( query = Query ) Here you created the Query RootType . The Query RootType is required to be able to crate a GraphQL schema. Each RootType must also have at least one Entrypoint in its class body. As the name implies, the Query RootType is for querying data. For mutating data, you'd create a Mutation RootType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pathlib import Path from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" class Mutation ( RootType ): @Entrypoint def testing ( self ) -> int : return Path ( \"foo.txt\" ) . write_text ( \"Hello, World!\" , encoding = \"utf-8\" ) schema = create_schema ( query = Query , mutation = Mutation ) The Mutation RootType is optional, but if created, it must also include at least one Entrypoint , just like the Query RootType . For subscription support, see the Subscriptions section. Schema name \ud83d\udd17 By default, the name of the RootType type is the name of the created class. If you need to change this without changing the class name, you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , schema_name = \"MyQuery\" ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" Description \ud83d\udd17 To provide a description for the RootType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Entrypoint , RootType class Query ( RootType ): \"\"\"Operations for querying.\"\"\" @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" Directives \ud83d\udd17 You can add directives to the RootType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class Query ( RootType , directives = [ MyDirective ()]): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" See the Directives section for more details on directives. GraphQL extensions \ud83d\udd17 You can provide custom extensions for the RootType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the RootType . 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , extensions = { \"foo\" : \"bar\" }): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" RootType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The RootType itself is found in the extensions under a key defined by the ROOT_TYPE_EXTENSIONS_KEY setting. Entrypoints \ud83d\udd17 Entrypoints can be thought of as the \"API endpoints inside the GraphQL schema\" . They are the fields in a RootType from which you can execute operations like queries or mutations. An Entrypoint always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the operation. Function references \ud83d\udd17 Using a function/method as a reference is the most basic way of creating an Entrypoint . Function references can be used for both query and mutation Entrypoints . See the example from the Tutorial . 1 2 3 4 5 6 7 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint def testing ( self , info : GQLInfo ) -> str : return \"Hello World!\" With a function reference, the Entrypoint will use the decorated function as its GraphQL resolver. The function's return type will be used as the Entrypoint's output type, so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. You can add arguments to the Entrypoint by adding them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" This will add a non-null name string argument to the Entrypoint . Note that non-null arguments are required by GraphQL, so if you wanted to make the argument optional, you'd need to make it nullable (in which case it will be None by default) or add a default value ourselves. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str | None = None ) -> str : return f \"Hello, { name or 'World' } !\" You can add a description to the Entrypoint by adding a docstring to the method. If the method has arguments, you can add descriptions to those arguments by using reStructuredText docstrings format . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" What about other docstring formats? Other types of docstrings can be used by parsed by providing a custom parser to the DOCSTRING_PARSER setting that conforms to the DocstringParserProtocol from undine.typing . QueryType references \ud83d\udd17 A QueryType represents a GraphQL ObjectType for querying data from a Django model in the GraphQL schema. You should read more on QueryTypes in the Queries section since this section will only cover using them in Entrypoints . For querying a single model instance, simply use the QueryType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) This would create the following field in the Query RootType : 1 2 3 type Query { task ( pk : Int ! ) : TaskType } To query a list of model instances, simply add the many argument to the Entrypoint in addition to the QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) This would create the following field in the Query RootType : 1 2 3 type Query { tasks : [ TaskType !]! } If a FilterSet or an OrderSet has been added to your QueryType , those filters and orders will be added to the Entrypoint . 1 2 3 4 5 6 type Query { tasks ( filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): [ TaskType !]! } MutationType references \ud83d\udd17 A MutationType represents a possible mutation operation based on a Django model. You should read more on MutationTypes in the Mutations section since this section will only cover using them in Entrypoints . To create a mutation for a model instance (a create mutation in this example), simply use the MutationType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } To make this a bulk mutation, you can add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { bulkCreateTask ( input : [ TaskCreateMutation !]!): [ TaskType !]! } Note that the total amount of objects that can be mutated in a bulk mutation is limited by the MUTATION_INSTANCE_LIMIT setting. Schema name \ud83d\udd17 By default, the name of the Entrypoint is the name of the method or class attribute it's defined in. If you need to change this without changing the method or class attribute name, for example if the desired name is a Python keyword (e.g. if or from ), you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , schema_name = \"singleTask\" ) Description \ud83d\udd17 You can add a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , description = \"Fetch a single Task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) \"\"\"Fetch a single Task.\"\"\" If a description is not provided in these ways, the Entrypoint will try to determine a description from the given reference, e.g., for a method reference, it will use the method's docstring, or for a QueryType reference, it will use the QueryType's docstring. Many \ud83d\udd17 As seen in this section, the many argument is used to indicate whether the Entrypoint should return a non-null list of the referenced type. However, for for function references , the many argument is not required, as the Entrypoint can determine the this from the function's signature (i.e. whether it returns a list or not). Nullable \ud83d\udd17 By default, all Entrypoints are non-null (except for function references , which determine nullability from the function's signature). However, you can make an Entrypoint nullable explicitly by adding the nullable argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , nullable = True ) Limit \ud83d\udd17 The limit argument is used by list Entrypoints (i.e. many=True ) based on either QueryTypes , UnionTypes , or InterfaceTypes to limit the number of objects that are fetched. It has no effect on other Entrypoint references, like Connections . Permissions \ud83d\udd17 Usually, permissions for Entrypoints are checked using the QueryType or MutationType that the Entrypoint is added for. However, you can override these by decorating a method using the @<entrypoint_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : # Not called if 'TaskType' is accessed from 'Query.task' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) @task . permissions def task_permissions ( self , info : GQLInfo , instance : Task ) -> None : if info . context . user . is_authenticated : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Custom resolver \ud83d\udd17 Before overriding an Entrypoint 's resolver, you should check if QueryType filtering can be used instead. You can override the resolver for an Entrypoint by decorating a method using the @<entrypoint_name>.resolve decorator. This can be used, e.g., to add special-case Entrypoints for QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.optimizer.optimizer import optimize_sync from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task_by_name = Entrypoint ( TaskType , nullable = True ) @task_by_name . resolve def resolve_task_by_name ( self , info : GQLInfo , name : str ) -> Task | None : return optimize_sync ( Task . objects . all (), info , name = name ) About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Note that using this decorator, you'll override the resolver and arguments based on the reference used in the Entrypoint . Arguments will be taken from the additional arguments passed to the resolver, e.g., \"name\" in the example above. Be sure to call the optimizer, either directly or using the optimize_sync or optimize_async helper functions, to queries are optimized. Deprecation reason \ud83d\udd17 A deprecation_reason can be provided to mark the Entrypoint as deprecated. This is for documentation purposes only and does not affect the use of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , deprecation_reason = \"Use something else.\" ) Directives \ud83d\udd17 You can add directives to the Entrypoint by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , directives = [ MyDirective ()]) See the Directives section for more details on directives. Visibility \ud83d\udd17 This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Entrypoint from certain users by adding the visible argument to the Entrypoint . Hiding an entrypoint means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType from undine.typing import DjangoRequestProtocol class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" @testing . visible def testing_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser GraphQL extensions \ud83d\udd17 You can provide custom extensions for the Entrypoint by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , extensions = { \"foo\" : \"bar\" }) Entrypoint extensions are made available in the GraphQL field extensions after the schema is created. The Entrypoint itself is found in the extensions under a key defined by the ENTRYPOINT_EXTENSIONS_KEY setting. Schema export \ud83d\udd17 Undine includes a management command to export your GraphQL schema. 1 python manage.py print_schema > schema.graphql","title":"Schema"},{"location":"schema/#schema","text":"In this section, we'll cover how you can set up entrypoints to you GraphQL schema in Undine, expanding on the basics introduced in the Tutorial .","title":"Schema"},{"location":"schema/#roottypes","text":"A GraphQL schema defines a RootType for each kind of operation that it supports. In GraphQL terms, a RootType is just a regular ObjectType that just happens to be the root of the GraphQL Schema. Let's take a look at the basic setup from the Tutorial . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" schema = create_schema ( query = Query ) Here you created the Query RootType . The Query RootType is required to be able to crate a GraphQL schema. Each RootType must also have at least one Entrypoint in its class body. As the name implies, the Query RootType is for querying data. For mutating data, you'd create a Mutation RootType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pathlib import Path from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" class Mutation ( RootType ): @Entrypoint def testing ( self ) -> int : return Path ( \"foo.txt\" ) . write_text ( \"Hello, World!\" , encoding = \"utf-8\" ) schema = create_schema ( query = Query , mutation = Mutation ) The Mutation RootType is optional, but if created, it must also include at least one Entrypoint , just like the Query RootType . For subscription support, see the Subscriptions section.","title":"RootTypes"},{"location":"schema/#schema-name","text":"By default, the name of the RootType type is the name of the created class. If you need to change this without changing the class name, you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , schema_name = \"MyQuery\" ): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\"","title":"Schema name"},{"location":"schema/#description","text":"To provide a description for the RootType , you can add a docstring to the class. 1 2 3 4 5 6 7 8 9 from undine import Entrypoint , RootType class Query ( RootType ): \"\"\"Operations for querying.\"\"\" @Entrypoint def testing ( self ) -> str : return \"Hello, World!\"","title":"Description"},{"location":"schema/#directives","text":"You can add directives to the RootType by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 from graphql import DirectiveLocation from undine import Entrypoint , RootType from undine.directives import Directive class MyDirective ( Directive , locations = [ DirectiveLocation . OBJECT ]): ... class Query ( RootType , directives = [ MyDirective ()]): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" See the Directives section for more details on directives.","title":"Directives"},{"location":"schema/#graphql-extensions","text":"You can provide custom extensions for the RootType by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the RootType . 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType , extensions = { \"foo\" : \"bar\" }): @Entrypoint def testing ( self ) -> str : return \"Hello, World!\" RootType extensions are made available in the GraphQL ObjectType extensions after the schema is created. The RootType itself is found in the extensions under a key defined by the ROOT_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"schema/#entrypoints","text":"Entrypoints can be thought of as the \"API endpoints inside the GraphQL schema\" . They are the fields in a RootType from which you can execute operations like queries or mutations. An Entrypoint always requires a reference from which it will create the proper GraphQL resolver, output type, and arguments for the operation.","title":"Entrypoints"},{"location":"schema/#function-references","text":"Using a function/method as a reference is the most basic way of creating an Entrypoint . Function references can be used for both query and mutation Entrypoints . See the example from the Tutorial . 1 2 3 4 5 6 7 from undine import Entrypoint , GQLInfo , RootType class Query ( RootType ): @Entrypoint def testing ( self , info : GQLInfo ) -> str : return \"Hello World!\" With a function reference, the Entrypoint will use the decorated function as its GraphQL resolver. The function's return type will be used as the Entrypoint's output type, so typing it is required. You can even use a TypedDict to return an object with multiple fields. About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. You can add arguments to the Entrypoint by adding them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" This will add a non-null name string argument to the Entrypoint . Note that non-null arguments are required by GraphQL, so if you wanted to make the argument optional, you'd need to make it nullable (in which case it will be None by default) or add a default value ourselves. 1 2 3 4 5 6 7 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str | None = None ) -> str : return f \"Hello, { name or 'World' } !\" You can add a description to the Entrypoint by adding a docstring to the method. If the method has arguments, you can add descriptions to those arguments by using reStructuredText docstrings format . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : \"\"\" Return a greeting. :param name: The name to greet. \"\"\" return f \"Hello, { name } !\" What about other docstring formats? Other types of docstrings can be used by parsed by providing a custom parser to the DOCSTRING_PARSER setting that conforms to the DocstringParserProtocol from undine.typing .","title":"Function references"},{"location":"schema/#querytype-references","text":"A QueryType represents a GraphQL ObjectType for querying data from a Django model in the GraphQL schema. You should read more on QueryTypes in the Queries section since this section will only cover using them in Entrypoints . For querying a single model instance, simply use the QueryType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) This would create the following field in the Query RootType : 1 2 3 type Query { task ( pk : Int ! ) : TaskType } To query a list of model instances, simply add the many argument to the Entrypoint in addition to the QueryType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Entrypoint , Field , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): tasks = Entrypoint ( TaskType , many = True ) This would create the following field in the Query RootType : 1 2 3 type Query { tasks : [ TaskType !]! } If a FilterSet or an OrderSet has been added to your QueryType , those filters and orders will be added to the Entrypoint . 1 2 3 4 5 6 type Query { tasks ( filter : TaskFilterSet orderBy : [ TaskOrderSet !] ): [ TaskType !]! }","title":"QueryType references"},{"location":"schema/#mutationtype-references","text":"A MutationType represents a possible mutation operation based on a Django model. You should read more on MutationTypes in the Mutations section since this section will only cover using them in Entrypoints . To create a mutation for a model instance (a create mutation in this example), simply use the MutationType class as the reference for the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { createTask ( input : TaskCreateMutation ! ) : TaskType ! } To make this a bulk mutation, you can add the many argument to the Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) This would create the following field in the Mutation RootType : 1 2 3 type Mutation { bulkCreateTask ( input : [ TaskCreateMutation !]!): [ TaskType !]! } Note that the total amount of objects that can be mutated in a bulk mutation is limited by the MUTATION_INSTANCE_LIMIT setting.","title":"MutationType references"},{"location":"schema/#schema-name_1","text":"By default, the name of the Entrypoint is the name of the method or class attribute it's defined in. If you need to change this without changing the method or class attribute name, for example if the desired name is a Python keyword (e.g. if or from ), you can do so by providing the schema_name argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , schema_name = \"singleTask\" )","title":"Schema name"},{"location":"schema/#description_1","text":"You can add a description in one of two ways: 1) By setting the description argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , description = \"Fetch a single Task.\" ) 2) As class attribute docstrings, if ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS is enabled. 1 2 3 4 5 6 7 8 9 10 11 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType ) \"\"\"Fetch a single Task.\"\"\" If a description is not provided in these ways, the Entrypoint will try to determine a description from the given reference, e.g., for a method reference, it will use the method's docstring, or for a QueryType reference, it will use the QueryType's docstring.","title":"Description"},{"location":"schema/#many","text":"As seen in this section, the many argument is used to indicate whether the Entrypoint should return a non-null list of the referenced type. However, for for function references , the many argument is not required, as the Entrypoint can determine the this from the function's signature (i.e. whether it returns a list or not).","title":"Many"},{"location":"schema/#nullable","text":"By default, all Entrypoints are non-null (except for function references , which determine nullability from the function's signature). However, you can make an Entrypoint nullable explicitly by adding the nullable argument. 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , nullable = True )","title":"Nullable"},{"location":"schema/#limit","text":"The limit argument is used by list Entrypoints (i.e. many=True ) based on either QueryTypes , UnionTypes , or InterfaceTypes to limit the number of objects that are fetched. It has no effect on other Entrypoint references, like Connections .","title":"Limit"},{"location":"schema/#permissions","text":"Usually, permissions for Entrypoints are checked using the QueryType or MutationType that the Entrypoint is added for. However, you can override these by decorating a method using the @<entrypoint_name>.permissions decorator. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : # Not called if 'TaskType' is accessed from 'Query.task' # because it has a permissions check already if not info . context . user . is_superuser : raise GraphQLPermissionError class Query ( RootType ): task = Entrypoint ( TaskType ) @task . permissions def task_permissions ( self , info : GQLInfo , instance : Task ) -> None : if info . context . user . is_authenticated : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg )","title":"Permissions"},{"location":"schema/#custom-resolver","text":"Before overriding an Entrypoint 's resolver, you should check if QueryType filtering can be used instead. You can override the resolver for an Entrypoint by decorating a method using the @<entrypoint_name>.resolve decorator. This can be used, e.g., to add special-case Entrypoints for QueryTypes . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Entrypoint , GQLInfo , QueryType , RootType from undine.optimizer.optimizer import optimize_sync from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task_by_name = Entrypoint ( TaskType , nullable = True ) @task_by_name . resolve def resolve_task_by_name ( self , info : GQLInfo , name : str ) -> Task | None : return optimize_sync ( Task . objects . all (), info , name = name ) About method signature The decorated method is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. Note that using this decorator, you'll override the resolver and arguments based on the reference used in the Entrypoint . Arguments will be taken from the additional arguments passed to the resolver, e.g., \"name\" in the example above. Be sure to call the optimizer, either directly or using the optimize_sync or optimize_async helper functions, to queries are optimized.","title":"Custom resolver"},{"location":"schema/#deprecation-reason","text":"A deprecation_reason can be provided to mark the Entrypoint as deprecated. This is for documentation purposes only and does not affect the use of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , deprecation_reason = \"Use something else.\" )","title":"Deprecation reason"},{"location":"schema/#directives_1","text":"You can add directives to the Entrypoint by providing them using the directives argument. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from graphql import DirectiveLocation from undine import Entrypoint , QueryType , RootType from undine.directives import Directive from .models import Task class MyDirective ( Directive , locations = [ DirectiveLocation . FIELD_DEFINITION ]): ... class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , directives = [ MyDirective ()]) See the Directives section for more details on directives.","title":"Directives"},{"location":"schema/#visibility","text":"This is an experimental feature that needs to be enabled using the EXPERIMENTAL_VISIBILITY_CHECKS setting. You can hide an Entrypoint from certain users by adding the visible argument to the Entrypoint . Hiding an entrypoint means that it will not be included in introspection queries for that user, and it cannot be used in operations by that user. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import Entrypoint , RootType from undine.typing import DjangoRequestProtocol class Query ( RootType ): @Entrypoint def testing ( self , name : str ) -> str : return f \"Hello, { name } !\" @testing . visible def testing_visible ( self , request : DjangoRequestProtocol ) -> bool : return request . user . is_superuser","title":"Visibility"},{"location":"schema/#graphql-extensions_1","text":"You can provide custom extensions for the Entrypoint by providing a extensions argument with a dictionary containing them. These can then be used however you wish to extend the functionality of the Entrypoint . 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , QueryType , RootType from .models import Task class TaskType ( QueryType [ Task ]): ... class Query ( RootType ): task = Entrypoint ( TaskType , extensions = { \"foo\" : \"bar\" }) Entrypoint extensions are made available in the GraphQL field extensions after the schema is created. The Entrypoint itself is found in the extensions under a key defined by the ENTRYPOINT_EXTENSIONS_KEY setting.","title":"GraphQL extensions"},{"location":"schema/#schema-export","text":"Undine includes a management command to export your GraphQL schema. 1 python manage.py print_schema > schema.graphql","title":"Schema export"},{"location":"settings/","text":"Settings \ud83d\udd17 In this section, we'll cover the settings that can be used to customize Undine. Settings should be set in a dictionary named UNDINE in your settings file, unless otherwise specified. The settings can also be found in the settings file . 1 2 3 UNDINE = { # Settings go here } ADDITIONAL_VALIDATION_RULES Type: list[type[ASTValidationRule]] | Default: [] Additional validation rules to use for validating the GraphQL schema. Values should be given as the dotted paths to the validation rules used. ALLOW_DID_YOU_MEAN_SUGGESTIONS Type: bool | Default: False Whether to allow the 'did you mean' suggestions on error messages. ALLOW_INTROSPECTION_QUERIES Type bool | Default: False Whether schema introspection queries are allowed or not. Should set this to True if using GraphiQL. ASYNC Type bool | Default: False Whether to use async view for the GraphQL endpoint or not. Allows using async resolvers for Fields and Entrypoints . See Async Support for more information. AUTOGENERATION Type bool | Default: True Whether to automatically generate Fields for QueryTypes , Inputs for MutationTypes , Filters for FilterSets , and Orders for OrderSets . Can also be set on an individual QueryType , MutationType , FilterSet , and OrderSet classes. CALCULATION_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_calculation_argument\" The key used to store a CalculationArgument in the extensions of the GraphQLArgument . CAMEL_CASE_SCHEMA_FIELDS Type: bool | Default: True Should names be converted from 'snake_case' to 'camelCase' for the GraphQL schema? Conversion is not applied if schema_name is set manually. CONNECTION_EXTENSIONS_KEY Type: str | Default: \"undine_connection\" The key used to store a Connection in the extensions of the GraphQLObjectType . CONNECTION_INDEX_KEY Type: str | Default: \"_undine_pagination_index\" The key to which a nested connection's pagination indexes are annotated to. CONNECTION_PAGE_SIZE Type: int | Default: 100 The maximum number of items to return from a Connection at a time. CONNECTION_START_INDEX_KEY Type: str | Default: \"_undine_pagination_start\" The key to which a nested connection's pagination start indexes are annotated to. CONNECTION_STOP_INDEX_KEY Type: str | Default: \"_undine_pagination_stop\" The key to which a nested connection's pagination stop indexes are annotated to. CONNECTION_TOTAL_COUNT_KEY Type: str | Default: \"_undine_pagination_total_count\" The key to which a nested connection's total counts are annotated to. DIRECTIVE_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_directive_argument\" The key used to store a DirectiveArgument in the extensions of the GraphQLArgument . DIRECTIVE_EXTENSIONS_KEY Type str | Default: \"undine_directive\" The key used to store a Directive in the extensions of the GraphQLDirective . DISABLE_ONLY_FIELDS_OPTIMIZATION Type bool | Default: False Disable optimizing fetched fields with queryset.only() . DOCSTRING_PARSER Type type[DocstringParserProtocol] | Default: \"undine.parsers.parse_docstring.RSTDocstringParser\" The docstring parser to use. Should be given as the dotted path to the docstring parser class. EMPTY_VALUES Type Container[Any] | Default: (None, \"\", [], {}) By default, if a Filter receives any of these values, it will be ignored. Can be changed on per-filter basis using the empty_values argument. ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS Type bool | Default: False Whether to parse class attribute docstrings or not. Disabled by default to improve performance of the schema creation. ENTRYPOINT_EXTENSIONS_KEY Type str | Default: \"undine_entrypoint\" The key used to store an Entrypoint in the extensions of the GraphQLField . LIST_ENTRYPOINT_LIMIT Type int | None | Default: None Default number of objects that are fetched per model when fetching results from a list Entrypoint (not Connections). If None, all items are fetched. EXECUTION_CONTEXT_CLASS Type type[UndineExecutionContext] | Default: \"undine.execution.UndineExecutionContext\" GraphQL execution context class used by the schema. Should be given as the dotted path to the execution context class. EXECUTION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during execution phase the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. EXPERIMENTAL_VISIBILITY_CHECKS Type: bool | Default: False Whether to enable experimental visibility checks. When enabled, parts of the schema can be hidden from certain users according to specified visibility checks. When a field is not visible to a user, it will not be included in introspection queries and it cannot be used in operations. Note that visibility does not affect \"did you mean\" suggestions, so it is advised to disable these using ALLOW_DID_YOU_MEAN_SUGGESTIONS when using this feature. FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_field\" The key used to store a Field in the extensions of the GraphQLField . FILE_UPLOAD_ENABLED Type: bool | Default: False Whether file uploads are enabled. Should enable CSRF protection on the GraphiQL endpoint if enabled. See file uploads for more information. FILTER_EXTENSIONS_KEY Type: str | Default: \"undine_filter\" The key used to store a Filter in the extensions of the GraphQLInputField . FILTERSET_EXTENSIONS_KEY Type: str | Default: \"undine_filterset\" The key used to store a FilterSet in the extensions of the GraphQLInputObjectType . GRAPHIQL_ENABLED Type: bool | Default: False Whether to enable GraphiQL. Should also set ALLOW_INTROSPECTION_QUERIES to True , so that GraphiQL can introspect the GraphQL schema. GRAPHQL_PATH Type: str | Default: \"graphql/\" The URL path where the GraphQL endpoint is located if it's included using path(\"\", include(\"undine.http.urls\")) . GRAPHQL_VIEW_NAME Type: str | Default: \"graphql\" The name given to the GraphQL view in Django's URL resolvers if it's included using path(\"\", include(\"undine.http.urls\")) . INCLUDE_ERROR_TRACEBACK Type: bool | Default: False Whether to include the error traceback in the response error extensions. INPUT_EXTENSIONS_KEY Type: str | Default: \"undine_input\" The key used to store an Input in the extensions of the GraphQLInputField . INTERFACE_FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_interface_field\" The key used to store an InterfaceField in the extensions of the GraphQLField . INTERFACE_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_interface\" The key used to store a InterfaceType in the extensions of the GraphQLInterfaceType . MAX_ALLOWED_ALIASES Type: int | Default: 15 The maximum number of aliases allowed in a single operation. MAX_ALLOWED_DIRECTIVES Type: int | Default: 50 The maximum number of directives allowed in a single operation. MAX_ERRORS Type: int | Default: 100 The maximum number of validation errors allowed in a GraphQL request before it is rejected, even if validation is still not complete. MAX_FILTERS_PER_TYPE Type: int | Default: 20 The maximum number of filters allowed to be used for filtering a single QueryType . MAX_ORDERS_PER_TYPE Type: int | Default: 10 The maximum number of orderings allowed to be used for ordering a single QueryType . MAX_QUERY_COMPLEXITY Type: int | Default: 10 Maximum query complexity that is allowed to be queried in a single operation. MAX_TOKENS Type int | Default: None Maximum number of GraphQL document tokens the GraphQL parser will parse before it rejects a request. By default, this is set to None which means no limit. MIDDLEWARE Type: list[type[GraphQLFieldResolver]] | Default: [] Middleware to use during GraphQL field resolving. See Custom Middleware in the GraphQL-core documentation for more information. MODELTRANSLATION_INCLUDE_TRANSLATABLE Type: bool | Default: False Whether to add translatable fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MODELTRANSLATION_INCLUDE_TRANSLATIONS Type: bool | Default: True Whether to add translation fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MUTATION_FULL_CLEAN Type: bool | Default: True Whether to run model.full_clean() when mutating a model. Turning this off can reduce the number of database queries during mutations, but may introduce issues that would be solved by running full model validation. MUTATION_INSTANCE_LIMIT Type: int | Default: 100 The maximum number of objects that can be mutated in a single mutation. MUTATION_INPUT_DATA_KEY Type: str | Default: \"input\" The key that the input argument based on a MutationType is added to when said MutationType is used in Entrypoints . MUTATION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_mutation_type\" The key used to store a MutationType in the extensions of the GraphQLInputObjectType . NO_ERROR_LOCATION Type: bool | Default: False Whether to remove error location information to GraphQL errors. OPERATION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run encompassing the entire GraphQL operation. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. OPTIMIZER_CLASS Type: type[QueryOptimizer] | Default: \"undine.optimizer.optimizer.QueryOptimizer\" The optimizer class to use for optimizing queries. Value should be given as the dotted path to the optimizer class. ORDER_EXTENSIONS_KEY Type: str | Default: \"undine_order\" The key used to store an Order in the extensions of the GraphQLEnumValue . ORDERSET_EXTENSIONS_KEY Type: str | Default: \"undine_orderset\" The key used to store a OrderSet in the extensions of the GraphQLEnumType . PARSE_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during parsing phase of a GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. PERSISTED_DOCUMENTS_ONLY Type: bool | Default: False Whether to only allow persisted documents to be executed in the GraphQL API. PERSISTED_DOCUMENTS_PATH Type: str | Default: \"persisted-documents/\" The path where the persisted documents registration endpoint is located by default. PERSISTED_DOCUMENTS_PERMISSION_CALLBACK Type: PersistedDocumentsPermissionsCallback | Default: undine.persisted_documents.utils.default_permission_callback The function to use for permission checks for registration of persisted documents. PERSISTED_DOCUMENTS_VIEW_NAME Type: str | Default: \"persisted_documents\" The name of given to the persisted documents registration view in the URLconf. PG_TEXT_SEARCH_PREFIX Type: str | Default: \"_undine_ts_vector\" A prefix to use for the filter aliases of postgres full text search Filters. PREFETCH_HACK_CACHE_KEY Type: str | Default: \"_undine_prefetch_hack_cache\" The key to use for storing the prefetch hack cache in the queryset hints. QUERY_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_query_type\" The key used to store a QueryType in the extensions of the GraphQLObjectType . QUERY_TYPE_FILTER_INPUT_KEY Type: str | Default: \"filter\" The key that the input argument based on a FilterSet of a QueryType is added to when said QueryType is used in list Entrypoints or \"to-many\" related Fields . QUERY_TYPE_ORDER_INPUT_KEY Type: str | Default: \"orderBy\" The key that the input argument based on an OrderSet of a QueryType is added to when said QueryType is used in list Entrypoints or \"to-many\" related Fields . RESOLVER_ROOT_PARAM_NAME Type: str | Default: \"root\" The name of the root/parent parameter in Field / Entrypoint resolvers. ROOT_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_root_type\" The key used to store a RootType in the extensions of the GraphQLObjectType . ROOT_VALUE Type: Any | Default: None The root value for the GraphQL execution. Can be accessed by Entrypoint resolvers from the root argument. SCALAR_EXTENSIONS_KEY Type: str | Default: \"undine_scalar\" The key used to store a Undine ScalarType in the extensions of the GraphQLScalarType . SCHEMA Type: GraphQLSchema | Default: \"undine.settings.example_schema\" The file and variable where the GraphQL Schema for Undine is located. Value should be given as the dotted path, usually created using undine.schema.create_schema . SCHEMA_DIRECTIVES_EXTENSIONS_KEY Type: str | Default: \"undine_schema_directives\" The key used to store the schema definition directives in the extensions of the GraphQLSchema . SDL_PRINTER Type: type[SDLPrinter] | Default: \"undine.utils.graphql.sdl_printer.SDLPrinter\" The SDL printer to use. Value should be given as the dotted path to the SDL printer class. TESTING_CLIENT_FULL_STACKTRACE Type: bool | Default: False Whether to include the full stacktrace in testing client instead of just the relevant frames when checking where SQL queries are made. TOTAL_COUNT_PARAM_NAME Type: str | Default: \"totalCount\" The name of the parameter in a connection ObjectType for holding the count for the total number of items that can be queried from the connection. UNDINE_PERSISTED_DOCUMENTS_MODEL Type: type[Model] | Default: \"undine.persisted_documents.models.PersistedDocument\" NOTE : This setting should be set in the top level of the settings file, not in the UNDINE dictionary! The model to use for the PersistedDocument model. Works similarly to AUTH_USER_MODEL , so must be set before running migrations for the persisted documents app. UNION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_union_type\" The key used to store a Undine UnionType in the extensions of the GraphQLUnion . VALIDATION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during validation the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. WEBSOCKET_CONNECTION_INIT_HOOK Type: WebSocketConnectionInitHook | Default: \"undine.utils.graphql.websocket.connection_init_hook\" The function to use for custom ConnectionInit logic. Value should be given as the dotted path to the function. WEBSOCKET_CONNECTION_INIT_TIMEOUT_SECONDS Type: int | Default: 3 The number of seconds to wait for the ConnectionInit message after opening a WebSocket before closing it. WEBSOCKET_PATH Type: str | Default: \"graphql/\" The path where the GraphQL over WebSocket endpoint is located if using undine.integrations.channels.get_websocket_enabled_app . WEBSOCKET_PING_HOOK Type: WebSocketConnectionPingHook | Default: \"undine.utils.graphql.websocket.ping_hook\" The function for specifying custom Ping message logic. Value should be given as the dotted path to the function. WEBSOCKET_PONG_HOOK Type: WebSocketConnectionPongHook | Default: \"undine.utils.graphql.websocket.pong_hook\" The function to for specifying custom Pong message logic. Value should be given as the dotted path to the function.","title":"Settings"},{"location":"settings/#settings","text":"In this section, we'll cover the settings that can be used to customize Undine. Settings should be set in a dictionary named UNDINE in your settings file, unless otherwise specified. The settings can also be found in the settings file . 1 2 3 UNDINE = { # Settings go here } ADDITIONAL_VALIDATION_RULES Type: list[type[ASTValidationRule]] | Default: [] Additional validation rules to use for validating the GraphQL schema. Values should be given as the dotted paths to the validation rules used. ALLOW_DID_YOU_MEAN_SUGGESTIONS Type: bool | Default: False Whether to allow the 'did you mean' suggestions on error messages. ALLOW_INTROSPECTION_QUERIES Type bool | Default: False Whether schema introspection queries are allowed or not. Should set this to True if using GraphiQL. ASYNC Type bool | Default: False Whether to use async view for the GraphQL endpoint or not. Allows using async resolvers for Fields and Entrypoints . See Async Support for more information. AUTOGENERATION Type bool | Default: True Whether to automatically generate Fields for QueryTypes , Inputs for MutationTypes , Filters for FilterSets , and Orders for OrderSets . Can also be set on an individual QueryType , MutationType , FilterSet , and OrderSet classes. CALCULATION_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_calculation_argument\" The key used to store a CalculationArgument in the extensions of the GraphQLArgument . CAMEL_CASE_SCHEMA_FIELDS Type: bool | Default: True Should names be converted from 'snake_case' to 'camelCase' for the GraphQL schema? Conversion is not applied if schema_name is set manually. CONNECTION_EXTENSIONS_KEY Type: str | Default: \"undine_connection\" The key used to store a Connection in the extensions of the GraphQLObjectType . CONNECTION_INDEX_KEY Type: str | Default: \"_undine_pagination_index\" The key to which a nested connection's pagination indexes are annotated to. CONNECTION_PAGE_SIZE Type: int | Default: 100 The maximum number of items to return from a Connection at a time. CONNECTION_START_INDEX_KEY Type: str | Default: \"_undine_pagination_start\" The key to which a nested connection's pagination start indexes are annotated to. CONNECTION_STOP_INDEX_KEY Type: str | Default: \"_undine_pagination_stop\" The key to which a nested connection's pagination stop indexes are annotated to. CONNECTION_TOTAL_COUNT_KEY Type: str | Default: \"_undine_pagination_total_count\" The key to which a nested connection's total counts are annotated to. DIRECTIVE_ARGUMENT_EXTENSIONS_KEY Type: str | Default: \"undine_directive_argument\" The key used to store a DirectiveArgument in the extensions of the GraphQLArgument . DIRECTIVE_EXTENSIONS_KEY Type str | Default: \"undine_directive\" The key used to store a Directive in the extensions of the GraphQLDirective . DISABLE_ONLY_FIELDS_OPTIMIZATION Type bool | Default: False Disable optimizing fetched fields with queryset.only() . DOCSTRING_PARSER Type type[DocstringParserProtocol] | Default: \"undine.parsers.parse_docstring.RSTDocstringParser\" The docstring parser to use. Should be given as the dotted path to the docstring parser class. EMPTY_VALUES Type Container[Any] | Default: (None, \"\", [], {}) By default, if a Filter receives any of these values, it will be ignored. Can be changed on per-filter basis using the empty_values argument. ENABLE_CLASS_ATTRIBUTE_DOCSTRINGS Type bool | Default: False Whether to parse class attribute docstrings or not. Disabled by default to improve performance of the schema creation. ENTRYPOINT_EXTENSIONS_KEY Type str | Default: \"undine_entrypoint\" The key used to store an Entrypoint in the extensions of the GraphQLField . LIST_ENTRYPOINT_LIMIT Type int | None | Default: None Default number of objects that are fetched per model when fetching results from a list Entrypoint (not Connections). If None, all items are fetched. EXECUTION_CONTEXT_CLASS Type type[UndineExecutionContext] | Default: \"undine.execution.UndineExecutionContext\" GraphQL execution context class used by the schema. Should be given as the dotted path to the execution context class. EXECUTION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during execution phase the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. EXPERIMENTAL_VISIBILITY_CHECKS Type: bool | Default: False Whether to enable experimental visibility checks. When enabled, parts of the schema can be hidden from certain users according to specified visibility checks. When a field is not visible to a user, it will not be included in introspection queries and it cannot be used in operations. Note that visibility does not affect \"did you mean\" suggestions, so it is advised to disable these using ALLOW_DID_YOU_MEAN_SUGGESTIONS when using this feature. FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_field\" The key used to store a Field in the extensions of the GraphQLField . FILE_UPLOAD_ENABLED Type: bool | Default: False Whether file uploads are enabled. Should enable CSRF protection on the GraphiQL endpoint if enabled. See file uploads for more information. FILTER_EXTENSIONS_KEY Type: str | Default: \"undine_filter\" The key used to store a Filter in the extensions of the GraphQLInputField . FILTERSET_EXTENSIONS_KEY Type: str | Default: \"undine_filterset\" The key used to store a FilterSet in the extensions of the GraphQLInputObjectType . GRAPHIQL_ENABLED Type: bool | Default: False Whether to enable GraphiQL. Should also set ALLOW_INTROSPECTION_QUERIES to True , so that GraphiQL can introspect the GraphQL schema. GRAPHQL_PATH Type: str | Default: \"graphql/\" The URL path where the GraphQL endpoint is located if it's included using path(\"\", include(\"undine.http.urls\")) . GRAPHQL_VIEW_NAME Type: str | Default: \"graphql\" The name given to the GraphQL view in Django's URL resolvers if it's included using path(\"\", include(\"undine.http.urls\")) . INCLUDE_ERROR_TRACEBACK Type: bool | Default: False Whether to include the error traceback in the response error extensions. INPUT_EXTENSIONS_KEY Type: str | Default: \"undine_input\" The key used to store an Input in the extensions of the GraphQLInputField . INTERFACE_FIELD_EXTENSIONS_KEY Type: str | Default: \"undine_interface_field\" The key used to store an InterfaceField in the extensions of the GraphQLField . INTERFACE_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_interface\" The key used to store a InterfaceType in the extensions of the GraphQLInterfaceType . MAX_ALLOWED_ALIASES Type: int | Default: 15 The maximum number of aliases allowed in a single operation. MAX_ALLOWED_DIRECTIVES Type: int | Default: 50 The maximum number of directives allowed in a single operation. MAX_ERRORS Type: int | Default: 100 The maximum number of validation errors allowed in a GraphQL request before it is rejected, even if validation is still not complete. MAX_FILTERS_PER_TYPE Type: int | Default: 20 The maximum number of filters allowed to be used for filtering a single QueryType . MAX_ORDERS_PER_TYPE Type: int | Default: 10 The maximum number of orderings allowed to be used for ordering a single QueryType . MAX_QUERY_COMPLEXITY Type: int | Default: 10 Maximum query complexity that is allowed to be queried in a single operation. MAX_TOKENS Type int | Default: None Maximum number of GraphQL document tokens the GraphQL parser will parse before it rejects a request. By default, this is set to None which means no limit. MIDDLEWARE Type: list[type[GraphQLFieldResolver]] | Default: [] Middleware to use during GraphQL field resolving. See Custom Middleware in the GraphQL-core documentation for more information. MODELTRANSLATION_INCLUDE_TRANSLATABLE Type: bool | Default: False Whether to add translatable fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MODELTRANSLATION_INCLUDE_TRANSLATIONS Type: bool | Default: True Whether to add translation fields to the GraphQL schema when using django-modeltranslation . See the integration description for more information. MUTATION_FULL_CLEAN Type: bool | Default: True Whether to run model.full_clean() when mutating a model. Turning this off can reduce the number of database queries during mutations, but may introduce issues that would be solved by running full model validation. MUTATION_INSTANCE_LIMIT Type: int | Default: 100 The maximum number of objects that can be mutated in a single mutation. MUTATION_INPUT_DATA_KEY Type: str | Default: \"input\" The key that the input argument based on a MutationType is added to when said MutationType is used in Entrypoints . MUTATION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_mutation_type\" The key used to store a MutationType in the extensions of the GraphQLInputObjectType . NO_ERROR_LOCATION Type: bool | Default: False Whether to remove error location information to GraphQL errors. OPERATION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run encompassing the entire GraphQL operation. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. OPTIMIZER_CLASS Type: type[QueryOptimizer] | Default: \"undine.optimizer.optimizer.QueryOptimizer\" The optimizer class to use for optimizing queries. Value should be given as the dotted path to the optimizer class. ORDER_EXTENSIONS_KEY Type: str | Default: \"undine_order\" The key used to store an Order in the extensions of the GraphQLEnumValue . ORDERSET_EXTENSIONS_KEY Type: str | Default: \"undine_orderset\" The key used to store a OrderSet in the extensions of the GraphQLEnumType . PARSE_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during parsing phase of a GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. PERSISTED_DOCUMENTS_ONLY Type: bool | Default: False Whether to only allow persisted documents to be executed in the GraphQL API. PERSISTED_DOCUMENTS_PATH Type: str | Default: \"persisted-documents/\" The path where the persisted documents registration endpoint is located by default. PERSISTED_DOCUMENTS_PERMISSION_CALLBACK Type: PersistedDocumentsPermissionsCallback | Default: undine.persisted_documents.utils.default_permission_callback The function to use for permission checks for registration of persisted documents. PERSISTED_DOCUMENTS_VIEW_NAME Type: str | Default: \"persisted_documents\" The name of given to the persisted documents registration view in the URLconf. PG_TEXT_SEARCH_PREFIX Type: str | Default: \"_undine_ts_vector\" A prefix to use for the filter aliases of postgres full text search Filters. PREFETCH_HACK_CACHE_KEY Type: str | Default: \"_undine_prefetch_hack_cache\" The key to use for storing the prefetch hack cache in the queryset hints. QUERY_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_query_type\" The key used to store a QueryType in the extensions of the GraphQLObjectType . QUERY_TYPE_FILTER_INPUT_KEY Type: str | Default: \"filter\" The key that the input argument based on a FilterSet of a QueryType is added to when said QueryType is used in list Entrypoints or \"to-many\" related Fields . QUERY_TYPE_ORDER_INPUT_KEY Type: str | Default: \"orderBy\" The key that the input argument based on an OrderSet of a QueryType is added to when said QueryType is used in list Entrypoints or \"to-many\" related Fields . RESOLVER_ROOT_PARAM_NAME Type: str | Default: \"root\" The name of the root/parent parameter in Field / Entrypoint resolvers. ROOT_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_root_type\" The key used to store a RootType in the extensions of the GraphQLObjectType . ROOT_VALUE Type: Any | Default: None The root value for the GraphQL execution. Can be accessed by Entrypoint resolvers from the root argument. SCALAR_EXTENSIONS_KEY Type: str | Default: \"undine_scalar\" The key used to store a Undine ScalarType in the extensions of the GraphQLScalarType . SCHEMA Type: GraphQLSchema | Default: \"undine.settings.example_schema\" The file and variable where the GraphQL Schema for Undine is located. Value should be given as the dotted path, usually created using undine.schema.create_schema . SCHEMA_DIRECTIVES_EXTENSIONS_KEY Type: str | Default: \"undine_schema_directives\" The key used to store the schema definition directives in the extensions of the GraphQLSchema . SDL_PRINTER Type: type[SDLPrinter] | Default: \"undine.utils.graphql.sdl_printer.SDLPrinter\" The SDL printer to use. Value should be given as the dotted path to the SDL printer class. TESTING_CLIENT_FULL_STACKTRACE Type: bool | Default: False Whether to include the full stacktrace in testing client instead of just the relevant frames when checking where SQL queries are made. TOTAL_COUNT_PARAM_NAME Type: str | Default: \"totalCount\" The name of the parameter in a connection ObjectType for holding the count for the total number of items that can be queried from the connection. UNDINE_PERSISTED_DOCUMENTS_MODEL Type: type[Model] | Default: \"undine.persisted_documents.models.PersistedDocument\" NOTE : This setting should be set in the top level of the settings file, not in the UNDINE dictionary! The model to use for the PersistedDocument model. Works similarly to AUTH_USER_MODEL , so must be set before running migrations for the persisted documents app. UNION_TYPE_EXTENSIONS_KEY Type: str | Default: \"undine_union_type\" The key used to store a Undine UnionType in the extensions of the GraphQLUnion . VALIDATION_HOOKS Type: list[type[LifecycleHook]] | Default: [] Hooks to run during validation the GraphQL request. See Lifecycle Hooks for more information. Values should be given as the dotted paths to the lifecycle hooks used. WEBSOCKET_CONNECTION_INIT_HOOK Type: WebSocketConnectionInitHook | Default: \"undine.utils.graphql.websocket.connection_init_hook\" The function to use for custom ConnectionInit logic. Value should be given as the dotted path to the function. WEBSOCKET_CONNECTION_INIT_TIMEOUT_SECONDS Type: int | Default: 3 The number of seconds to wait for the ConnectionInit message after opening a WebSocket before closing it. WEBSOCKET_PATH Type: str | Default: \"graphql/\" The path where the GraphQL over WebSocket endpoint is located if using undine.integrations.channels.get_websocket_enabled_app . WEBSOCKET_PING_HOOK Type: WebSocketConnectionPingHook | Default: \"undine.utils.graphql.websocket.ping_hook\" The function for specifying custom Ping message logic. Value should be given as the dotted path to the function. WEBSOCKET_PONG_HOOK Type: WebSocketConnectionPongHook | Default: \"undine.utils.graphql.websocket.pong_hook\" The function to for specifying custom Pong message logic. Value should be given as the dotted path to the function.","title":"Settings"},{"location":"subscriptions/","text":"Subscriptions \ud83d\udd17 In this section, we'll cover how you can add subscriptions to your schema. Subscriptions are a way to get real-time updates from your server through your GraphQL Schema. Setup \ud83d\udd17 To use subscriptions, you'll need to turn on Undine's async support , and use the channels integration . This will set you up with a web server capable of GraphQL over WebSocket protocol. You'll also need a client capable of using the protocol. Now, you can create a new RootType called Subscription and add Entrypoints that return an AsyncIterable , usually an AsyncGenerator . AsyncGenerators \ud83d\udd17 Let's take a look at a simple example of a subscription that counts down from 10 to 0. This subscription is set up using an AsyncGenerator function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown : Int ! } Using this subscription, you'll receive the following response 10 times on 1 second intervals, while the value of the countdown field is decreases from 10 to 1. 1 2 3 4 5 { \"data\" : { \"countdown\" : 10 } } The subscription's output type will be determined based on the first generic type parameter on the function's return type, so typing it is required. To add arguments for the subscription, you can add them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo , start : int = 10 ) -> AsyncGenerator [ int , None ]: for i in range ( start , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown ( start : Int ! = 10 ) : Int ! } AsyncIterables \ud83d\udd17 You can also use an AsyncIterable instead of creating an AsyncGenerator function. Note that the AsyncIterable needs to be returned from the Entrypoint function, not used as the Entrypoint reference itself. Otherwise, they work similarly to AsyncGenerators . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import asyncio from collections.abc import AsyncGenerator , AsyncIterable , AsyncIterator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Countdown : def __aiter__ ( self ) -> AsyncIterator [ int ]: return self . gen () async def gen ( self ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncIterable [ int ]: return Countdown () schema = create_schema ( query = Query , subscription = Subscription ) Exceptions \ud83d\udd17 If an exception is raised in the subscription, the subscription will be closed and an error message will be sent to the client. You should raise exceptions subclassing GraphQLError for better error messages, or use the GraphQLErrorGroup to raise multiple errors at once. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" raise GraphQLError ( msg ) await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) You can also yield a GraphQLError from the subscription, which will send an error while keeping the subscription open. Adding the error to the return type does not change the return type of the subscription. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int | GraphQLError , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" yield GraphQLError ( msg ) continue await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) Permissions \ud83d\udd17 As subscriptions use Entrypoints , you can use their permission checks to set per-value permissions for the subscription. Raising an exception from a permission check will close the subscription and send an error message to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema from undine.exceptions import GraphQLPermissionError class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i @countdown . permissions def countdown_permissions ( self , info : GQLInfo , value : int ) -> None : if value > 10 and not info . context . user . is_superuser : msg = \"Countdown value is too high\" raise GraphQLPermissionError ( msg ) schema = create_schema ( query = Query , subscription = Subscription ) You can also configure permission checks for establishing a websocket connection using the WEBSOCKET_CONNECTION_INIT_HOOK setting. 1 2 3 4 5 6 7 8 9 10 from typing import Any from undine.exceptions import GraphQLPermissionError from undine.utils.graphql.websocket import WebSocketRequest def connection_init_hook ( request : WebSocketRequest ) -> dict [ str , Any ] | None : if not request . user . is_superuser : msg = \"Only superusers can establish a connection\" raise GraphQLPermissionError ( msg )","title":"Subscriptions"},{"location":"subscriptions/#subscriptions","text":"In this section, we'll cover how you can add subscriptions to your schema. Subscriptions are a way to get real-time updates from your server through your GraphQL Schema.","title":"Subscriptions"},{"location":"subscriptions/#setup","text":"To use subscriptions, you'll need to turn on Undine's async support , and use the channels integration . This will set you up with a web server capable of GraphQL over WebSocket protocol. You'll also need a client capable of using the protocol. Now, you can create a new RootType called Subscription and add Entrypoints that return an AsyncIterable , usually an AsyncGenerator .","title":"Setup"},{"location":"subscriptions/#asyncgenerators","text":"Let's take a look at a simple example of a subscription that counts down from 10 to 0. This subscription is set up using an AsyncGenerator function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) About method signature A method decorated with @Entrypoint is treated as a static method by the Entrypoint . The self argument is not an instance of the RootType , but root argument of the GraphQLField resolver. To clarify this, it's recommended to change the argument's name to root , as defined by the RESOLVER_ROOT_PARAM_NAME setting. The value of the root argument for an Entrypoint is None by default, but can be configured using the ROOT_VALUE setting if desired. The info argument can be left out, but if it's included, it should always have the GQLInfo type annotation. This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown : Int ! } Using this subscription, you'll receive the following response 10 times on 1 second intervals, while the value of the countdown field is decreases from 10 to 1. 1 2 3 4 5 { \"data\" : { \"countdown\" : 10 } } The subscription's output type will be determined based on the first generic type parameter on the function's return type, so typing it is required. To add arguments for the subscription, you can add them to the function signature. Typing these arguments is required to determine their input type. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo , start : int = 10 ) -> AsyncGenerator [ int , None ]: for i in range ( start , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) This will create the following subscription in the GraphQL schema: 1 2 3 type Subscription { countdown ( start : Int ! = 10 ) : Int ! }","title":"AsyncGenerators"},{"location":"subscriptions/#asynciterables","text":"You can also use an AsyncIterable instead of creating an AsyncGenerator function. Note that the AsyncIterable needs to be returned from the Entrypoint function, not used as the Entrypoint reference itself. Otherwise, they work similarly to AsyncGenerators . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import asyncio from collections.abc import AsyncGenerator , AsyncIterable , AsyncIterator from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Countdown : def __aiter__ ( self ) -> AsyncIterator [ int ]: return self . gen () async def gen ( self ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncIterable [ int ]: return Countdown () schema = create_schema ( query = Query , subscription = Subscription )","title":"AsyncIterables"},{"location":"subscriptions/#exceptions","text":"If an exception is raised in the subscription, the subscription will be closed and an error message will be sent to the client. You should raise exceptions subclassing GraphQLError for better error messages, or use the GraphQLErrorGroup to raise multiple errors at once. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" raise GraphQLError ( msg ) await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription ) You can also yield a GraphQLError from the subscription, which will send an error while keeping the subscription open. Adding the error to the return type does not change the return type of the subscription. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from graphql import GraphQLError from undine import Entrypoint , GQLInfo , RootType , create_schema class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int | GraphQLError , None ]: for i in range ( 10 , 0 , - 1 ): if i == 5 : msg = \"Something went wrong\" yield GraphQLError ( msg ) continue await asyncio . sleep ( 1 ) yield i schema = create_schema ( query = Query , subscription = Subscription )","title":"Exceptions"},{"location":"subscriptions/#permissions","text":"As subscriptions use Entrypoints , you can use their permission checks to set per-value permissions for the subscription. Raising an exception from a permission check will close the subscription and send an error message to the client. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import asyncio from collections.abc import AsyncGenerator from undine import Entrypoint , GQLInfo , RootType , create_schema from undine.exceptions import GraphQLPermissionError class Query ( RootType ): @Entrypoint def task ( self , info : GQLInfo ) -> str : return \"Hello World\" class Subscription ( RootType ): @Entrypoint async def countdown ( self , info : GQLInfo ) -> AsyncGenerator [ int , None ]: for i in range ( 10 , 0 , - 1 ): await asyncio . sleep ( 1 ) yield i @countdown . permissions def countdown_permissions ( self , info : GQLInfo , value : int ) -> None : if value > 10 and not info . context . user . is_superuser : msg = \"Countdown value is too high\" raise GraphQLPermissionError ( msg ) schema = create_schema ( query = Query , subscription = Subscription ) You can also configure permission checks for establishing a websocket connection using the WEBSOCKET_CONNECTION_INIT_HOOK setting. 1 2 3 4 5 6 7 8 9 10 from typing import Any from undine.exceptions import GraphQLPermissionError from undine.utils.graphql.websocket import WebSocketRequest def connection_init_hook ( request : WebSocketRequest ) -> dict [ str , Any ] | None : if not request . user . is_superuser : msg = \"Only superusers can establish a connection\" raise GraphQLPermissionError ( msg )","title":"Permissions"},{"location":"tutorial/","text":"Tutorial \ud83d\udd17 Before starting the tutorial, read the Getting Started section. This tutorial will guide you through creating a simple GraphQL API using Undine. You'll learn the fundamental aspects of creating a GraphQL schema: queries, mutations, filtering, ordering, permissions, and validation. This should give you familiarity with how Undine works so that you can explore the rest of the documentation for more details. The example application will be a project management system, where users can create tasks with multiple steps and add them to projects. Very exciting! The Django project will have a single app called service where you'll create your models and schema. See the full directory structure below: 1 2 3 4 5 6 7 8 9 10 11 12 13 system/ \u251c\u2500 config/ \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 settings.py \u2502 \u251c\u2500 urls.py \u2502 \u251c\u2500 wsgi.py \u251c\u2500 service/ \u2502 \u251c\u2500 migrations/ \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 apps.py \u2502 \u251c\u2500 models.py \u251c\u2500 manage.py A starting template is available in docs/snippets/tutorial/template . Part 1: Setup \ud83d\udd17 First, install Undine using the installation instructions . Undine comes with an example schema that you can try out before creating your own. To access it, add the following to your project's urls.py file: 1 2 3 4 5 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), ] Next, configure Undine to enable GraphiQL , a tool for exploring GraphQL schemas in the browser. Undine is configured using the UNDINE setting in your Django project's settings.py file, so add the following to it: 1 2 3 4 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , } Now start the Django server and navigate to /graphql/ to see the GraphiQL UI. Make the following request: 1 2 3 query { testing } You should see the following response: 1 2 3 4 5 { \"data\" : { \"testing\" : \"Hello World\" } } Part 2: Creating the Schema \ud83d\udd17 Next, let's replace the example schema with your own. Create a file called schema.py in your service app directory, and add the following to it: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello World\" schema = create_schema ( query = Query ) This code creates the same schema as Undine's example schema. To make it your own, simply modify the return value of the testing method with your own custom message. In Undine, Entrypoints are used in the class bodies of RootTypes to define the operations that can be executed at the root of the GraphQL schema. Now you need to tell Undine to use your custom schema instead of the example one. Add the SCHEMA setting to Undine's configuration and set it to point to the schema variable you created in your schema.py file. 1 2 3 4 5 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , \"SCHEMA\" : \"service.schema.schema\" , } How do I determine the value for SCHEMA ? The value for SCHEMA is a \"dotted import path\" \u2014 a string that can be imported with Django's import_string utility. In other words, \"service.schema.schema\" points to a file service/schema.py with a variable schema . Restart the Django server and make the same request as before. You should see your own message instead of the example one. Part 3: Adding Queries \ud83d\udd17 Now that you have your own schema, let's start exposing Django models through it. In your models.py file, add the following model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Create and run migrations for this model. To add the Task model to the schema, let's add two Entrypoints : one for fetching a single Task , and another for fetching all Tasks . Replace the current schema.py file with the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) A QueryType is a class that represents a GraphQL ObjectType for a Django model in the GraphQL schema. By adding Fields to its class body, you can expose the model's fields in the GraphQL schema. To create Entrypoints for this QueryType , you simply use the QueryType as an argument to the Entrypoint class instead of decorating a method like you did before. This creates an Entrypoint for fetching a single Task by its primary key. For fetching all Tasks , pass many=True to indicate a list endpoint. Now it's time to try out your new schema. But wait, first you need some data to query! In your terminal, run python manage.py shell to start Django's shell and create a few rows for the Task model. 1 2 3 4 >>> from service.models import Task >>> Task . objects . create ( name = \"Task 1\" , done = False ) >>> Task . objects . create ( name = \"Task 2\" , done = True ) >>> Task . objects . create ( name = \"Task 3\" , done = False ) Now reboot the Django server and make the following request: 1 2 3 4 5 6 7 query { tasks { pk name done } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } ] } } Next, let's add a couple more models to your project. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . SET_NULL , null = True , blank = True , related_name = \"tasks\" ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE , related_name = \"steps\" ) Create and run migrations for these models, then create some data for them: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> from service.models import Project , Step , Task >>> project_1 = Project . objects . create ( name = \"Project 1\" ) >>> project_2 = Project . objects . create ( name = \"Project 2\" ) >>> task_1 = Task . objects . get ( name = \"Task 1\" ) >>> task_2 = Task . objects . get ( name = \"Task 2\" ) >>> task_3 = Task . objects . get ( name = \"Task 3\" ) >>> task_1 . project = project_1 >>> task_1 . save () >>> task_2 . project = project_2 >>> task_2 . save () >>> step_1 = Step . objects . create ( name = \"Step 1\" , done = false , task = task_1 ) >>> step_2 = Step . objects . create ( name = \"Step 2\" , done = true , task = task_1 ) >>> step_3 = Step . objects . create ( name = \"Step 3\" , done = false , task = task_2 ) >>> step_4 = Step . objects . create ( name = \"Step 4\" , done = true , task = task_3 ) >>> step_5 = Step . objects . create ( name = \"Step 5\" , done = true , task = task_3 ) Then, add these models to your schema by creating a QueryType for each of them. We can also link the QueryTypes to each other by adding Fields for the model's relations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () steps = Field () class StepType ( QueryType [ Step ]): pk = Field () name = Field () done = Field () task = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) Reboot the Django server once more and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name done project { pk name } steps { pk name done } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false , \"project\" : { \"pk\" : 1 , \"name\" : \"Project 1\" }, \"steps\" : [ { \"pk\" : 1 , \"name\" : \"Step 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Step 2\" , \"done\" : true } ] }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true , \"project\" : { \"pk\" : 2 , \"name\" : \"Project 2\" }, \"steps\" : [ { \"pk\" : 3 , \"name\" : \"Step 3\" , \"done\" : false } ] }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false , \"project\" : null , \"steps\" : [ { \"pk\" : 4 , \"name\" : \"Step 4\" , \"done\" : true }, { \"pk\" : 5 , \"name\" : \"Step 5\" , \"done\" : true } ] } ] } } Now that you're are using relations, Undine will automatically optimize the database queries for those relations. Part 4: Adding Mutations \ud83d\udd17 Next, let's add a mutation to your schema for creating Tasks . Add the following to the schema.py file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Undine will know that the MutationType TaskCreateMutation is a create mutation because the class has the word \"create\" in its name. Similarly, having \"update\" in the name will create an update mutation, and \"delete\" will create a delete mutation. Create, update and delete mutations are executed differently, more on this in the Mutations section. You could also use the kind argument in the MutationType class definition to be more explicit. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () done = Input () Undine will use the TaskType QueryType as the output type for MutationTypes automatically since they share the same model. All mutations require a QueryType for the same model to be created, even if it's not otherwise usable from the GraphQL schema. Let's try out the new mutations. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" }) { name } } You should see this response: 1 2 3 4 5 6 7 { \"data\" : { \"createTask\" : { \"name\" : \"New task\" } } } You can also mutate related objects by using other MutationTypes as Inputs . Modify the TaskCreateMutation by adding a Project Input. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Here TaskProjectInput is a special \"related\" kind of MutationType . These MutationTypes allow you to freely modify the related objects during the mutation. For example, using the above configuration, you could create a Task and a Project in a single mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { name project { name } } } Or you could link an existing Project to a new Task . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { name project { name } } } Or link an existing Project while renaming it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Renamed project\" } } ) { name project { name } } } Undine also supports bulk mutations by using the many argument on the Entrypoint . Let's add a bulk mutation for creating Tasks using the TaskCreateMutation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation ) Bulk mutations work just like regular mutations. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mutation { bulkCreateTasks ( input : [ { name : \"New Task\" project : { name : \"New Project\" } } { name : \"Other Task\" project : { name : \"Other Project\" } } ] ) { name project { name } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"data\" : { \"bulkCreateTasks\" : [ { \"name\" : \"New Task\" , \"project\" : { \"name\" : \"New Project\" } }, { \"name\" : \"Other Task\" , \"project\" : { \"name\" : \"Other Project\" } } ] } } Part 5: Adding Permissions \ud83d\udd17 In Undine, you can add permission checks to QueryTypes or MutationTypes as well as individual Fields or Inputs . Let's add a permission check for querying Tasks . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Now all users need to be logged in to access Tasks through TaskType . Boot up the Django server and make the following request: 1 2 3 4 5 query { tasks { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Need to be logged in to access Tasks.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"tasks\" ], \"extensions\" : { \"status_code\" : 403 , \"error_code\" : \"PERMISSION_DENIED\" } } ] } The permission check will be called for each instance returned by the QueryType . For Field permissions, you first need to define a Field explicitly on the QueryType and then decorate a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access the name of the Task.\" raise GraphQLPermissionError ( msg ) Now users need to be logged in to be able to query Task names. Mutation permissions work similarly to query permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : msg = \"Must be a staff user to be able add tasks.\" raise GraphQLPermissionError ( msg ) Now users need to be staff members to be able to create new Tasks using TaskCreateMutation . You can also restrict the usage of specific Inputs by defining the input on the MutationType and decorating a method with @<input_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): done = Input () @done . permissions def done_permissions ( self , info : GQLInfo , value : bool ) -> None : if not info . context . user . is_superuser : msg = \"Must be a superuser to be able add done tasks.\" raise GraphQLPermissionError ( msg ) Now only superusers can add Tasks that are already done, since in this case the default value of Task.done is False , and Input permissions are only checked for non-default values. Part 6: Adding Validation \ud83d\udd17 Mutations using MutationTypes can also be validated on both the MutationType and individual Input level. To add validation for a MutationType , add the __validate__ classmethod to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data [ \"done\" ]: msg = \"Cannot create a done task.\" raise GraphQLValidationError ( msg ) Now users cannot create tasks that are already marked as done. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" , done : true }) { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Cannot create a done task.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"createTask\" ], \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" } } ] } To add validation for an Input , define the input on the MutationType and decorate a method with @<input_name>.validate . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters.\" raise GraphQLValidationError ( msg ) Now users cannot create tasks with names that are less than 3 characters long. Part 7: Adding Filtering \ud83d\udd17 Results from QueryTypes can be filtered using Filters defined in a FilterSet . To filter results, create a FilterSet for the Task model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_contains = Filter ( lookup = \"icontains\" ) done = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): pk = Field () name = Field () done = Field () created_at = Field () Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameContains : \"a\" } ) { pk name } } Check the response. You should only see tasks with names that contain the letter \"a\". Different Filters can also be combined to narrow down the results. 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( filter : { nameContains : \"a\" done : false } ) { pk name } } With this query, you should only see tasks that contain the letter \"a\" and are not done. If you wanted to see either tasks containing the letter a or tasks that are not done, you could put the filters inside an OR block: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { OR : { nameContains : \"a\" done : false } } ) { pk name } } Similar logical blocks exist for AND , NOT and XOR , and they can be nested as deeply as needed. Part 8: Adding Ordering \ud83d\udd17 Results from QueryTypes can be ordered using Orders defined in an OrderSet . To order results, create an OrderSet for the Task model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): pk = Order () name = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): pk = Field () name = Field () done = Field () created_at = Field () Adding an ordering enables you to order by that fields in both ascending and descending directions. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( orderBy : [ nameAsc pkDesc ] ) { pk name } } With this ordering, you should see the tasks ordered primarily by name in ascending order, and secondarily by primary key in descending order. Next Steps \ud83d\udd17 In this tutorial, you've learned the basics of creating a GraphQL schema using Undine. It's likely your GraphQL schema has requirements outside of what has been covered here, so it's recommended to read the Queries , Mutations , Filtering , and Ordering sections next. The Pagination section is also helpful to learn how to paginate your QueryTypes using Relay Connections. For more in-depth information on how Undine optimizes queries to your GraphQL Schema, as well as how to provide custom optimizations for more complex use cases, see the Optimizer section.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"Before starting the tutorial, read the Getting Started section. This tutorial will guide you through creating a simple GraphQL API using Undine. You'll learn the fundamental aspects of creating a GraphQL schema: queries, mutations, filtering, ordering, permissions, and validation. This should give you familiarity with how Undine works so that you can explore the rest of the documentation for more details. The example application will be a project management system, where users can create tasks with multiple steps and add them to projects. Very exciting! The Django project will have a single app called service where you'll create your models and schema. See the full directory structure below: 1 2 3 4 5 6 7 8 9 10 11 12 13 system/ \u251c\u2500 config/ \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 settings.py \u2502 \u251c\u2500 urls.py \u2502 \u251c\u2500 wsgi.py \u251c\u2500 service/ \u2502 \u251c\u2500 migrations/ \u2502 \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 __init__.py \u2502 \u251c\u2500 apps.py \u2502 \u251c\u2500 models.py \u251c\u2500 manage.py A starting template is available in docs/snippets/tutorial/template .","title":"Tutorial"},{"location":"tutorial/#part-1-setup","text":"First, install Undine using the installation instructions . Undine comes with an example schema that you can try out before creating your own. To access it, add the following to your project's urls.py file: 1 2 3 4 5 from django.urls import include , path urlpatterns = [ path ( \"\" , include ( \"undine.http.urls\" )), ] Next, configure Undine to enable GraphiQL , a tool for exploring GraphQL schemas in the browser. Undine is configured using the UNDINE setting in your Django project's settings.py file, so add the following to it: 1 2 3 4 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , } Now start the Django server and navigate to /graphql/ to see the GraphiQL UI. Make the following request: 1 2 3 query { testing } You should see the following response: 1 2 3 4 5 { \"data\" : { \"testing\" : \"Hello World\" } }","title":"Part 1: Setup"},{"location":"tutorial/#part-2-creating-the-schema","text":"Next, let's replace the example schema with your own. Create a file called schema.py in your service app directory, and add the following to it: 1 2 3 4 5 6 7 8 9 10 from undine import Entrypoint , RootType , create_schema class Query ( RootType ): @Entrypoint def testing ( self ) -> str : return \"Hello World\" schema = create_schema ( query = Query ) This code creates the same schema as Undine's example schema. To make it your own, simply modify the return value of the testing method with your own custom message. In Undine, Entrypoints are used in the class bodies of RootTypes to define the operations that can be executed at the root of the GraphQL schema. Now you need to tell Undine to use your custom schema instead of the example one. Add the SCHEMA setting to Undine's configuration and set it to point to the schema variable you created in your schema.py file. 1 2 3 4 5 UNDINE = { \"GRAPHIQL_ENABLED\" : True , \"ALLOW_INTROSPECTION_QUERIES\" : True , \"SCHEMA\" : \"service.schema.schema\" , } How do I determine the value for SCHEMA ? The value for SCHEMA is a \"dotted import path\" \u2014 a string that can be imported with Django's import_string utility. In other words, \"service.schema.schema\" points to a file service/schema.py with a variable schema . Restart the Django server and make the same request as before. You should see your own message instead of the example one.","title":"Part 2: Creating the Schema"},{"location":"tutorial/#part-3-adding-queries","text":"Now that you have your own schema, let's start exposing Django models through it. In your models.py file, add the following model: 1 2 3 4 5 6 7 from django.db import models class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) Create and run migrations for this model. To add the Task model to the schema, let's add two Entrypoints : one for fetching a single Task , and another for fetching all Tasks . Replace the current schema.py file with the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) A QueryType is a class that represents a GraphQL ObjectType for a Django model in the GraphQL schema. By adding Fields to its class body, you can expose the model's fields in the GraphQL schema. To create Entrypoints for this QueryType , you simply use the QueryType as an argument to the Entrypoint class instead of decorating a method like you did before. This creates an Entrypoint for fetching a single Task by its primary key. For fetching all Tasks , pass many=True to indicate a list endpoint. Now it's time to try out your new schema. But wait, first you need some data to query! In your terminal, run python manage.py shell to start Django's shell and create a few rows for the Task model. 1 2 3 4 >>> from service.models import Task >>> Task . objects . create ( name = \"Task 1\" , done = False ) >>> Task . objects . create ( name = \"Task 2\" , done = True ) >>> Task . objects . create ( name = \"Task 3\" , done = False ) Now reboot the Django server and make the following request: 1 2 3 4 5 6 7 query { tasks { pk name done } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false } ] } } Next, let's add a couple more models to your project. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from django.db import models class Project ( models . Model ): name = models . CharField ( max_length = 255 ) class Task ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) created_at = models . DateTimeField ( auto_now_add = True ) project = models . ForeignKey ( Project , on_delete = models . SET_NULL , null = True , blank = True , related_name = \"tasks\" ) class Step ( models . Model ): name = models . CharField ( max_length = 255 ) done = models . BooleanField ( default = False ) task = models . ForeignKey ( Task , on_delete = models . CASCADE , related_name = \"steps\" ) Create and run migrations for these models, then create some data for them: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 >>> from service.models import Project , Step , Task >>> project_1 = Project . objects . create ( name = \"Project 1\" ) >>> project_2 = Project . objects . create ( name = \"Project 2\" ) >>> task_1 = Task . objects . get ( name = \"Task 1\" ) >>> task_2 = Task . objects . get ( name = \"Task 2\" ) >>> task_3 = Task . objects . get ( name = \"Task 3\" ) >>> task_1 . project = project_1 >>> task_1 . save () >>> task_2 . project = project_2 >>> task_2 . save () >>> step_1 = Step . objects . create ( name = \"Step 1\" , done = false , task = task_1 ) >>> step_2 = Step . objects . create ( name = \"Step 2\" , done = true , task = task_1 ) >>> step_3 = Step . objects . create ( name = \"Step 3\" , done = false , task = task_2 ) >>> step_4 = Step . objects . create ( name = \"Step 4\" , done = true , task = task_3 ) >>> step_5 = Step . objects . create ( name = \"Step 5\" , done = true , task = task_3 ) Then, add these models to your schema by creating a QueryType for each of them. We can also link the QueryTypes to each other by adding Fields for the model's relations. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from undine import Entrypoint , Field , QueryType , RootType , create_schema from .models import Project , Step , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () tasks = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () steps = Field () class StepType ( QueryType [ Step ]): pk = Field () name = Field () done = Field () task = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) schema = create_schema ( query = Query ) Reboot the Django server once more and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 query { tasks { pk name done project { pk name } steps { pk name done } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"data\" : { \"tasks\" : [ { \"pk\" : 1 , \"name\" : \"Task 1\" , \"done\" : false , \"project\" : { \"pk\" : 1 , \"name\" : \"Project 1\" }, \"steps\" : [ { \"pk\" : 1 , \"name\" : \"Step 1\" , \"done\" : false }, { \"pk\" : 2 , \"name\" : \"Step 2\" , \"done\" : true } ] }, { \"pk\" : 2 , \"name\" : \"Task 2\" , \"done\" : true , \"project\" : { \"pk\" : 2 , \"name\" : \"Project 2\" }, \"steps\" : [ { \"pk\" : 3 , \"name\" : \"Step 3\" , \"done\" : false } ] }, { \"pk\" : 3 , \"name\" : \"Task 3\" , \"done\" : false , \"project\" : null , \"steps\" : [ { \"pk\" : 4 , \"name\" : \"Step 4\" , \"done\" : true }, { \"pk\" : 5 , \"name\" : \"Step 5\" , \"done\" : true } ] } ] } } Now that you're are using relations, Undine will automatically optimize the database queries for those relations.","title":"Part 3: Adding Queries"},{"location":"tutorial/#part-4-adding-mutations","text":"Next, let's add a mutation to your schema for creating Tasks . Add the following to the schema.py file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Task class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Undine will know that the MutationType TaskCreateMutation is a create mutation because the class has the word \"create\" in its name. Similarly, having \"update\" in the name will create an update mutation, and \"delete\" will create a delete mutation. Create, update and delete mutations are executed differently, more on this in the Mutations section. You could also use the kind argument in the MutationType class definition to be more explicit. 1 2 3 4 5 6 7 8 from undine import Input , MutationType from .models import Task class TaskCreateMutation ( MutationType [ Task ], kind = \"create\" ): name = Input () done = Input () Undine will use the TaskType QueryType as the output type for MutationTypes automatically since they share the same model. All mutations require a QueryType for the same model to be created, even if it's not otherwise usable from the GraphQL schema. Let's try out the new mutations. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" }) { name } } You should see this response: 1 2 3 4 5 6 7 { \"data\" : { \"createTask\" : { \"name\" : \"New task\" } } } You can also mutate related objects by using other MutationTypes as Inputs . Modify the TaskCreateMutation by adding a Project Input. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) schema = create_schema ( query = Query , mutation = Mutation ) Here TaskProjectInput is a special \"related\" kind of MutationType . These MutationTypes allow you to freely modify the related objects during the mutation. For example, using the above configuration, you could create a Task and a Project in a single mutation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { name : \"New project\" } } ) { name project { name } } } Or you could link an existing Project to a new Task . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 } } ) { name project { name } } } Or link an existing Project while renaming it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mutation { createTask ( input : { name : \"New task\" project : { pk : 1 name : \"Renamed project\" } } ) { name project { name } } } Undine also supports bulk mutations by using the many argument on the Entrypoint . Let's add a bulk mutation for creating Tasks using the TaskCreateMutation . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 from undine import Entrypoint , Field , Input , MutationType , QueryType , RootType , create_schema from .models import Project , Task class ProjectType ( QueryType [ Project ]): pk = Field () name = Field () class TaskType ( QueryType [ Task ]): pk = Field () name = Field () done = Field () created_at = Field () project = Field () class Query ( RootType ): task = Entrypoint ( TaskType ) tasks = Entrypoint ( TaskType , many = True ) class TaskProjectInput ( MutationType [ Project ], kind = \"related\" ): pk = Input () name = Input () class TaskCreateMutation ( MutationType [ Task ]): name = Input () done = Input () project = Input ( TaskProjectInput ) class Mutation ( RootType ): create_task = Entrypoint ( TaskCreateMutation ) bulk_create_tasks = Entrypoint ( TaskCreateMutation , many = True ) schema = create_schema ( query = Query , mutation = Mutation ) Bulk mutations work just like regular mutations. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mutation { bulkCreateTasks ( input : [ { name : \"New Task\" project : { name : \"New Project\" } } { name : \"Other Task\" project : { name : \"Other Project\" } } ] ) { name project { name } } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"data\" : { \"bulkCreateTasks\" : [ { \"name\" : \"New Task\" , \"project\" : { \"name\" : \"New Project\" } }, { \"name\" : \"Other Task\" , \"project\" : { \"name\" : \"Other Project\" } } ] } }","title":"Part 4: Adding Mutations"},{"location":"tutorial/#part-5-adding-permissions","text":"In Undine, you can add permission checks to QueryTypes or MutationTypes as well as individual Fields or Inputs . Let's add a permission check for querying Tasks . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access Tasks.\" raise GraphQLPermissionError ( msg ) Now all users need to be logged in to access Tasks through TaskType . Boot up the Django server and make the following request: 1 2 3 4 5 query { tasks { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Need to be logged in to access Tasks.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"tasks\" ], \"extensions\" : { \"status_code\" : 403 , \"error_code\" : \"PERMISSION_DENIED\" } } ] } The permission check will be called for each instance returned by the QueryType . For Field permissions, you first need to define a Field explicitly on the QueryType and then decorate a method with @<field_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import Field , GQLInfo , QueryType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskType ( QueryType [ Task ]): name = Field () @name . permissions def name_permissions ( self , info : GQLInfo , value : str ) -> None : if info . context . user . is_anonymous : msg = \"Need to be logged in to access the name of the Task.\" raise GraphQLPermissionError ( msg ) Now users need to be logged in to be able to query Task names. Mutation permissions work similarly to query permissions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __permissions__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if not info . context . user . is_staff : msg = \"Must be a staff user to be able add tasks.\" raise GraphQLPermissionError ( msg ) Now users need to be staff members to be able to create new Tasks using TaskCreateMutation . You can also restrict the usage of specific Inputs by defining the input on the MutationType and decorating a method with @<input_name>.permissions . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLPermissionError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): done = Input () @done . permissions def done_permissions ( self , info : GQLInfo , value : bool ) -> None : if not info . context . user . is_superuser : msg = \"Must be a superuser to be able add done tasks.\" raise GraphQLPermissionError ( msg ) Now only superusers can add Tasks that are already done, since in this case the default value of Task.done is False , and Input permissions are only checked for non-default values.","title":"Part 5: Adding Permissions"},{"location":"tutorial/#part-6-adding-validation","text":"Mutations using MutationTypes can also be validated on both the MutationType and individual Input level. To add validation for a MutationType , add the __validate__ classmethod to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from typing import Any from undine import GQLInfo , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): @classmethod def __validate__ ( cls , instance : Task , info : GQLInfo , input_data : dict [ str , Any ]) -> None : if input_data [ \"done\" ]: msg = \"Cannot create a done task.\" raise GraphQLValidationError ( msg ) Now users cannot create tasks that are already marked as done. Boot up the Django server and make the following request: 1 2 3 4 5 mutation { createTask ( input : { name : \"New task\" , done : true }) { name } } You should see this response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"data\" : null , \"errors\" : [ { \"message\" : \"Cannot create a done task.\" , \"locations\" : [ { \"line\" : 2 , \"column\" : 3 } ], \"path\" : [ \"createTask\" ], \"extensions\" : { \"status_code\" : 400 , \"error_code\" : \"VALIDATION_ERROR\" } } ] } To add validation for an Input , define the input on the MutationType and decorate a method with @<input_name>.validate . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from undine import GQLInfo , Input , MutationType from undine.exceptions import GraphQLValidationError from .models import Task class TaskCreateMutation ( MutationType [ Task ]): name = Input () @name . validate def validate_name ( self , info : GQLInfo , value : str ) -> None : if len ( value ) < 3 : msg = \"Name must be at least 3 characters.\" raise GraphQLValidationError ( msg ) Now users cannot create tasks with names that are less than 3 characters long.","title":"Part 6: Adding Validation"},{"location":"tutorial/#part-7-adding-filtering","text":"Results from QueryTypes can be filtered using Filters defined in a FilterSet . To filter results, create a FilterSet for the Task model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Filter , FilterSet , QueryType from .models import Task class TaskFilterSet ( FilterSet [ Task ]): name_contains = Filter ( lookup = \"icontains\" ) done = Filter () class TaskType ( QueryType [ Task ], filterset = TaskFilterSet ): pk = Field () name = Field () done = Field () created_at = Field () Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 query { tasks ( filter : { nameContains : \"a\" } ) { pk name } } Check the response. You should only see tasks with names that contain the letter \"a\". Different Filters can also be combined to narrow down the results. 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( filter : { nameContains : \"a\" done : false } ) { pk name } } With this query, you should only see tasks that contain the letter \"a\" and are not done. If you wanted to see either tasks containing the letter a or tasks that are not done, you could put the filters inside an OR block: 1 2 3 4 5 6 7 8 9 10 11 12 13 query { tasks ( filter : { OR : { nameContains : \"a\" done : false } } ) { pk name } } Similar logical blocks exist for AND , NOT and XOR , and they can be nested as deeply as needed.","title":"Part 7: Adding Filtering"},{"location":"tutorial/#part-8-adding-ordering","text":"Results from QueryTypes can be ordered using Orders defined in an OrderSet . To order results, create an OrderSet for the Task model and add it to your TaskType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from undine import Field , Order , OrderSet , QueryType from .models import Task class TaskOrderSet ( OrderSet [ Task ]): pk = Order () name = Order () class TaskType ( QueryType [ Task ], orderset = TaskOrderSet ): pk = Field () name = Field () done = Field () created_at = Field () Adding an ordering enables you to order by that fields in both ascending and descending directions. Boot up the Django server and make the following request: 1 2 3 4 5 6 7 8 9 10 11 query { tasks ( orderBy : [ nameAsc pkDesc ] ) { pk name } } With this ordering, you should see the tasks ordered primarily by name in ascending order, and secondarily by primary key in descending order.","title":"Part 8: Adding Ordering"},{"location":"tutorial/#next-steps","text":"In this tutorial, you've learned the basics of creating a GraphQL schema using Undine. It's likely your GraphQL schema has requirements outside of what has been covered here, so it's recommended to read the Queries , Mutations , Filtering , and Ordering sections next. The Pagination section is also helpful to learn how to paginate your QueryTypes using Relay Connections. For more in-depth information on how Undine optimizes queries to your GraphQL Schema, as well as how to provide custom optimizations for more complex use cases, see the Optimizer section.","title":"Next Steps"},{"location":"unions/","text":"Unions \ud83d\udd17 In this section, we'll cover how GraphQL Unions work in Undine. Unions are abstract GraphQL types that represent a group of ObjectTypes that need to be returned together, e.g. for a search result. UnionType \ud83d\udd17 In Undine, a GraphQL Union between two or more QueryTypes is implemented using a UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... A UnionType can be added to a schema using an Entrypoint . Note that UnionType should always be added using a list Entrypoint (e.g. many=True ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 query { searchObjects { __typename ... on TaskType { name } ... on ProjectType { name } } } Filtering \ud83d\udd17 By default, the an Entrypoint for a UnionType will return all instances of all QueryTypes it contains. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the UnionType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class ProjectFilterSet ( FilterSet [ Project ]): ... class ProjectOrderSet ( OrderSet [ Project ]): ... class ProjectType ( QueryType [ Project ], filterset = ProjectFilterSet , orderset = ProjectOrderSet ): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { searchObjects ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterProject : ProjectFilterSet orderByProject : [ ProjectOrderSet !] ): [ Commentable !]! } This allows filtering and ordering the different types of models in the UnionType separately. To filter and order across different models in the UnionType , you can implement a FilterSet or an OrderSet for the same models as the UnionType and add it to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjectsFilterSet ( FilterSet [ Task , Project ]): ... class SearchObjectsOrderSet ( OrderSet [ Task , Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], filterset = SearchObjectsFilterSet , orderset = SearchObjectsOrderSet , ): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 type Query { searchObjects ( filter : SearchObjectsFilterSet orderBy : [ SearchObjectsOrderSet !] ): [ Commentable !]! } Note that a FilterSet or OrderSet created for multiple models like this should only contain Filters and Orders which will work on all models in the UnionType , i.e. they are of the same type. Pagination \ud83d\udd17 To paginate UnionTypes , you can use the Connection Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Entrypoint , QueryType , RootType , UnionType from undine.relay import Connection from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( Connection ( SearchObjects )) See the Pagination section for more details on pagination. Schema name \ud83d\udd17 By default, the name of the generated GraphQL Union is the same as the name of the UnionType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], schema_name = \"Search\" ): ... Description \ud83d\udd17 A description for a UnionType can be provided as a docstring. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): \"\"\"Description\"\"\" GraphQL Extensions \ud83d\udd17 You can provide custom extensions for the UnionType by providing a extensions argument with a dictionary containing them. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], extensions = { \"foo\" : \"bar\" }): ... UnionType extensions are made available in the GraphQL UnionType extensions after the schema is created. The UnionType itself is found in the extensions under a key defined by the UNION_TYPE_EXTENSIONS_KEY setting.","title":"Unions"},{"location":"unions/#unions","text":"In this section, we'll cover how GraphQL Unions work in Undine. Unions are abstract GraphQL types that represent a group of ObjectTypes that need to be returned together, e.g. for a search result.","title":"Unions"},{"location":"unions/#uniontype","text":"In Undine, a GraphQL Union between two or more QueryTypes is implemented using a UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... A UnionType can be added to a schema using an Entrypoint . Note that UnionType should always be added using a list Entrypoint (e.g. many=True ). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from undine import Entrypoint , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This Entrypoint can be queried like this: 1 2 3 4 5 6 7 8 9 10 11 query { searchObjects { __typename ... on TaskType { name } ... on ProjectType { name } } }","title":"UnionType"},{"location":"unions/#filtering","text":"By default, the an Entrypoint for a UnionType will return all instances of all QueryTypes it contains. However, if those QueryTypes implement a FilterSet or an OrderSet , those will also be available on the UnionType Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskFilterSet ( FilterSet [ Task ]): ... class TaskOrderSet ( OrderSet [ Task ]): ... class TaskType ( QueryType [ Task ], filterset = TaskFilterSet , orderset = TaskOrderSet ): ... class ProjectFilterSet ( FilterSet [ Project ]): ... class ProjectOrderSet ( OrderSet [ Project ]): ... class ProjectType ( QueryType [ Project ], filterset = ProjectFilterSet , orderset = ProjectOrderSet ): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 7 8 type Query { searchObjects ( filterTask : TaskFilterSet orderByTask : [ TaskOrderSet !] filterProject : ProjectFilterSet orderByProject : [ ProjectOrderSet !] ): [ Commentable !]! } This allows filtering and ordering the different types of models in the UnionType separately. To filter and order across different models in the UnionType , you can implement a FilterSet or an OrderSet for the same models as the UnionType and add it to the UnionType . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from undine import Entrypoint , FilterSet , OrderSet , QueryType , RootType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjectsFilterSet ( FilterSet [ Task , Project ]): ... class SearchObjectsOrderSet ( OrderSet [ Task , Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], filterset = SearchObjectsFilterSet , orderset = SearchObjectsOrderSet , ): ... class Query ( RootType ): search_objects = Entrypoint ( SearchObjects , many = True ) This creates the following Entrypoint : 1 2 3 4 5 6 type Query { searchObjects ( filter : SearchObjectsFilterSet orderBy : [ SearchObjectsOrderSet !] ): [ Commentable !]! } Note that a FilterSet or OrderSet created for multiple models like this should only contain Filters and Orders which will work on all models in the UnionType , i.e. they are of the same type.","title":"Filtering"},{"location":"unions/#pagination","text":"To paginate UnionTypes , you can use the Connection Entrypoint . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from undine import Entrypoint , QueryType , RootType , UnionType from undine.relay import Connection from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): ... class Query ( RootType ): search_objects = Entrypoint ( Connection ( SearchObjects )) See the Pagination section for more details on pagination.","title":"Pagination"},{"location":"unions/#schema-name","text":"By default, the name of the generated GraphQL Union is the same as the name of the UnionType class. If you want to change the name, you can do so by setting the schema_name argument: 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], schema_name = \"Search\" ): ...","title":"Schema name"},{"location":"unions/#description","text":"A description for a UnionType can be provided as a docstring. 1 2 3 4 5 6 7 8 9 10 11 12 13 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ]): \"\"\"Description\"\"\"","title":"Description"},{"location":"unions/#graphql-extensions","text":"You can provide custom extensions for the UnionType by providing a extensions argument with a dictionary containing them. 1 2 3 4 5 6 7 8 9 10 11 12 from undine import QueryType , UnionType from .models import Project , Task class TaskType ( QueryType [ Task ]): ... class ProjectType ( QueryType [ Project ]): ... class SearchObjects ( UnionType [ TaskType , ProjectType ], extensions = { \"foo\" : \"bar\" }): ... UnionType extensions are made available in the GraphQL UnionType extensions after the schema is created. The UnionType itself is found in the extensions under a key defined by the UNION_TYPE_EXTENSIONS_KEY setting.","title":"GraphQL Extensions"},{"location":"validation-rules/","text":"Validation rules \ud83d\udd17 This is an advanced GraphQL core feature. For validating mutations, see the Mutations documentation. A GraphQL operation consists of three main parts: parsing, validation, and execution. The parsing step transforms the GraphQL source document (string) into an AST (abstract syntax tree), which is then validated against the GraphQL schema. Finally, the execution step executes the AST against the schema to produce a result. By default, GraphQL Core (which Undine uses under the hood) comes with a set of validation rules which make sure that a GraphQL operation is valid according to the GraphQL specification. Undine adds a few more validation rules of its own, and allows you to add your own as well. Additional Rules \ud83d\udd17 MaxAliasCountRule \ud83d\udd17 This validation rule checks that the number of aliases in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_ALIASES setting. MaxComplexityRule \ud83d\udd17 This validation rule checks that the complexity of a GraphQL operation does not exceed the maximum allowed, as set by the MAX_QUERY_COMPLEXITY setting. MaxDirectiveCountRule \ud83d\udd17 This validation rule checks that the number of directives in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_DIRECTIVES setting. OneOfInputObjectTypeRule \ud83d\udd17 This validation rule checks that a one-of input object is used correctly. VisibilityRule \ud83d\udd17 When EXPERIMENTAL_VISIBILITY_CHECKS are enabled, this validation rule checks that users cannot use parts of the schema that are not visible to them. Custom validation rules \ud83d\udd17 To add your own validation rules, you'll need to create a class that inherits from graphql.validation.rules.ValidationRule . This class implements the visitor pattern to traverse the GraphQL AST. Different Nodes in the AST can be visited by defining either enter_<node_type> or leave_<node_type> methods, depending on whether you want to visit the node before or after its children. These methods have the following signature (example for NameNode ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import NameNode , Node , ValidationRule , VisitorAction class MyValidationRule ( ValidationRule ): def enter_name ( self , Node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : return None def leave_name ( self , Node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : return None For clarity, here is a list of Node types that can be visited during the GraphQL document validation phase: DocumentNode Hooks enter_document and leave_document | Node: graphql.language.ast.DocumentNode A DocumentNode is visited at the root of the GraphQL document AST. It can define multiple operations and fragments. OperationDefinitionNode Hooks enter_operation_definition and leave_operation_definition | Node: graphql.language.ast.OperationDefinitionNode An OperationDefinitionNode is visited for each operation in the GraphQL document. Note that a GraphQL document can contain multiple operations, although only one operation can be executed in a single request. VariableDefinitionNode Hooks enter_variable_definition and leave_variable_definition | Node: graphql.language.ast.VariableDefinitionNode A VariableDefinitionNode is visited for each variable definition in the GraphQL document. Variables are defined at the start of an operation using dollar signs ( $ ). NameNode Hooks enter_name and enter_name | Node: graphql.language.ast.NameNode A NameNode is visited for each named entity in the GraphQL document. This includes field names, argument names, and type names, etc. SelectionSetNode Hooks enter_selection_set and leave_selection_set | Node: graphql.language.ast.SelectionSetNode A SelectionSetNode is visited for each selection set in the GraphQL document. A selection set is a set of fields or fragments requested from a GraphQL type. FieldNode Hooks enter_field and leave_field | Node: graphql.language.ast.FieldNode A FieldNode is visited for each field in the GraphQL document. ArgumentNode Hooks enter_argument and leave_argument | Node: graphql.language.ast.ArgumentNode An ArgumentNode is visited for each field argument in the GraphQL document. FragmentSpreadNode Hooks enter_fragment_spread and leave_fragment_spread | Node: graphql.language.ast.FragmentSpreadNode A FragmentSpreadNode is visited for each fragment spread in the GraphQL document. InlineFragmentNode Hooks enter_inline_fragment and leave_inline_fragment | Node: graphql.language.ast.InlineFragmentNode A InlineFragmentNode is visited for each inline fragment in the GraphQL document. FragmentDefinitionNode Hooks enter_fragment_definition and leave_fragment_definition | Node: graphql.language.ast.FragmentDefinitionNode A FragmentDefinitionNode is visited for each fragment definition in the GraphQL document. NamedTypeNode Hooks enter_named_type and leave_named_type | Node: graphql.language.ast.NamedTypeNode A NamedTypeNode is visited for each named type is references in the GraphQL document. These are hit when using inline fragments or defining fragments. ListTypeNode Hooks enter_list_type and leave_list_type | Node: graphql.language.ast.ListTypeNode A ListTypeNode is visited for each list type in the GraphQL document. NonNullTypeNode Hooks enter_non_null_type and leave_non_null_type | Node: graphql.language.ast.NonNullTypeNode A NonNullTypeNode is visited for each non-null type in the GraphQL document. DirectiveNode Hooks enter_directive and leave_directive | Node: graphql.language.ast.DirectiveNode A DirectiveNode is visited for each directive used in the GraphQL document. VariableNode Hooks enter_variable and leave_variable | Node: graphql.language.ast.VariableNode A VariableNode is visited for each variable used in the GraphQL document. IntValueNode Hooks enter_int_value and leave_int_value | Node: graphql.language.ast.IntValueNode A IntValueNode is visited for each integer value in the GraphQL document. Values can be used in arguments or variables. FloatValueNode Hooks enter_float_value and leave_float_value | Node: graphql.language.ast.FloatValueNode A FloatValueNode is visited for each float value in the GraphQL document. Values can be used in arguments or variables. StringValueNode Hooks enter_string_value and leave_string_value | Node: graphql.language.ast.StringValueNode A StringValueNode is visited for each string value in the GraphQL document. Values can be used in arguments or variables. BooleanValueNode Hooks enter_boolean_value and leave_boolean_value | Node: graphql.language.ast.BooleanValueNode A BooleanValueNode is visited for each boolean value in the GraphQL document. Values can be used in arguments or variables. NullValueNode Hooks enter_null_value and leave_null_value | Node: graphql.language.ast.NullValueNode A NullValueNode is visited for each null value in the GraphQL document. Values can be used in arguments or variables. EnumValueNode Hooks enter_enum_value and leave_enum_value | Node: graphql.language.ast.EnumValueNode A EnumValueNode is visited for each enum value in the GraphQL document. Values can be used in arguments or variables. ListValueNode Hooks enter_list_value and leave_list_value | Node: graphql.language.ast.ListValueNode A ListValueNode is visited for each list value in the GraphQL document. Values can be used in arguments or variables. ObjectValueNode Hooks enter_object_value and leave_object_value | Node: graphql.language.ast.ObjectValueNode A ObjectValueNode is visited for each object value in the GraphQL document. Values can be used in arguments or variables. ObjectFieldNode Hooks enter_object_field and leave_object_field | Node: graphql.language.ast.ObjectFieldNode A ObjectFieldNode is visited for each object field in the GraphQL document. Values can be used in arguments or variables. There are other nodes which can be visited if validation rules are run against the GraphQL schema, but these are not covered in this documentation. A ValidationRule instance has access to the ValidationContext instance, through which you can access to commonly useful contextual information from within a validation rule. For example, you can access the current GraphQL type for the node using self.context.get_type() . Custom ValidationRules should be registered using the ADDITIONAL_VALIDATION_RULES setting.","title":"Validation Rules"},{"location":"validation-rules/#validation-rules","text":"This is an advanced GraphQL core feature. For validating mutations, see the Mutations documentation. A GraphQL operation consists of three main parts: parsing, validation, and execution. The parsing step transforms the GraphQL source document (string) into an AST (abstract syntax tree), which is then validated against the GraphQL schema. Finally, the execution step executes the AST against the schema to produce a result. By default, GraphQL Core (which Undine uses under the hood) comes with a set of validation rules which make sure that a GraphQL operation is valid according to the GraphQL specification. Undine adds a few more validation rules of its own, and allows you to add your own as well.","title":"Validation rules"},{"location":"validation-rules/#additional-rules","text":"","title":"Additional Rules"},{"location":"validation-rules/#maxaliascountrule","text":"This validation rule checks that the number of aliases in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_ALIASES setting.","title":"MaxAliasCountRule"},{"location":"validation-rules/#maxcomplexityrule","text":"This validation rule checks that the complexity of a GraphQL operation does not exceed the maximum allowed, as set by the MAX_QUERY_COMPLEXITY setting.","title":"MaxComplexityRule"},{"location":"validation-rules/#maxdirectivecountrule","text":"This validation rule checks that the number of directives in a GraphQL operation does not exceed the maximum allowed, as set by the MAX_ALLOWED_DIRECTIVES setting.","title":"MaxDirectiveCountRule"},{"location":"validation-rules/#oneofinputobjecttyperule","text":"This validation rule checks that a one-of input object is used correctly.","title":"OneOfInputObjectTypeRule"},{"location":"validation-rules/#visibilityrule","text":"When EXPERIMENTAL_VISIBILITY_CHECKS are enabled, this validation rule checks that users cannot use parts of the schema that are not visible to them.","title":"VisibilityRule"},{"location":"validation-rules/#custom-validation-rules","text":"To add your own validation rules, you'll need to create a class that inherits from graphql.validation.rules.ValidationRule . This class implements the visitor pattern to traverse the GraphQL AST. Different Nodes in the AST can be visited by defining either enter_<node_type> or leave_<node_type> methods, depending on whether you want to visit the node before or after its children. These methods have the following signature (example for NameNode ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from graphql import NameNode , Node , ValidationRule , VisitorAction class MyValidationRule ( ValidationRule ): def enter_name ( self , Node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : return None def leave_name ( self , Node : NameNode , key : str | int | None , parent : Node | tuple [ Node , ... ] | None , path : list [ str | int ], ancestors : list [ Node | tuple [ Node , ... ]], ) -> VisitorAction : return None For clarity, here is a list of Node types that can be visited during the GraphQL document validation phase: DocumentNode Hooks enter_document and leave_document | Node: graphql.language.ast.DocumentNode A DocumentNode is visited at the root of the GraphQL document AST. It can define multiple operations and fragments. OperationDefinitionNode Hooks enter_operation_definition and leave_operation_definition | Node: graphql.language.ast.OperationDefinitionNode An OperationDefinitionNode is visited for each operation in the GraphQL document. Note that a GraphQL document can contain multiple operations, although only one operation can be executed in a single request. VariableDefinitionNode Hooks enter_variable_definition and leave_variable_definition | Node: graphql.language.ast.VariableDefinitionNode A VariableDefinitionNode is visited for each variable definition in the GraphQL document. Variables are defined at the start of an operation using dollar signs ( $ ). NameNode Hooks enter_name and enter_name | Node: graphql.language.ast.NameNode A NameNode is visited for each named entity in the GraphQL document. This includes field names, argument names, and type names, etc. SelectionSetNode Hooks enter_selection_set and leave_selection_set | Node: graphql.language.ast.SelectionSetNode A SelectionSetNode is visited for each selection set in the GraphQL document. A selection set is a set of fields or fragments requested from a GraphQL type. FieldNode Hooks enter_field and leave_field | Node: graphql.language.ast.FieldNode A FieldNode is visited for each field in the GraphQL document. ArgumentNode Hooks enter_argument and leave_argument | Node: graphql.language.ast.ArgumentNode An ArgumentNode is visited for each field argument in the GraphQL document. FragmentSpreadNode Hooks enter_fragment_spread and leave_fragment_spread | Node: graphql.language.ast.FragmentSpreadNode A FragmentSpreadNode is visited for each fragment spread in the GraphQL document. InlineFragmentNode Hooks enter_inline_fragment and leave_inline_fragment | Node: graphql.language.ast.InlineFragmentNode A InlineFragmentNode is visited for each inline fragment in the GraphQL document. FragmentDefinitionNode Hooks enter_fragment_definition and leave_fragment_definition | Node: graphql.language.ast.FragmentDefinitionNode A FragmentDefinitionNode is visited for each fragment definition in the GraphQL document. NamedTypeNode Hooks enter_named_type and leave_named_type | Node: graphql.language.ast.NamedTypeNode A NamedTypeNode is visited for each named type is references in the GraphQL document. These are hit when using inline fragments or defining fragments. ListTypeNode Hooks enter_list_type and leave_list_type | Node: graphql.language.ast.ListTypeNode A ListTypeNode is visited for each list type in the GraphQL document. NonNullTypeNode Hooks enter_non_null_type and leave_non_null_type | Node: graphql.language.ast.NonNullTypeNode A NonNullTypeNode is visited for each non-null type in the GraphQL document. DirectiveNode Hooks enter_directive and leave_directive | Node: graphql.language.ast.DirectiveNode A DirectiveNode is visited for each directive used in the GraphQL document. VariableNode Hooks enter_variable and leave_variable | Node: graphql.language.ast.VariableNode A VariableNode is visited for each variable used in the GraphQL document. IntValueNode Hooks enter_int_value and leave_int_value | Node: graphql.language.ast.IntValueNode A IntValueNode is visited for each integer value in the GraphQL document. Values can be used in arguments or variables. FloatValueNode Hooks enter_float_value and leave_float_value | Node: graphql.language.ast.FloatValueNode A FloatValueNode is visited for each float value in the GraphQL document. Values can be used in arguments or variables. StringValueNode Hooks enter_string_value and leave_string_value | Node: graphql.language.ast.StringValueNode A StringValueNode is visited for each string value in the GraphQL document. Values can be used in arguments or variables. BooleanValueNode Hooks enter_boolean_value and leave_boolean_value | Node: graphql.language.ast.BooleanValueNode A BooleanValueNode is visited for each boolean value in the GraphQL document. Values can be used in arguments or variables. NullValueNode Hooks enter_null_value and leave_null_value | Node: graphql.language.ast.NullValueNode A NullValueNode is visited for each null value in the GraphQL document. Values can be used in arguments or variables. EnumValueNode Hooks enter_enum_value and leave_enum_value | Node: graphql.language.ast.EnumValueNode A EnumValueNode is visited for each enum value in the GraphQL document. Values can be used in arguments or variables. ListValueNode Hooks enter_list_value and leave_list_value | Node: graphql.language.ast.ListValueNode A ListValueNode is visited for each list value in the GraphQL document. Values can be used in arguments or variables. ObjectValueNode Hooks enter_object_value and leave_object_value | Node: graphql.language.ast.ObjectValueNode A ObjectValueNode is visited for each object value in the GraphQL document. Values can be used in arguments or variables. ObjectFieldNode Hooks enter_object_field and leave_object_field | Node: graphql.language.ast.ObjectFieldNode A ObjectFieldNode is visited for each object field in the GraphQL document. Values can be used in arguments or variables. There are other nodes which can be visited if validation rules are run against the GraphQL schema, but these are not covered in this documentation. A ValidationRule instance has access to the ValidationContext instance, through which you can access to commonly useful contextual information from within a validation rule. For example, you can access the current GraphQL type for the node using self.context.get_type() . Custom ValidationRules should be registered using the ADDITIONAL_VALIDATION_RULES setting.","title":"Custom validation rules"}]}